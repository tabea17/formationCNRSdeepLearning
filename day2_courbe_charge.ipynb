{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prévision de courbes de charge de consommation électrique\n",
    "\n",
    "L’objectif de cet atelier est de construire un modèle afin de **prévoir la courbe de charge** de la consommation électrique d'un site, avec les contraintes suivantes : \n",
    "           \n",
    " - on souhaite une prédiction sur 3 jours\n",
    " - avec un intervalle d'1 jour par rapport à l'historique des données. \n",
    "\n",
    "Par exemple, les observations sur le site ID08 - hôtel ou hébergement similaire - s'arrêtent le 09/10/2012 à 23:30. Il s'agit donc de prévoir la courbe de charge de consommation pour les 11/10/2012, 12/10/2012 et 13/10/2012. \n",
    "\n",
    "L’atelier est scindé en 2 étapes :\n",
    "\n",
    "* **Étape 1**. **Pré-traitement des données.**  \n",
    "Cette étape contient :\n",
    "\n",
    "    - L’import et l’audit des données : vérification rapide du contenu des fichiers de travail. Permet d’avoir une idée des méthodologies possibles à utiliser. \n",
    "\n",
    "    - Mise au format des données. En effet, pour étudier cette série temporelle, il va falloir découper les données en périodes (d'une durée à fixer) dont on va observer des réplicats (dans le temps).\n",
    "    \n",
    "* **Étape 2**. **Modélisation : apprentissage et test.**  \n",
    "Plusieurs modélisations sont proposées :\n",
    "\n",
    "    - Régression linéaire\n",
    "    - Gradient Boosting : LightGBM\n",
    "    - Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='import'></a>\n",
    "# Importer et auditer les données \n",
    "\n",
    "Les données à disposition sont contenues dans le fichier  `Courbes_Charge08.csv` à charger et qui contient \n",
    "\n",
    "   - la **consommation d'éléctricité** relevée **toutes les 10 minutes sur le site ID08  \n",
    "   - la **température** sur le site ID08 relevée physiquement toutes les 3 heures. Les données sur les temps intermédiaires ont été complétées par interpolation linéaire. \n",
    "\n",
    "Avant d'importer le fichier, on peut  afficher les premières lignes avec la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -10 'data/Courbes_Charge08.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercice 1\n",
    "\n",
    "Importez les données dans un dataframe (de la bibliothèque `pandas`) nommé `df` : \n",
    "* L'option `parse_dates` de la fonction `read_csv` de pandas vous permet de lire correctement la variable de la date.  \n",
    "* Faites attention au format de la température. \n",
    "* On transformera les noms de variables en minuscules (usage python). \n",
    "\n",
    "Puis familiarisez-vous avec ces données (à l'aide de `shape`, `head`, `dtypes`, `describe`,...).    \n",
    "Pendant combien de jours sont mesurées les données du site ? \n",
    "\n",
    "\n",
    "À l'aide de la librairie `matplotlib`, tracez les courbes de charge et de température en fonction de la date. Zoomez la courbe de charge en faisant varier la date de début et la durée de l'observation (pour mémoire, 1 jour = 6x24 points), l'objectif étant de comprendre les périodicités de cette courbe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Votre chemin. Par defaut celui du notebook\n",
    "# path_data = '.'\n",
    "path_data = 'data/'\n",
    "    \n",
    "df = pd.read_csv(os.path.join(path_data, 'Courbes_Charge08.csv'), \n",
    "                 sep=';', \n",
    "                 parse_dates=['DATE_LOCAL'],\n",
    "                 decimal=',',  # les décimales sont codées par une virgule\n",
    "                 dayfirst=True, # the day appears before month\n",
    "                 infer_datetime_format=True)\n",
    "\n",
    "# L'usage en Python est de mettre les noms de variables en minuscule \n",
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Les données du site id08 débutent le 1er janvier 2011 à minuit et s'achèvent le 09 octobre 2012 à 23:50. Elles sont régulières et contiennent des mesures toutes les 10 minutes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Avec des mesures toutes les 10 mins, on doit avoir 6 mesures par heure et 6*24 mesures par jour. Les 93312 lignes correspondent donc à 648 jours, ce qui fait bien 1 an (365 jours) plus 283 jours ; soit 1 an, 40 semaines et 3 jours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# description IT des données\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "On trace les courbes de charge et de température en fonction de la date : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df.plot(x='date_local', y='charge_id08', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.plot(x='date_local', y='temp_id08', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Nous allons zoomer les courbes de charge en faisant varier la date de départ et la durée des périodes (rappel 1 jour = 6*24 points), l'objectif étant de comprendre les périodicités de cette courbe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# On fera varier les deux quantités ci-dessous\n",
    "j_deb = 82 # n'importe quoi entre 0 et 648 moins la durée d'observation\n",
    "j_dur = 7 # regardons sur une semaine de temps\n",
    "\n",
    "# \n",
    "debut = 6*24*j_deb # point de départ \n",
    "duree = 6*24*j_dur\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, duree, duree)\n",
    "plt.plot(x, df[\"charge_id08\"].iloc[debut:(debut+duree)], label=\"courbe de charge sur %.f jours à partir du jour %.f\" %(j_dur, j_deb), lw=2)\n",
    "# séparateur de jours\n",
    "plt.xticks(np.arange(0, max(x), 6*24))\n",
    "plt.vlines(np.arange(0, max(x), 6*24),0,max(df[\"charge_id08\"].iloc[debut:(debut+duree)]),color='red')\n",
    "plt.legend(fontsize=14, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Rappel : Une journée contient 6x24=144 points et une semaine en contient 1008. On a tracé ci-dessus les périodes quotidiennes. On voit que certains jours ont des profils identiques, mais pas tous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# On regarde les choses à l'échelle mensuelle\n",
    "# On fera varier les deux quantités ci-dessous\n",
    "m_deb = 0 # n'importe quoi entre 0 et 22 moins la durée d'observation\n",
    "m_dur = 12 # regardons pendant un nobre de mois fixé\n",
    "\n",
    "# On se fixe des mois à 30 jours \n",
    "debut = 6*24*30*m_deb # point de départ \n",
    "duree = 6*24*30*m_dur\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, duree, duree) \n",
    "plt.plot(x, df[\"charge_id08\"].iloc[debut:(debut+duree)], label=\"courbe de charge sur %.f mois à partir du mois %.f\" %(m_dur, m_deb), lw=2)\n",
    "# séparateur de mois : \n",
    "plt.xticks(np.arange(0, max(x), 6*24*30)) \n",
    "plt.vlines(np.arange(0, max(x), 6*24*30),0,max(df[\"charge_id08\"].iloc[debut:(debut+duree)]),color='red')\n",
    "plt.legend(fontsize=14, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Conclusion : à l'échelle mensuelle on ne voit pas grand chose (sauf peut-être l'hiver et l'été)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise au format des données\n",
    "\n",
    "\n",
    "## Utilisation des données calendaires\n",
    "\n",
    "Dans cette partie, nous utilisons le module `datetime` afin de créer des champs de variables calendaires (pour une étude plus avancée). \n",
    "\n",
    "### Exercie 2\n",
    "On définit donc les 3 variables suivantes : \n",
    "* identifiant de jour (de 1 à 648 sur ces données)\n",
    "* type de jour (lundi, mardi,...)\n",
    "* un code du type de jour (de 0 à 6 pour lundi à dimanche)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# On ajoute la colonne qui donne un id unique du jour\n",
    "\n",
    "# Pour cela on écrit une fonction qui donne le nombre exact de jours dans \n",
    "# une année donnée\n",
    "def n_days_in_year(year):\n",
    "    d1 = datetime.date(year, 1, 1) \n",
    "    d2 = datetime.date(year + 1, 1, 1) \n",
    "    return (d2 - d1).days\n",
    "\n",
    "# L'année la plus ancienne dans le jeux de données\n",
    "min_year = df['date_local'].dt.year.min()\n",
    "\n",
    "# Une fonction qui renvoie un numéro unique de jour \n",
    "def day_number(t):\n",
    "    n_days = 0\n",
    "    for y in range(min_year, t.year):\n",
    "        n_days += n_days_in_year(y)      \n",
    "    return n_days + t.dayofyear\n",
    "\n",
    "# On ajoute à notre jeu de données une colonne avec numero du jour\n",
    "col_jour = df['date_local'].apply(day_number)\n",
    "df.insert(loc=0, column='jour', value=col_jour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# On ajoute également une colonne qui donne le nom du jour\n",
    "day_name = df['date_local'].dt.day_name()\n",
    "df.insert(loc=1, column='type_jour', value=day_name)\n",
    "\n",
    "# Création de codes pour le type de jour\n",
    "day_num = df['date_local'].dt.dayofweek\n",
    "df.insert(loc=2, column='code_jour', value=day_num)\n",
    "\n",
    "# Visualisons le nouveau jeu de données\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df['code_jour'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatage de la série temporelle - Étape importante : choix de la periode\n",
    "\n",
    "Dans cette partie, on va découper la série temporelle en série  d'observations successives sur une période fixée. Ces différentes périodes seront ensuite considérées comme des réplicats.  Il faut donc choisir une période qui fait du sens vis-à-vis de la variable étudiée (ici la courbe de charge). Il faudra aussi choisir une période de façon à avoir assez de réplicats (par exemple travailler à l'échelle annuelle n'est pas possible avec ces données). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercice 3\n",
    "\n",
    "Définissez une variable `periode`, exprimée en jours, qui pourra prendre par exemple les valeurs 1 (courbes de charge quotidiennes) ou 7 (courbes de charge hebdomadaires) ou tout autre choix. Pour cette variable, vous allez calculer :\n",
    "* `nobs` le nombre de points de mesure correspondant à cette période\n",
    "* `n` le nombre **entier** de périodes contenues dans les données. \n",
    "\n",
    "Ensuite, vous allez :\n",
    "- supprimer les données les plus anciennes de manière à avoir un nombre entier de périodes d'observation \n",
    "- sauver le tableau de travail sous un nouveau nom `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## On fixe la periode en jours - faites varier la période\n",
    "#periode = 1 # On peut travailler sur des consommations journalières\n",
    "periode = 7 # Ou sur des consommations hebdomadaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Nombre de points d'observation necessaires pour 1 période (exprimée en jours)\n",
    "nobs = periode * 6 * 24\n",
    "\n",
    "# Nombre de periodes disponibles dans les donnees\n",
    "n = int(df.shape[0] / nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# On supprime des données de manière à disposer d'un nombre entier de périodes d'observation\n",
    "\n",
    "# Nombre de lignes a supprimer (on choisit de les supprimer au debut de la période d'observation)\n",
    "kill = df.shape[0] - n * nobs\n",
    "\n",
    "# On définit un nouveau tableau en supprimant la période incomplète du début \n",
    "df2 = df.iloc[kill:df.shape[0]]\n",
    "\n",
    "# Comptages divers\n",
    "print(\"Chaque période contient %.f points de mesure\" %nobs)\n",
    "print(\"Il y a un total de %.f périodes\" %n)\n",
    "print(\"On a supprimé %.f points d'observation en début de série\" %kill)\n",
    "print(\"Les nouvelles données contiennent %.f points de mesure\" %df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisons l'en-tête des nouvelles données\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rappelons que l'objectif final est la prédiction de la charge en fonction de l'historique. Pour cela, nous considérerons un modèle linéaire dans lequel on souhaite  prédire la nouvelle charge à un moment précis de la période (p.ex. un mardi à 15h10, si on considère des périodes d'une semaine) en fonction de toutes les charges et temperatures observées dans le passé au même moment (tous les mardis à 15h10). \n",
    "\n",
    "### Exercice 4\n",
    "\n",
    "- Mettre les données au bon format maintenant.  Commencer par les données de la charge. On construira un nouveau tableau de données, appelé `df_charge`, qui contient`nobs`  lignes (= nombre de points par période) et `n` colonnes (= nombre de périodes). \n",
    "  Vous nommerez les colonnes de `Cn` (la première) à `C1` (la dernière), les premières correspondant aux périodes les plus récentes et les dernières correspondant aux périodes les plus anciennes.\n",
    "- En utilisant ce nouveau tableau, tracez sur un même graphique la  superposition de quelques courbes de charge sur la période donnée.\n",
    "- Faites varier la période.\n",
    "- Effectuer la même démarche pour la température. Vous nommerez le nouveau tableau `df_temp` et  les colonnes `Tn` à `T1` avec la même convention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reformater la variable charge_id08\n",
    "# C1 ==>  correspond à la charge de la période 1, C2  ==> Période 2 , etc\n",
    "nom = ['C' + str(i) for i in range(2, n + 2)]\n",
    "debut, fin = 0, nobs \n",
    "\n",
    "df_charge = df2.iloc[debut:fin, 4].to_frame()\n",
    "\n",
    "for i in range(n - 1):\n",
    "    debut += nobs\n",
    "    fin += nobs\n",
    "    a = df2.iloc[debut:fin, 4]\n",
    "    df_charge.insert(0, nom[i], a.values)  \n",
    "\n",
    "df_charge.rename(columns={'charge_id08': 'C1'}, inplace=True)\n",
    "df_charge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Commande alternative pour formater les données :\n",
    "# df_charge = np.array(df2['charge_id08']).reshape(n, nobs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Le nouveau tableau a nobs lignes et n colonnes\n",
    "print(df_charge.shape)\n",
    "print(nobs,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualisons le haut du nouveau tableau\n",
    "df_charge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Notez que les périodes sont ordonnées de la plus récente (première colonne, qui s'appelle `Cn`) à la plus ancienne (dernière colonne, qui s'appelle `C1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Il y a correspondance entre la variable C1 et la charge de la période 1\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Visualisons les charges de quelques périodes choisies arbitrairement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Visualisation graphique de quelques périodes \n",
    "P0 = [10,19,8,27,6,52] # on choisit des indices de périodes  \n",
    "periodes = df_charge.columns[P0]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "df_charge.plot(y=periodes, figsize=(15, 5), title='Courbes de charge sur une période')\n",
    "\n",
    "for i in range(len(periodes)): \n",
    "    a = (n - P0[i])*periode + int(kill/6/24)+1   # on démarre au jour d'indice kill/(6*24)+1\n",
    "    toto = df2[df2['jour'] == a]\n",
    "    print(periodes[i], 'débute le :',toto.iloc[0,1],toto.iloc[0,3])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "On fait la même chose sur la variable température."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reformater la variable temp_id08\n",
    "# T1 ==>  correspond à la température de la période 1, T2  ==> Période 2 , etc\n",
    "nom = ['T' + str(i) for i in range(2, n + 2)]\n",
    "debut, fin = 0, nobs \n",
    "df_temp = df2.iloc[debut:fin, 5].to_frame()\n",
    "\n",
    "for i in range(n - 1):\n",
    "    debut += nobs\n",
    "    fin += nobs\n",
    "    a = df2.iloc[debut:fin, 5]\n",
    "    df_temp.insert(0, nom[i], a.values) # insère 0 insère au début!!!\n",
    "\n",
    "df_temp.rename(columns={'temp_id08': 'T1'}, inplace=True)\n",
    "df_temp.head()\n",
    "\n",
    "# Courbes de température pour quelques périodes\n",
    "P0 = [10,9,8,7,6,5]\n",
    "periodes = df_temp.columns[P0]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "df_temp.plot(y=periodes, figsize=(15, 5), title='Températures sur une période')\n",
    "\n",
    "# Pour chaque période, on indique à quel jour de la semaine et quelle date elle débute\n",
    "\n",
    "for i in range(len(periodes)):    \n",
    "    a = (n - P0[i])*periode + int(kill/6/24)+1   # on démarre au jour d'indice kill/(6*24)+1\n",
    "    toto = df2[df2['jour'] == a]\n",
    "    print(periodes[i], 'débute le :',toto.iloc[0,1],toto.iloc[0,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Premières questions de modélisation\n",
    "\n",
    "Nous allons apprendre la courbe de charge $C_j$ de la période numéro $j$ à l'aide des courbes de charge $C_{k}, C_{p}, \\ldots$ des jours passés numéro $k,p, \\ldots$.\n",
    "\n",
    "Attention, le problème initial imposé est de proposer une prévision :\n",
    "   - d'une durée 3 jours ;\n",
    "   - avec un intervalle d'1 jour par rapport à l'historique des données. \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "1. Une modélisation *à la journée* est-t-elle judicieuse à votre avis ? Étudiez cette question : \n",
    "    -  en observant le comportement des différents types de jours ;\n",
    "    -  en pensant à l'objectif : prévision sur 3 jours avec un intervalle d'1 jour.\n",
    "\n",
    "\n",
    "2. Choisir de modéliser *à la semaine* plutôt qu'*à la journée* ne semble-t-il pas plus pertinent ? Pourquoi ? \n",
    "\n",
    "3. Quelles variables explicatives pourrait-on inclure dans le modèle ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse\n",
    "\n",
    "1. Non ce n'est pas judicieux car les jours ont des comportements différents (typiquement le dimanche a un profil de courbe de charge très différent). \n",
    "\n",
    "2. Modéliser à la semaine est donc plus intéressant, puisque la périodicité des comportements est sur 7 jours. \n",
    "\n",
    "3. Il est naturel et même obligatoire d'inclure la température comme variable explicative. \n",
    "\n",
    "\n",
    "**Refaites tourner le code ci-dessus en choisissant une période de 7 jours avant de passer à la suite.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modélisation\n",
    "\n",
    "**NB** : Pour tous les modèles proposés, il faut choisir la profondeur de l'historique selon :\n",
    "- les possibilités techniques ;\n",
    "- le sens \"métier\".\n",
    "\n",
    "## Modèle de régression linéaire\n",
    "\n",
    "On commence par choisir une période (ici une semaine) d'indice $k$  et par entraîner le modèle linéaire pour prévoir la courbe de charge sur la période (semaine) qui suit immédiatement la période $k$, i.e la période d'indice $k-1$. Autrement dit on va d'abord apprendre le lien entre $C_k$ et les courbes de charges précedentes $C_{k+1},C_{k+2},\\dots,C_{k+h}$ ainsi que les températures associées $T_{k+1},\\dots,T_{k+h}$, pour un certain choix de l'historique $h$.\n",
    "Ensuite, on utilisera cette relation apprise pour prédire la courbe de charge $C_{k-1}$. On évaluera les mêmes erreurs que précedemment entre la courbe prédite et la courbe réelle. \n",
    "\n",
    "La qualité de la méthode sera évaluée en faisant varier $k$ et $h$ (selon la longueur des données dont on dispose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6\n",
    "\n",
    "1. À l'aide de la fonction `LinearRegression` du module `sklearn.linear_model` faites une régression linéaire de la variable $C_k$ (qu'on renommera en `y_train`) sur les variables $C_{k+1},\\dots C_{k+h}, T_{k+1},\\dots,T_{k+h}$ (qu'on renommera en `x_train`). \n",
    "\n",
    "2. Ensuite, grâce à cette relation apprise, vous prédirez la variable $C_{k-1}$ (renommée `y_test`) à partir des $h$ variables immédiatement précédentes, c'est-à-dire $C_{k},\\dots C_{k+h-1},T_k,\\dots, T_{k+h-1}$ (renommées `x_test`).\n",
    "\n",
    "3. La qualité de la prédiction sera mesurée en erreur relative pour la norme $L_1$ ainsi que via la racine carrée de l'erreur quadratique moyenne (via la fonction `mean_squared_error` du module `sklearn.metrics`). \n",
    "Vous calculerez également la corrélation de Pearson entre les valeurs prédites et les valeurs observées via  la fonction `pearsonr` du module `scipy.stats`.\n",
    "4. Vous tracerez les courbes prédites et observées pour visualiser la qualité de la prédiction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Modèle Auto-régressif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "# Choisir le numero k de periode\n",
    "# Apprendre le lien entre Ck et son passe C_{k+1}...C_{k+h}, T_{k+1}...T_{k+h}\n",
    "# Prevoir la periode suivante C_{k-1}\n",
    "\n",
    "# Numero de colonne du debut la periode d'apprentissage \n",
    "k = 75\n",
    "# Nombre de periodes (semaines) passées, ie historique utilisé\n",
    "h = 4\n",
    "\n",
    "# Creation du modele\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Données TEST et TRAIN\n",
    "# NB on a rangé les colonnes des plus récentes au plus anciennes !\n",
    "y_train = df_charge.iloc[:, k]\n",
    "x_train = pd.concat([df_charge.iloc[:, (k+1):(k+h+1)], # courbes de charge de l'historique\n",
    "                     df_temp.iloc[:, (k+1):(k+h+1)]], axis=1) # courbes de température de l'historique\n",
    "y_test = df_charge.iloc[:, (k-1)]\n",
    "x_test = pd.concat([df_charge.iloc[:, k:(k+h)],\n",
    "                     df_temp.iloc[:, k:(k+h)]], axis=1) # nouvel historique\n",
    "\n",
    "# Rename columns - Necessary\n",
    "x_test.columns = x_train.columns\n",
    "\n",
    "lr.fit(x_train, y_train) \n",
    "pred = lr.predict(x_test)\n",
    "\n",
    "#############\n",
    "# Graphes de prédiction sur toute la période\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "\n",
    "x = np.linspace(1, nobs, nobs)\n",
    "plt.plot(x, y_test, label=\"observation\", lw=2)\n",
    "plt.plot(x, pred, label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Root mean square error\n",
    "rmse = mean_squared_error(y_test, pred) ** 0.5 # racine carrée de la MSE\n",
    "print(\"RMSE: %.4f\" % rmse)\n",
    "# Mean absolute prediction error\n",
    "mape = (abs((pred - y_test) / y_test)).mean()\n",
    "print(\"MAPE: %.4f\" % mape)\n",
    "cor = pearsonr(y_test, pred)\n",
    "print(\"Correlation observation/prevision: %.4f\" % cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Notez que le problème des mesures RMSE et MAP est qu'elles ne sont pas facilement interprétables (combien vaut un 'bon RMSE' ?). Il faut faire varier les valeurs de $h$ et de $k$ (c'est ce qu'on fera ci-dessous) pour trouver le 'meilleur' ajustement.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Avec cette approche, répondez à la demande initiale de prédiction sur 3 jours avec un intervalle d'un jour. Plus précisément, grâce à la relation apprise ci-dessus entre la courbe de la semaine $k$ et celles des $h$ semaines précédentes, vous avez obtenu une prédiction pour *toute la semaine* $k-1$ et vous pouvez en extraire les prédictions pour les jours numéros 2 à 4 de cette semaine. Vous tracerez les courbes prédites et observées et calculerez les mêmes erreurs que précédemment restreintes aux 3 jours qui nous intéressent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Prédiction demandée : 3 jours avec un intervalle de 1 jour ==> restriction\n",
    "\n",
    "gap = 1\n",
    "horizon = 3 \n",
    "debut = gap * 6 * 24 # première mesure (commence le second jour de la période)\n",
    "fin = debut + horizon * 6 * 24 # dernière mesure (finit le quatrième jour de la période)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "\n",
    "npoints = fin-debut\n",
    "x = np.linspace(1, npoints, npoints)\n",
    "# On extrait de y_test les points entre \n",
    "plt.plot(x, y_test[debut:fin], label=\"observation\", lw=2)\n",
    "plt.plot(x, pred[debut:fin], label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "rmse = mean_squared_error(y_test[debut:fin], pred[debut:fin]) ** 0.5\n",
    "print(\"RMSE: %.4f\" % rmse)\n",
    "mape = (abs((pred[debut:fin] - y_test[debut:fin]) /y_test[debut:fin])).mean()\n",
    "print(\"MAPE: %.4f\" % mape)\n",
    "cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "print(\"Correlation observation/prevue: %.4f\" % cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "On va à présent pour un historique $h$ fixé regarder toutes les prévisions possibles, i.e. faire varier $k$ sur l'ensemble des valeurs possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modelisation lineaire systématique sur les périodes k\n",
    "\n",
    "# Nombre de periodes passées, ie historique utilise\n",
    "h = 4\n",
    "E2_lr = []\n",
    "E1_lr = []\n",
    "Cor_lr = []\n",
    "\n",
    "# Toutes les prévisions de Période_Max à (Periode moins historique)\n",
    "for i in range(n-h-1):\n",
    "    k = i + 1\n",
    "\n",
    "    # Données TEST et TRAIN\n",
    "    y_train = df_charge.iloc[:, k]\n",
    "    x_train = pd.concat([df_charge.iloc[:, (k+1):(k+h+1)],\n",
    "                     df_temp.iloc[:, (k+1):(k+h+1)]], axis=1) \n",
    "    y_test = df_charge.iloc[:, (k-1)]\n",
    "    x_test = pd.concat([df_charge.iloc[:, k:(k+h)],\n",
    "                     df_temp.iloc[:, k:(k+h)]], axis=1) \n",
    "                     \n",
    "    # Modélisation\n",
    "    x_test.columns = x_train.columns\n",
    "    lr.fit(x_train, y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    \n",
    "    # Performances\n",
    "    err2 = mean_squared_error( pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    mape = (abs(( pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin],  pred[debut:fin])\n",
    "    Cor_lr.append(cor[0]) \n",
    "    E2_lr.append(err2)\n",
    "    E1_lr.append(mape)\n",
    "    \n",
    "\n",
    "#########\n",
    "# Résultats\n",
    "from statistics import mean\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, len(E1_lr), len(E1_lr))\n",
    "plt.plot(x, E1_lr, label=\"erreur\", lw=2)\n",
    "plt.title('Erreur MAP', fontsize=18)\n",
    "\n",
    "print(\"RMSE: %.4f\" % mean(E2_lr))\n",
    "print(\"MAPE: %.4f\" % mean(E1_lr))\n",
    "print(\"Corr: %.4f\" % mean(Cor_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 8\n",
    "Avec le code ci-dessus, faites varier $h$ et choisissez l'historique le mieux adapté à l'ensemble des périodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Pour $h$ variant entre 4 et 6, on obtient des erreurs moyennes très similaires (ça se dégrade un peu pour $h=3$ et pour $h=7$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle de Gradient Boosting\n",
    "\n",
    "À l'aide du module `lightgbm` et de la fonction `LGBMRegressor` vous allez utiliser le boosting pour apprendre la relation entre une courbe de charge $C_k$ à une période $k$ fixée, et l'historique des courbes précédentes $C_{k+1},\\dots C_{k+h+1}$ et des températures précédentes $T_{k+1},\\dots T_{k+h+1}$.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### Exercice 9\n",
    "- Commencez par fixer (arbitrairement) les paramètres de l'algorithme. Vous ferez attention à l'option `num_leaves`de `LGBMRegressor`. Cette option indique le nombre maximal de feuilles des arbres utilisés. Il est important de régler convenablement ce paramètre `num_leaves` plutôt que le paramètre `max_depth`.\n",
    "- Entraînez le modèle et faites la prédiction de la même façon qu'à l'exercice 6 ci-dessus. En particulier, vous présenterez les mêmes graphiques et les mêmes calculs d'erreurs. \n",
    "- Faites varier les paramètres de l'algorithme pour essayer de diminuer les erreurs. On peut également regarder l'importance des variables via l'attribut `feature_importances_` de `LGBMRegressor`. La notion d'importance des variables permet d'indiquer les variables dont l'absence dégraderait la qualité de l'ajustement du modèle. Par défaut,  l'importance d'une variable correspond au nombre de splits dans le modèle où la variable est utilisée.\n",
    "- Enfin, évaluez la qualité de la méthode en utilisant toutes les valeurs de $k$ possibles (selon la longueur des données dont on dispose).\n",
    "- Dernière étape: choisissez les paramètres de la méthode par validation croisée. On utilisera `GridSearchCV` de `sklearn.model_selection`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Minimum à relancer pour la suite quand ton kernel est mort\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "\n",
    "path_data = 'data/'\n",
    "df = pd.read_csv(os.path.join(path_data, 'Courbes_Charge08.csv'), sep=';', \n",
    "                 parse_dates=['DATE_LOCAL'],\n",
    "                 decimal=',',  # les décimales sont codées par une virgule\n",
    "                 dayfirst=True,\n",
    "                 infer_datetime_format=True)\n",
    "df.columns = [x.lower() for x in df.columns]\n",
    "\n",
    "periode = 7 # consommations hebdomadaires\n",
    "nobs = periode * 6 * 24\n",
    "n = int(df.shape[0] / nobs)\n",
    "\n",
    "def n_days_in_year(year):\n",
    "    d1 = datetime.date(year, 1, 1) \n",
    "    d2 = datetime.date(year + 1, 1, 1) \n",
    "    return (d2 - d1).days\n",
    "min_year = df['date_local'].dt.year.min()\n",
    "def day_number(t):\n",
    "    n_days = 0\n",
    "    for y in range(min_year, t.year):\n",
    "        n_days += n_days_in_year(y)       \n",
    "    return n_days + t.dayofyear\n",
    "col_jour = df['date_local'].apply(day_number)\n",
    "df.insert(loc=0, column='jour', value=col_jour)\n",
    "day_name = df['date_local'].dt.day_name()\n",
    "df.insert(loc=1, column='type_jour', value=day_name)\n",
    "day_num = df['date_local'].dt.dayofweek\n",
    "df.insert(loc=2, column='code_jour', value=day_num)\n",
    "\n",
    "kill = df.shape[0] - n * nobs\n",
    "df2 = df.iloc[kill:df.shape[0]]\n",
    "\n",
    "nom = ['C' + str(i) for i in range(2, n + 2)]\n",
    "debut, fin = 0, nobs \n",
    "df_charge = df2.iloc[debut:fin, 4].to_frame()\n",
    "for i in range(n - 1):\n",
    "    debut += nobs\n",
    "    fin += nobs\n",
    "    a = df2.iloc[debut:fin, 4]\n",
    "    df_charge.insert(0, nom[i], a.values)\n",
    "df_charge.rename(columns={'charge_id08': 'C1'}, inplace=True)\n",
    "\n",
    "nom = ['T' + str(i) for i in range(2, n + 2)]\n",
    "debut, fin = 0, nobs \n",
    "df_temp = df2.iloc[debut:fin, 5].to_frame()\n",
    "for i in range(n - 1):\n",
    "    debut += nobs\n",
    "    fin += nobs\n",
    "    a = df2.iloc[debut:fin, 5]\n",
    "    df_temp.insert(0, nom[i], a.values)\n",
    "df_temp.rename(columns={'temp_id08': 'T1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Modelisation LightGBM\n",
    "\n",
    "# Choisir k numero de periode\n",
    "# Apprendre le lien entre C_k et son passe\n",
    "# Prevoir C_{k-1}\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Numero de colonne du debut la periode d'apprentissage \n",
    "k = 52\n",
    "# Historique utilisé \n",
    "h = 3\n",
    "\n",
    "# Creation du modele\n",
    "gbm = lgb.LGBMRegressor(objective='regression', # default value\n",
    "                        num_leaves=10, # c'est pas forcément des souches, default is 31\n",
    "                        learning_rate=0.05, # default is 0.1\n",
    "                        feature_fraction = 0.2, # if feature_fraction < 1, use feature sub-sampling : randomly select a subset of features (size defined by feature_fraction) for the splits\n",
    "                        bagging_fraction = 1, # default is 1 (if < 1, randomly select a subset of data (size defined by bagging_fraction) on each iteration (tree))\n",
    "                        n_estimators=100, #number of boosting iterations performed.\n",
    "                       ) \n",
    "#gbm = lgb.LGBMRegressor()\n",
    "y_train = df_charge.iloc[:, k]\n",
    "x_train = pd.concat([df_charge.iloc[:, (k+1):(k+h+1)],\n",
    "                     df_temp.iloc[:, (k+1):(k+h+1)]], axis=1)\n",
    "\n",
    "y_test = df_charge.iloc[:, (k-1)]\n",
    "x_test = pd.concat([df_charge.iloc[:, k:(k+h)],\n",
    "                    df_temp.iloc[:, k:(k+h)]], axis=1)\n",
    "x_test.columns = x_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# c'est là que le kernel meurt\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pred = gbm.predict(x_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, pred) ** 0.5 # racine carrée de l'erreur quadratique\n",
    "print(\"RMSE: %.4f\" % rmse)\n",
    "map1 = (abs((pred - y_test) / y_test)).mean()\n",
    "print(\"MAPE: %.4f\" % map1)\n",
    "cor = pearsonr(y_test, pred)\n",
    "print(\"Correlation observation/prevue: %.4f\" % cor[0])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, nobs, nobs)\n",
    "plt.plot(x, y_test, label=\"observation\", lw=2)\n",
    "plt.plot(x, pred, label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche des variables les plus \"pertinentes\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importance des variables explicatives\n",
    "var_importance = gbm.feature_importances_\n",
    "var_importance = 100.0 * (var_importance / var_importance.sum())\n",
    "sorted_idx = np.argsort(var_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.barh(pos, var_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, x_train.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détermination des 'meilleurs' paramètres par validation croisée sur une grille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estimator = lgb.LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.01, 0.05, 0.1],\n",
    "    'num_leaves' : [2, 3]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=10)\n",
    "\n",
    "gbm.fit(x_train, y_train)\n",
    "\n",
    "print('Les meilleurs paramètres sur la grille sont ', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = lgb.LGBMRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100],\n",
    "    'learning_rate': [0.05, 0.1, .5],\n",
    "    'num_leaves' : [2, 3, 5, 7, 10]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=10)\n",
    "\n",
    "gbm.fit(x_train, y_train)\n",
    "\n",
    "print('Les meilleurs paramètres sur la grille sont ', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Modelisation LightGBM\n",
    "# Systematique\n",
    "gap = 1\n",
    "horizon = 3 \n",
    "debut = gap*6*24\n",
    "fin = debut + horizon*6*24\n",
    "\n",
    "# Apprendre le lien Pk et son passe\n",
    "# Prevoir Pk+1\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=2,\n",
    "                        learning_rate=0.05,\n",
    "                        feature_fraction=0.3,\n",
    "                        bagging_fraction=1,\n",
    "                        n_estimators=200)\n",
    "\n",
    "# Nombre de jours passes: historique utilise\n",
    "p = 20\n",
    "E2_lgbm = []\n",
    "E1_lgbm = []\n",
    "Cor_lgbm = []\n",
    "\n",
    "# Toutes les prévisions du Période Max à Periode 10\n",
    "for k in range(n - 30):\n",
    "    K = k + 1\n",
    "    y_train = df_charge.iloc[:, K]\n",
    "    X_train = pd.concat([df_charge.iloc[:, (K+1):(K+p+1)],\n",
    "                     df_temp.iloc[:, (K+1):(K+p+1)]], axis=1)\n",
    "\n",
    "    y_test = df_charge.iloc[:, (K-1)]\n",
    "    X_test = pd.concat([df_charge.iloc[:, K:(K+p)],\n",
    "                    df_temp.iloc[:, K:(K+p)]], axis=1)\n",
    "\n",
    "    X_test.columns = X_train.columns\n",
    "    gbm.fit(X_train, y_train)\n",
    "    pred = gbm.predict(X_test)\n",
    "    \n",
    "    err2 = mean_squared_error(pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    map1 = (abs((pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "    Cor_lgbm.append(cor[0]) \n",
    "    E2_lgbm.append(err2)\n",
    "    E1_lgbm.append(map1)\n",
    "    \n",
    "### Résultats performances    \n",
    "from statistics import mean\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, len(E1_lgbm), len(E1_lgbm))\n",
    "plt.plot(x, E1_lgbm, label=\"erreur\", lw=2)\n",
    "plt.title('Erreur MAP', fontsize=18)\n",
    "\n",
    "print(\"RMSE: %.4f\" % mean(E2_lgbm))\n",
    "print(\"MAP: %.4f\" % mean(E1_lgbm))\n",
    "print(\"Corr: %.4f\" % mean(Cor_lgbm))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rf'></a>\n",
    "## Forêts aléatoires \n",
    "\n",
    "### Exercice 10\n",
    "\n",
    "Enfin, nous utiliseront des forêts aléatoires via le module `RandomForestRegressor` de `sklearn.ensemble` pour apprendre un modèle prédictif pour le même problème et les mêmes données qu'avant. On procède comme précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Modelisation Random Forest\n",
    "\n",
    "# Choisir K numero de periode\n",
    "# Apprendre le lien Pk et son passe\n",
    "# Prevoir Pk+1\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Numero colonne du debut la periode d'apprentissage ==> K-1 à prévoir\n",
    "K = 70\n",
    "\n",
    "# Nombre de periodes passees : historique utilisé\n",
    "p = 20\n",
    "\n",
    "#creation du modele\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100, # Nombre d'arbres\n",
    "    max_features=0.2, #  round(max_features * n_features) features are considered at each split (The default of 1.0 is equivalent to bagged trees)\n",
    "    max_depth=10,      # complexité\n",
    "    random_state=2,\n",
    "    oob_score=True # Whether to use out-of-bag samples to estimate the generalization score. \n",
    ")\n",
    "\n",
    "y_train = df_charge.iloc[:, K]\n",
    "X_train = pd.concat([df_charge.iloc[:, (K+1):(K+p+1)],\n",
    "                     df_temp.iloc[:, (K+1):(K+p+1)]], axis=1)\n",
    "\n",
    "y_test = df_charge.iloc[:, (K-1)]\n",
    "X_test = pd.concat([df_charge.iloc[:, K:(K+p)],\n",
    "                    df_temp.iloc[:, K:(K+p)]], axis=1)\n",
    "\n",
    "X_test.columns = X_train.columns\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, pred) ** 0.5\n",
    "print(\"RMSE: %.4f\" % mse)\n",
    "map1 = (abs((pred - y_test) / y_test)).mean()\n",
    "print(\"MAPE: %.4f\" % map1)\n",
    "cor = pearsonr(y_test, pred)\n",
    "print(\"Correlation observation/prevue: %.4f\" % cor[0])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, nobs, nobs)\n",
    "plt.plot(x, y_test, label=\"observation\", lw=2)\n",
    "plt.plot(x, pred, label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Modelisation RF\n",
    "# Systematique\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "gap = 1\n",
    "horizon = 3 \n",
    "debut = gap*6*24\n",
    "fin = debut + horizon*6*24\n",
    "\n",
    "# Creation du modele\n",
    "rf = RandomForestRegressor(n_estimators=50, max_features=\"sqrt\", \n",
    "                           max_depth=3)\n",
    "\n",
    "# Nombre de jours passes: historique utilise\n",
    "p = 29\n",
    "E2_rf = []\n",
    "E1_rf = []\n",
    "Cor_rf = []\n",
    "\n",
    "# Toutes les prévisions du Période Max à Periode 10\n",
    "for k in range(n - 30):\n",
    "    K = k + 1\n",
    "    y_train = df_charge.iloc[:, K]\n",
    "    X_train = pd.concat([df_charge.iloc[:, (K+1):(K+p+1)],\n",
    "                     df_temp.iloc[:, (K+1):(K+p+1)]], axis=1)\n",
    "\n",
    "    y_test = df_charge.iloc[:, (K-1)]\n",
    "    X_test = pd.concat([df_charge.iloc[:, K:(K+p)],\n",
    "                    df_temp.iloc[:, K:(K+p)]], axis=1)\n",
    "\n",
    "    X_test.columns = X_train.columns\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    \n",
    "    err2 = mean_squared_error(pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    map1 = (abs((pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "    Cor_rf.append(cor[0]) \n",
    "    E2_rf.append(err2)\n",
    "    E1_rf.append(map1)\n",
    "    \n",
    "# Résultats performances   \n",
    "from statistics import mean\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, len(E1_rf), len(E1_rf))\n",
    "plt.plot(x, E1_rf, label=\"erreur\", lw=2)\n",
    "plt.title('Erreur MAP', fontsize=18)\n",
    "\n",
    "print(\"RMSE: %.4f\" % mean(E2_rf))\n",
    "print(\"MAP: %.4f\" % mean(E1_rf))\n",
    "print(\"Corr: %.4f\" % mean(Cor_rf))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='comparaison'></a>\n",
    "# 5.  Comparaison de modèles \n",
    "\n",
    "### Exercice 11\n",
    "\n",
    "On compare les différents modèles sur\n",
    "\n",
    "- les erreurs moyennes : L2, MAP et corrélation\n",
    "- les erreurs ponctuelles MAP\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, len(E1_rf), len(E1_rf)) \n",
    "plt.plot(x, E1_lr[0:len(E1_rf)], label=\"Regression linéaire\", lw=2)\n",
    "plt.plot(x, E1_rf, label=\"Random Forest\", lw=2)\n",
    "plt.plot(x, E1_lgbm, label=\"LightGBM\", lw=2)\n",
    "plt.title('Erreur MAP', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "print(\"Reg lin : MAP %.3f\" % mean(E1_lr),\" RMSE %.1f\" % mean(E2_lr),\" corr %.2f\" % mean(Cor_lr))\n",
    "print(\"LightGBM : MAP %.3f\" % mean(E1_lgbm),\" RMSE %.1f\" % mean(E2_lgbm),\" corr %.2f\" % mean(Cor_lgbm))\n",
    "print(\"Random Forest : MAP %.3f\" % mean(E1_rf),\" RMSE %.1f\" % mean(E2_rf),\" corr %.2f\" % mean(Cor_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions supplémentaires\n",
    "\n",
    "### On refait tourner sans les températures, pour voir l'apport de ces données \"exogènes\"\n",
    "\n",
    "Les modeles sont:\n",
    "\n",
    "- `reg` : regression lineaire\n",
    "- `gbm`: boosting par `LightGBM`\n",
    "- `rf` : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gap = 1\n",
    "horizon = 3 \n",
    "debut = gap*6*24\n",
    "fin = debut + horizon*6*24\n",
    "\n",
    "\n",
    "# Nombre de jours passes: historique utilise\n",
    "p = 5    \n",
    "\n",
    "E2_lr_T = []\n",
    "E1_lr_T = []\n",
    "Cor_lr_T = []\n",
    "\n",
    "E2_rf_T = []\n",
    "E1_rf_T = []\n",
    "Cor_rf_T = []\n",
    "\n",
    "E2_lgbm_T = []\n",
    "E1_lgbm_T = []\n",
    "Cor_lgbm_T = []\n",
    "\n",
    "for k in range(n - 30):\n",
    "    K = k+1\n",
    "    y_train = df_charge.iloc[:, K]       \n",
    "    y_test = df_charge.iloc[:, (K-1)]\n",
    "    X_train = df_charge.iloc[:, (K+1):(K+p+1)]\n",
    "    X_test = df_charge.iloc[:, K:(K+p)]\n",
    "    X_test.columns = X_train.columns\n",
    "\n",
    "    # Regression lineaire\n",
    "    lr.fit(X_train, y_train)  \n",
    "    pred = lr.predict(X_test) \n",
    "    err2 = mean_squared_error(pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    map1 = (abs((pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "    Cor_lr_T.append(cor[0])\n",
    "    E2_lr_T.append(err2)\n",
    "    E1_lr_T.append(map1)\n",
    "\n",
    "    # Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "    pred = rf.predict(X_test)\n",
    "    err2 = mean_squared_error(pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    map1 = (abs((pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "    Cor_rf_T.append(cor[0])\n",
    "    E2_rf_T.append(err2)\n",
    "    E1_rf_T.append(map1)\n",
    "\n",
    "    # LightGBM\n",
    "    gbm.fit(X_train, y_train)\n",
    "    pred = gbm.predict(X_test)\n",
    "    err2 = mean_squared_error(pred[debut:fin], y_test[debut:fin]) ** 0.5\n",
    "    map1 = (abs((pred[debut:fin] - y_test[debut:fin]) / y_test[debut:fin])).mean()\n",
    "    cor = pearsonr(y_test[debut:fin], pred[debut:fin])\n",
    "    Cor_lgbm_T.append(cor[0]) \n",
    "    E2_lgbm_T.append(err2)\n",
    "    E1_lgbm_T.append(map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 3))\n",
    "\n",
    "x = np.linspace(1, len(E1_rf), len(E1_rf)) \n",
    "plt.plot(x, E1_lr_T, label=\"Regression linéaire\", lw=2)\n",
    "plt.plot(x, E1_rf_T, label=\"Random Forest\", lw=2)\n",
    "plt.plot(x, E1_lgbm_T, label=\"LightGBM\", lw=2)\n",
    "plt.title('Erreur MAP', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "print(\"Reg lin : MAP %.3f\" % mean(E1_lr_T),\" RMSE %.1f\" % mean(E2_lr_T),\" corr %.2f\" % mean(Cor_lr_T))\n",
    "print(\"LightGBM : MAP %.3f\" % mean(E1_lgbm_T),\" RMSE %.1f\" % mean(E2_lgbm_T),\" corr %.2f\" % mean(Cor_lgbm_T))\n",
    "print(\"Random Forest : MAP %.3f\" % mean(E1_rf_T),\" RMSE %.1f\" % mean(E2_rf_T),\" corr %.2f\" % mean(Cor_rf_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison avec et sans les temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "x = np.linspace(1, len(E1_rf), len(E1_rf))\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "plt.plot(x, E1_lr[0:len(E1_rf)], label=\"Avec températures\", lw=2)\n",
    "plt.plot(x, E1_lr_T, label=\"Sans températures)\", lw=2)\n",
    "plt.title('Erreur MAP pour Régression Linéaire', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x, E1_rf, label=\"Random Forest (avec temps)\", lw=2)\n",
    "plt.plot(x, E1_rf_T, label=\"Random Forest (sans temps)\", lw=2)\n",
    "plt.title('Erreur MAP pour Random Forest', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
