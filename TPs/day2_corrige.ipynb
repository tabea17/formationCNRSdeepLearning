{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# Prévision de courbes de charge de consommation électrique\n",
    "\n",
    "Dans ce TP nous allons travailler sur un jeu de données qui représente la consommation électrique d'un site sur une longue durée avec une résolution assez fine. L’objectif est de construire un modèle afin de **prévoir la courbe de charge** de la consommation électrique future.\n",
    "\n",
    "Les données forment une **série temporelle**. On observe la courbe de charge à intervalle régulier (toutes les 10 minutes) sur une longue durée  et on souhaite prédire le futur.\n",
    "\n",
    "![Série temporelle](img/timeSeries1.jpeg)\n",
    "\n",
    "Plus précisément, nous souhaitons un modèle qui prédit la courbe de charge électrique pour le jour suivant par rapport à l'historique des données. Par exemple, si nous sommes le 09/10/2012 à 13:30, il s'agit de prévoir la courbe de charge de consommation sur les prochaines 24 heures (toutes les 10 minutes, c'est-à-dire 144 valeurs).\n",
    "\n",
    "\n",
    "En statistique il existe des modèles puissants pour l'études des séries temporelles et il est également possible d'utiliser une approche deep learning pour aborder ce problème. En revanche, vu que nous n'avons pas le temps dans ce cours d'étudier ces modèles, nous commencerons par explorer l'utilisation d'un simple **modèle linéaire** et nous verrons ensuite une première applications des forêts aléatoires.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’atelier est scindé en deux étapes :\n",
    "\n",
    "* **Étape 1**. **Pré-traitement des données.**  \n",
    "Cette étape contient :\n",
    "\n",
    "    - L’import et l’audit des données : vérification rapide du contenu des fichiers de travail. Permet d’avoir une idée des méthodologies possibles à utiliser. \n",
    "\n",
    "    - Mise au format des données. En effet, pour étudier cette série temporelle, il va falloir découper les données en périodes (d'une durée à fixer) dont on va observer des réplicats (dans le temps).\n",
    "    \n",
    "* **Étape 2**. **Modélisation : apprentissage et test.**  \n",
    "Plusieurs modélisations sont proposées :\n",
    "\n",
    "    - Approche naïve\n",
    "    - Régression linéaire\n",
    "    - Random Forest\n",
    "    - Gradient Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation et exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données à disposition sont contenues dans le fichier  `Courbes_Charge08.csv` à charger et qui contient \n",
    "\n",
    "   - la **consommation d'éléctricité** relevée **toutes les 10 minutes sur le site ID08**\n",
    "   - la **température** sur le site ID08 relevée physiquement toutes les 3 heures. Les données sur les temps intermédiaires ont été complétées par interpolation linéaire. \n",
    "\n",
    "Avant d'importer le fichier, on peut  afficher les premières lignes avec la commande suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -10 'data/Courbes_Charge08.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la commande précédente ne fonctionne pas sur votre OS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/Courbes_Charge08.csv', 'r')\n",
    "for i, line in zip(range(5), file):\n",
    "   print(i, line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez qu'on ne sait pas si les dates sont codées en jour/mois/année ou mois/jour/année. On peut le voir en affichant une ligne un peu plus loin : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, line in enumerate(file):\n",
    "    if i == 4000:\n",
    "        print(i, line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là on constate qu'il s'agit d'un codage jour/mois/année."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1\n",
    "\n",
    "\n",
    "Importez les données dans un dataframe (de la bibliothèque `pandas`) nommé `df_raw` :\n",
    "\n",
    "- L'option `parse_dates` de la fonction `read_csv` de pandas vous permet de lire correctement la variable de la date. \n",
    "- Faites attention au format de la température. \n",
    "- On transformera les noms de variables en minuscules (usage python). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Votre chemin. Par defaut celui du notebook\n",
    "# path_data = '.'\n",
    "path_data = 'data/'\n",
    "    \n",
    "# Lecture du fichier\n",
    "df_raw = pd.read_csv(os.path.join(path_data, 'Courbes_Charge08.csv'), \n",
    "                 sep=';', \n",
    "                 parse_dates=['DATE_LOCAL'],\n",
    "                 decimal=',',  # les décimales sont codées par une virgule\n",
    "                 dayfirst=True, # the day appears before month\n",
    "                 )\n",
    "\n",
    "# L'usage en Python est de mettre les noms de variables en minuscule \n",
    "df_raw.columns = [x.lower() for x in df_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['date_local'][0].weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exercice 2\n",
    "\n",
    "Nous allons créer, à partir du dataframe de départ `df_raw`, un deuxième dataframe `df` sur lequel nous allons travailler.\n",
    "\n",
    "- Répartir l'information contenue dans la colonne `date_local` de `df_raw` en plusieurs colonnes de sorte à afficher séparement la date, le numéro de semaine, le numéro de jour, le jour de la semaine (0 pour lundi, 1 pour mardi, ...) et l'heure. Nous allons travailler uniquement sur la charge, il faut donc également supprimer la colonne des températures.\n",
    "\n",
    "- Vérifier qu'il n'y a pas de données manquantes.\n",
    "\n",
    "- Travailler sur des semaines complètes, qui commencent un lundi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# L'ordinal est le nombres jours qui se sont écoulés à partir du 1er janvier de l'année 0001\n",
    "print(datetime.strptime('0001-01-01', '%Y-%m-%d').toordinal())\n",
    "\n",
    "first_day = df_raw[\"date_local\"][0].toordinal()\n",
    "print(first_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "first_day = df_raw[\"date_local\"][0].toordinal()\n",
    "first_day_wd = df_raw[\"date_local\"][0].weekday()\n",
    "df = pd.concat(\n",
    "    [ \n",
    "        df_raw[\"date_local\"].transform({\n",
    "            \"date\": lambda d: d, # on garde le point temporel d'origine \n",
    "            \"week\": lambda d: (d.toordinal() - (first_day - first_day_wd)) // 7,\n",
    "            \"day\": lambda d: d.toordinal() - first_day,\n",
    "            \"weekday\": lambda d: d.weekday(),\n",
    "            \"time\": lambda d: d.strftime(\"%H:%M\"),\n",
    "        }),\n",
    "        df_raw[\"charge_id08\"]\n",
    "    ], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[144*np.arange(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# iloc : position le long de l'index\n",
    "# loc : basé sur le label\n",
    "df.index  = np.arange(10, 93312+10)\n",
    "df.iloc[0:10].equals(df.loc[np.arange(10,20)])\n",
    "\n",
    "# le slicing avec loc prend le debut ET la fin du slice \n",
    "df.loc[10:1018,'week']\n",
    "\n",
    "# loc avec condition logique\n",
    "df.loc[df['week'] == 1]\n",
    "\n",
    "df.index  = np.arange(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On vérifie qu'il n'y a pas de données manquantes\n",
    "print(\"Il y a \", df.isna().sum().sum(), \"données manquantes\")\n",
    "\n",
    "# Les jours sont des jours complets\n",
    "print(\"Nombre de jours observés : \", df.shape[0]/144)\n",
    "nb_days = int(df.shape[0]/144)\n",
    "\n",
    "# Les semaines ne sont pas complètes \n",
    "print(\"Nombre de semaines observées : \", df.shape[0]/(144*7))\n",
    "\n",
    "# Les données commencent à minuit du premier jour\n",
    "# et il n'y a pas d'intervals de temps manquants\n",
    "# donc on pourra faire un reshape 144\n",
    "print(df['time'].iloc[:144])\n",
    "np.sum(np.tile(df['time'].iloc[:144],nb_days) == df['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3\n",
    "\n",
    "`pandas` est dit *row-major*, ce qui signifie que les éléments d'un tableau multidimensionnel sont disposés séquentiellement ligne par ligne. Ceci est cohérent avec la vision d'un dataframe comme un ensemble d'individus (ou d'observations), chacun représenté par une ligne du tableau, qui ont des caractéristiques, représentées par les colonnes. \n",
    "Dans notre exemple, pour prendre en compte la périodicité des données (qui sera de un jour ou bien d'une semaine),  il convient de transformer le dataframe pour que chaque ligne corresponde à une période.  \n",
    "\n",
    "#### Période: 1 jour\n",
    "\n",
    "- Créer un dataframe `df_day` avec les charges ordonnées par période d'un jour. Les colonnes de ce dataframe vont être les 144 intervals de 10 minutes qui donnent un jour. On pourra utiliser la fonction `reshape`.\n",
    "- Visualiser les données de `df_day`, en affichant moyenne, min, max et déviation standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# À la main\n",
    "charge_matrix_by_day = df[\"charge_id08\"].to_numpy().reshape(-1, 144)\n",
    "df_day = pd.DataFrame(charge_matrix_by_day)\n",
    "df_day.index.name = 'day'\n",
    "df_day.columns = df['time'].iloc[:144]\n",
    "\n",
    "# Ou bien de façon équivalente (avec multiindex directement)\n",
    "#df_day = df.pivot(index=['week','weekday'], columns=['time'], values='charge_id08')\n",
    "\n",
    "df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on se donne une date générique 01/01/2023 que l'on utilise pas dans la suite \n",
    "# c'est uniquement pour générer la séquence des 144 instants de la journée (toutes les 10 minutes)\n",
    "timesteps_day = np.arange('2023-01-01', '2023-01-02', \n",
    "                      np.timedelta64(10, 'm'), dtype='datetime64')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(timesteps_day, df_day.mean(axis=0), label=\"mean\")\n",
    "ax.fill_between(timesteps_day, df_day.min(axis=0), df_day.max(axis=0), alpha=0.2, label=\"min-max\")\n",
    "up = df_day.mean(axis=0) + df_day.std(axis=0)\n",
    "down = df_day.mean(axis=0) - df_day.std(axis=0)\n",
    "ax.fill_between(timesteps_day, down, up, alpha=0.2, label=\"standard deviation\")\n",
    "ax.legend()\n",
    "\n",
    "ax.xaxis.set_major_formatter(md.DateFormatter(\"%H:%M\"))\n",
    "\n",
    "ax.set_title(\"Variabilité des profils de charge par jour sur tout le dataset\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4\n",
    "\n",
    "#### Période: 1 semaine\n",
    "\n",
    "- À l'aide de la fonction `pd.MultiIndex.from_arrays` créer un multi-index pour `df_day` qui affiche le numéro de semaine et le numéro de jour de la semaine.\n",
    "\n",
    "- Créer un dataframe `df_week` avec les charges ordonnées par période d'une semaine à partir du dataframe `df_day` en utilisant les fonctions `stack` et `unstack`. Les colonnes de ce dataframe vont être les 144 intervals de 10 minutes qui donnent un jour, répétés 7 fois, une pour chaque jour de la semaine.\n",
    "\n",
    "- Visualiser les données de `df_week` comme fait précédemment pour `df_day`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.MultiIndex.from_arrays([df['week'][144*np.arange(648)], df['weekday'][144*np.arange(648)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On change les indexes de df_day pour prendre en compte les semaines\n",
    "df_day_index = pd.MultiIndex.from_arrays([df['week'][144*np.arange(648)], df['weekday'][144*np.arange(648)]],\n",
    "                                         names=('week', 'weekday'))\n",
    "df_day.index = df_day_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Columns names\", df_day.columns.names)\n",
    "print(\"Index names \", df_day.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On accède aux éléments de df_day par multi-index\n",
    "print(df_day.loc[(92,4)])\n",
    "# Ou bien par position\n",
    "print(df_day_index.get_loc((92,4)))\n",
    "print(df_day.iloc[df_day_index.get_loc((92,4))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day.stack().unstack([1,2]).sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# df_week est une nouvelle vue sur df_day \n",
    "df_week = df_day.stack().unstack([1,2]).sort_index(axis=1)\n",
    "df_week\n",
    "\n",
    "# Ou bien de façon équivalente\n",
    "#df_week = df.pivot(index=['week', 'weekday'], columns='time', values='charge_id08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "timesteps_week = np.arange('2023-01-01', '2023-01-08', \n",
    "                      np.timedelta64(10, 'm'), dtype='datetime64')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(timesteps_week, df_week.mean(axis=0), label=\"mean\")\n",
    "ax.fill_between(timesteps_week, df_week.min(axis=0), df_week.max(axis=0), alpha=0.2, label=\"min-max\")\n",
    "up = df_week.mean(axis=0) + df_week.std(axis=0)\n",
    "down = df_week.mean(axis=0) - df_week.std(axis=0)\n",
    "ax.fill_between(timesteps_week, down, up, alpha=0.2, label=\"standard deviation\")\n",
    "ax.legend()\n",
    "\n",
    "ax.xaxis.set_major_formatter(md.DateFormatter(\"%w\"))\n",
    "\n",
    "ax.set_title(\"Variabilité des profils de charge par semaine sur tout le dataset\")\n",
    "fig.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modélisation : prédiction niveau 0\n",
    "\n",
    "Une approche naïve consiste à utiliser comme prédicteur :\n",
    "- soit la charge moyenne par heure (prise sur tous les jours de l'année via le dataframe `df_day`) \n",
    "- soit la charge moyenne par heure et par type de jour (en utilisant la périodicité hebdomadaire de `df_week`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 5\n",
    "\n",
    "Créer un premier prédicteur naïf avec la moyenne par jour et la moyenne par semaine.\n",
    "\n",
    "- Créer un predicteur naïf avec la moyenne par heure sur l'ensemble du dataframe, et afficher l'erreur quadratique et l'erreur MAPE (erreur moyenne absolue en pourcentage)\n",
    "- Faire la même chose avec une période d'une semaine, en utilisant comme prédicteur la moyenne par heure et par type de jour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque* : Nous n'allons pas séparer les données en train set et test set, il s'agit juste de fournir un prédicteur naïf à comparer avec les suivants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Moyenne par heure\n",
    "lazy_day = df_day.mean(axis=0)\n",
    "# Différence avec la vraie valeur\n",
    "lazy_day_errors = df_day - lazy_day\n",
    "\n",
    "lazy_day_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(np.sqrt((lazy_day_errors**2).mean(axis=1)).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# RMSE et MAPE commises chaque jour\n",
    "RMSE_lazy_day = np.sqrt((lazy_day_errors**2).mean(axis=1)).reset_index(drop=True)\n",
    "MAPE_lazy_day = abs(lazy_day_errors / df_day).mean(axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "ax1.plot(df['day'].unique(),RMSE_lazy_day, label=\"RMSE (day)\")  \n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(df['day'].unique(),MAPE_lazy_day, label=\"MAPE (day)\")\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Moyenne par heure et par jour de la semaine\n",
    "lazy_week = df_week.mean(axis=0)\n",
    "# Différence avec la vraie valeur\n",
    "lazy_week_errors = df_week - lazy_week\n",
    "lazy_week_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# L'indice weekday est au level 0 ds les noms des colonnes\n",
    "lazy_week_errors.columns.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On revient à une structure par jour, pour calculer l'erreur \n",
    "# et comparer avec lazy_day_errors\n",
    "lazy_week_errors = lazy_week_errors.stack(level = 0)\n",
    "lazy_week_errors\n",
    "# pareil que \n",
    "# lazy_week_errors.stack().stack().unstack([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# RMSE et MAPE de chaque jour\n",
    "RMSE_lazy_week = np.sqrt((lazy_week_errors**2).mean(axis=1)).reset_index(drop=True)\n",
    "MAPE_lazy_week = abs(lazy_week_errors / df_week).mean(axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "ax1.plot(df['day'].unique(),RMSE_lazy_day, label=\"RMSE (day)\", linewidth=1)\n",
    "ax1.plot(df['day'].unique(),RMSE_lazy_week, label=\"RMSE (week)\", linewidth=1)\n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(df['day'].unique(),MAPE_lazy_day, label=\"MAPE (day)\", linewidth=1)\n",
    "ax2.plot(df['day'].unique(),MAPE_lazy_week, label=\"MAPE (week)\", linewidth=1)\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 6\n",
    "\n",
    "Faire une première analyse des résultats obtenus.\n",
    "\n",
    "1. Une modélisation *à la journée* est-t-elle judicieuse à votre avis ?\n",
    "\n",
    "2. Choisir de modéliser *à la semaine* plutôt qu'*à la journée* ne semble-t-il pas plus pertinent ? Pourquoi ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "source": [
    "1. Non ce n'est pas judicieux car les jours ont des comportements différents (typiquement le dimanche a un profil de courbe de charge très différent). \n",
    "\n",
    "2. Modéliser à la semaine est donc plus intéressant, puisque la périodicité des comportements est sur 7 jours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On vérifie également par les erreurs que l'approche par semaine marche mieux\n",
    "print(RMSE_lazy_day.mean())\n",
    "print(RMSE_lazy_week.mean())\n",
    "\n",
    "print(MAPE_lazy_day.mean())\n",
    "print(MAPE_lazy_week.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Modèle linéaire\n",
    "\n",
    "Pour mettre en oeuvre un modèle linéaire, plusieurs approches sont possibles. \n",
    "### Modèle sans périodicité\n",
    "\n",
    "Notons  $x_t$ pout $t=1,2,3,...,T$  la suite de  charges électriques observées, où l'indice $t$ fait référence à la plus ancienne observation et $x_T$ à la toute dernière.  L'interval de temps entre deux observations $x_t$ et $x_{t+1}$  est toujours de 10 minutes. \n",
    "\n",
    "Une première approche consiste à essayer de prédire la future consommation électrique en utilisant la consommation passée, à partir des $d$ observations qui précèdent l'instant actuel (nous appelons $d$ la profondeur de l'historique).\n",
    "Nous cherchons alors une fonction $f$ telle que\n",
    "\\begin{equation}\n",
    "x_{t+1} = f(x_{t-d+1}, x_{t-d+2}, ..., x_{t-1}, x_t) + \\varepsilon_{t+1},\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "où $\\varepsilon_{t+1}$ est un petit bruit aléatoire.\n",
    "\n",
    "\n",
    "![Série temporelle](img/timeSeries2.jpeg)\n",
    "\n",
    "Dans un modèle linéaire, on suppose que $f$ est une application linéaire de la forme\n",
    "\\begin{equation*}\n",
    "f(\\mathbf x) = \\mathbf x^\\top \\beta = x_{t-d+1}\\beta_1+ x_{t-d+2}\\beta_2+...+ x_{t-1}\\beta_{d-1}+x_{t}\\beta_{d},\n",
    "\\tag{2}\n",
    "\\end{equation*}\n",
    "où $\\mathbf x=(x_{t-d+1}, x_{t-d+2}, ..., x_{t-1}, x_t)^\\top$ et $\\beta\\in\\mathbb R^d$ est un vecteur de paramètres inconnus à estimer à partir des données.  \n",
    "\n",
    "*Remarque :* Nous pouvons bien sur ajouter un intercept $\\beta_0$ à la fonction $f$. \n",
    "\n",
    "Or, un tel modèle ne tient pas compte de la périodicité de la série temporelle. Il est fort probable que la dépendance de la consommation au milieu de la nuit des $d$ dernières observations ne soit pas du tout la même que celle de la consommation du matin ou à midi. Cela veut dire que dans le modèle (2) il n'y a pas de vecteur $\\beta$ qui donne des bonnes prédicitions quelque soit le moment de la journée (ou le jour de la semaine).\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle avec périodicité\n",
    "Pour prendre en compte une périodicité de durée $p$, nous pouvons opter pour un modèle qui cherche à exprimer la charge $x_{t+1}$ à l'instant $t+1$ en fonction des derniers instants modulo la période $p$. Par exemple, si la période $p$ est un jour et s'il est 13h30, nous allons alors chercher à exprimer $x_{t+1}$ en fonction de la charge observée les $d$ derniers jours toujours à 13h30. Si nous faisons l'hypothèse que la consommation dépend des $d$ dernières consommations à la même heure quelque soit l'heure, alors il convient d'utiliser le même $\\beta$. Autrement dit, nous considérons un modèle de la forme\n",
    "\\begin{equation*}\n",
    "x_{t+1} = f(x_{t+1-dp}, x_{t+1-(d-1)p}, ..., x_{t+1-p}) + \\varepsilon_{t+1}.\n",
    "\\tag{3}\n",
    "\\end{equation*}\n",
    "Dans ce modèle, il est possible de considérer n'importe quelle  périodicité (journalière ou hebdomadaire, par exemple). Remarquons que $p$ correspond au nombre de points d'observations dans une période, donc p.ex. $p=6*24=144$ pour une période d'un jour, ou bien $p=6*24*7=1008$ pour une période d'une semaine.\n",
    "\n",
    "![Série temporelle](img/timeSeries3.jpeg)\n",
    "\n",
    "\n",
    "Avec ce modèle, il sera également possible de prédire, au lieu qu'un seul point,  un nombre $\\ell$ de points, en supposant $\\ell\\leq p$ (nous allons très souvent prendre $\\ell=p$).\n",
    "Il suffit en effet de poser \n",
    "\\begin{equation*}\n",
    "v_{t+1} = \\begin{pmatrix}x_{t+1}\\\\ \\vdots \\\\ x_{t+\\ell} \\end{pmatrix}\n",
    "\\quad \\text{et} \\quad \n",
    "v_{t-j} = \\begin{pmatrix}x_{t+1 -(j+1)p}\\\\ \\vdots \\\\ x_{t+\\ell-(j+1)p} \\end{pmatrix}\n",
    "\\quad \\text{pour} \\quad\n",
    "0\\leq j \\leq d-1\n",
    "\\end{equation*}\n",
    "et nous obtenons\n",
    "$$v_{t+1} = \\beta_1 v_{t-d+1}  + \\ldots + \\beta_d v_t + \\tilde{\\varepsilon}_{t+1}$$\n",
    "\n",
    "où $\\tilde{\\varepsilon}_{t+1} = \\begin{pmatrix}\\varepsilon_{t+1}\\\\ \\vdots \\\\ \\varepsilon_{t+\\ell} \\end{pmatrix}$.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "#### Tableau de données d'entrainement $X$\n",
    "\n",
    "Il est clair que les observations les plus récentes sont les données les plus pertinentes pour entrainer le modèle, c'est-à-dire pour estimer $\\beta$. On peut alors considérer comme vecteur $\\mathbf y$ les $\\ell$ valeurs observées :\n",
    "$$\\mathbf y = (x_{t-\\ell+1},..., x_{t-1}, x_t)^\\top,$$\n",
    "où $t$ est l'instant actuel et donc la dernière valeur observée.\n",
    "\n",
    "Maintenant il faut construire la matrice $X$ correspondante. Pour chaque entrée de $\\mathbf y$ on choisit les observations qui ont \"généré\" cette observation selon le modèle en (3). \n",
    "\n",
    "Ainsi, la dernière ligne de $X$, qui correspond à l'observations $x_{t}$, est le vecteur\n",
    "$$x_{t -dp}, x_{t-(d-1)p}, x_{t-(d-2)p},..., x_{t-p}\n",
    "$$\n",
    "Plus généralement, la $\\ell-i$-ième ligne de $X$, associée à l'observations $x_{t-i+1}$, est le vecteur\n",
    "$$x_{t-i -dp}, x_{t-i-(d-1)p }, x_{t-i-(d-2)p },..., x_{t-i-p}$$\n",
    " \n",
    "\n",
    "\n",
    "![alternative text](img/timeSeries5bis.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 7\n",
    "\n",
    "Mettre en oeuvre un prédicteur linéaire pour prédire le jour $k+1$ à partir des $d$ jours précedents.\n",
    "\n",
    "- À l'aide de la fonction `LinearRegression` du module `sklearn.linear_model` faire une régression linéaire de la variable d'indice $k$ (qu'on renommera en `y_train`) sur les variables d'indice $k-1,\\dots k-d$ (qu'on renommera en `x_train`) avec le jeu `df_day`. \n",
    "- Ensuite, grâce à cette relation apprise, prédire la variable d'indice $k+1$ (renommée `y_test`) à partir des $d$ variables immédiatement précédentes(renommées `x_test`).\n",
    "- Comparer avec l'approche naïve, en affichant l'erreur quadratique et l'erreur MAPE au temps estimé $k+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "d = 4 # profondeur de l'historique (en jours ou bien en semaines)\n",
    "k = 80 # date limite de l'historique (compris entre d+1 et 648)\n",
    "# pour retrouver l'indice sous forme de paire (semaine observée, jour de la semaine)\n",
    "# on pourra utiliser l'appel df_day_index[k]\n",
    "\n",
    "y_train = df_day.loc[df_day_index[k]]\n",
    "x_train = df_day.loc[df_day_index[k-d:k]]\n",
    "\n",
    "y_test = df_day.loc[df_day_index[k+1]]\n",
    "x_test = df_day.loc[df_day_index[k-d+1:k+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_day.loc[df_day_index[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from scipy.stats import pearsonr \n",
    "\n",
    "# On prépare le modèle\n",
    "lr = LinearRegression()\n",
    "\n",
    "# On vérifie comment doivent être passées les données\n",
    "lr.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Les x_train et x_test doivent etre transposés\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On entraine le modèle\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On prédit et on calcule l'erreur commise\n",
    "pred_day = lr.predict(x_test)\n",
    "\n",
    "RMSE_linear_tplus1 = mean_squared_error(y_test,pred_day, squared=False)\n",
    "MAPE_linear_tplus1 = mean_absolute_percentage_error(y_test,pred_day)\n",
    "\n",
    "print(RMSE_linear_tplus1)\n",
    "print(MAPE_linear_tplus1)\n",
    "\n",
    "print(RMSE_lazy_day[k+1])\n",
    "print(MAPE_lazy_day[k+1])\n",
    "\n",
    "print(RMSE_lazy_week[k+1])\n",
    "print(MAPE_lazy_week[k+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(0,144),y_test, label=\"true value\")\n",
    "ax.plot(range(0,144),pred_day, label=\"linear regression prediction\")\n",
    "ax.plot(range(0,144),lazy_day.to_numpy(), label=\"lazy prediction\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 8\n",
    "\n",
    "Mettre en oeuvre un prédicteur linéaire pour prédire la semaine qui contient le jour $k+1$ à partir des $d$ semaines précedentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_index[k+1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "d=4\n",
    " \n",
    "# Indices de semaine et de jour de la semaine précedente du jour k+1\n",
    "t_week = df_day_index[k+1][0]-1\n",
    "t_day = df_day_index[k+1][1]\n",
    "\n",
    "y_train = df_week.loc[t_week]\n",
    "x_train = df_week.loc[t_week-d:t_week-1].T\n",
    "\n",
    "y_test = df_week.loc[t_week+1]\n",
    "x_test = df_week.loc[t_week-d+1:t_week].T\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "pred_week = lr.predict(x_test)\n",
    "\n",
    "pred_week = np.array(pred_week)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "pred_week_by_day = pred_week.reshape((-1,144), order='C')\n",
    "y_test_by_day = y_test.reshape((-1,144), order='C')\n",
    "\n",
    "pred_week_day = pred_week_by_day[t_day]\n",
    "y_test_day = y_test_by_day[t_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(0,144),y_test_day, label=\"true value\")\n",
    "ax.plot(range(0,144),pred_week_day, label=\"linear regression prediction by week\")\n",
    "ax.plot(range(0,144),pred_day, label=\"linear regression prediction by day\")\n",
    "ax.plot(range(0,144),lazy_day.to_numpy(), label=\"lazy prediction\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 9\n",
    "\n",
    "Comparer les erreurs RMSE et MAPE pour des 4 prédicteurs sur l'ensemble des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Comparer sur l'ensemble des données RMSE et MAPE\n",
    "pred_day_time = np.arange(d, df_day.shape[0]-1)\n",
    "\n",
    "RMSE_linear_day = []\n",
    "MAPE_linear_day = []\n",
    "for t_ in pred_day_time:\n",
    "    y_train = df_day.loc[df_day_index[t_]].to_numpy()\n",
    "    x_train = df_day.loc[df_day_index[t_-d:t_]].to_numpy().T\n",
    "\n",
    "    y_test = df_day.loc[df_day_index[t_+1]].to_numpy()\n",
    "    x_test = df_day.loc[df_day_index[t_-d+1:t_+1]].to_numpy().T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    pred = lr.predict(x_test)\n",
    "\n",
    "    RMSE_linear_day.append(mean_squared_error(y_test, pred, squared=False)) \n",
    "    MAPE_linear_day.append(mean_absolute_percentage_error(y_test, pred))\n",
    "    \n",
    "RMSE_linear_day = np.array(RMSE_linear_day)\n",
    "MAPE_linear_day = np.array(MAPE_linear_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# profondeur de l'historique EN SEMAINES\n",
    "d =4\n",
    "\n",
    "# Comparer sur l'ensemble des données RMSE et MAPE\n",
    "week_range = np.arange(d+1, df_week.shape[0]-2) #on ne prend pas les lignes avec données manquantes\n",
    "\n",
    "# On va prédire de la semaine d+2 à la semaine df_week.shape[0]-2\n",
    "\n",
    "RMSE_linear_week = []\n",
    "MAPE_linear_week = []\n",
    "\n",
    "for w_ in week_range: \n",
    "    y_train = df_week.loc[w_].to_numpy()\n",
    "    x_train = df_week.loc[w_-d:w_-1].to_numpy().T\n",
    "\n",
    "    y_test = df_week.loc[w_+1].to_numpy()\n",
    "    x_test = df_week.loc[w_-d+1:w_].to_numpy().T\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    pred = lr.predict(x_test)\n",
    "    \n",
    "    pred = np.array(pred)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    pred_by_day = pred.reshape((-1,144), order='C')\n",
    "    y_test_by_day = y_test.reshape((-1,144), order='C')\n",
    "    \n",
    "    for y_t,y_p in zip(y_test_by_day, pred_by_day) :\n",
    "        RMSE_linear_week.append(mean_squared_error(y_t, y_p, squared=False)) \n",
    "        MAPE_linear_week.append(mean_absolute_percentage_error(y_p, y_t))\n",
    "    \n",
    "RMSE_linear_week = np.array(RMSE_linear_week)\n",
    "MAPE_linear_week = np.array(MAPE_linear_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# convertir en t pour avoir le range pour les plots\n",
    "#first_week_index = df_week.loc[d+2:df_week.shape[0]-2].stack([0]).index[0]\n",
    "#last_week_index = df_week.loc[d+2:df_week.shape[0]-2].stack([0]).index[-1]\n",
    "\n",
    "#week_pred_range = np.arange(df_day_index.get_indexer([first_week_index]), df_day_index.get_indexer([last_week_index])+1)\n",
    "\n",
    "first_week_index = df_day_index.get_loc((d+2,0))\n",
    "last_week_index = df_day_index.get_loc((df_week.shape[0]-2,6))\n",
    "\n",
    "week_pred_range = np.arange(first_week_index, last_week_index+1)\n",
    "\n",
    "print(week_pred_range[0])\n",
    "print(week_pred_range[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "ax1.plot(RMSE_lazy_day, label=\"RMSE (day)\", linewidth=1)\n",
    "ax1.plot(RMSE_lazy_week, label=\"RMSE (week)\", linewidth=1)\n",
    "ax1.plot(pred_day_time, RMSE_linear_day, label=\"RMSE (linear day)\", linewidth=1)\n",
    "ax1.plot(week_pred_range, RMSE_linear_week, label=\"RMSE (linear week)\", linewidth=1)\n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(MAPE_lazy_day, label=\"MAPE (day)\", linewidth=1)\n",
    "ax2.plot(MAPE_lazy_week, label=\"MAPE (week)\", linewidth=1)\n",
    "ax2.plot(pred_day_time,MAPE_linear_day, label=\"MAPE (linear day)\", linewidth=1)\n",
    "ax2.plot(week_pred_range,MAPE_linear_week, label=\"MAPE (linear week)\", linewidth=1)\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(RMSE_linear_day.mean())\n",
    "print(RMSE_linear_week.mean())\n",
    "\n",
    "print(MAPE_linear_day.mean())\n",
    "print(MAPE_linear_week.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette approche n'utilise qu'une petite partie des données. Si on suppose que le modèle est relativement stable sur une plus longue période, on peut bien évidemment   ajuster $\\beta$ sur plus de données. Pour cela, on considère pour l'entrainement un vecteur $\\mathbf y$ plus long\n",
    "$$\\mathbf y = (x_t,x_{t-1}...,x_{t-m})^\\top,$$\n",
    "avec $m$ plus grand que $\\ell$ (qui était le nombre de valeurs à prédire).\n",
    "La matrice $X$ est construite de la même façon que précédemment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forêts aléatoires \n",
    "\n",
    "Dans cette partie, on va encore chercher le lien entre  la courbe d'indice $k$ et les courbes de charges précedentes $k-1,\\dots,k-d$. Mais cette fois, le lien entre ces variables sera appris par des arbres de décision ; plus précisémment, par des forêts aléatoires. \n",
    "\n",
    "### Exercice 10\n",
    "\n",
    "Vous allez à présent utiliser des forêts aléatoires via le module `RandomForestRegressor` de `sklearn.ensemble` pour apprendre un modèle prédictif pour le même problème et les mêmes données qu'avant. \n",
    "\n",
    "Explorez les paramètres de la fonction `RandomForestRegressor`.\n",
    "\n",
    "Procédez comme précédemment : \n",
    "- apprendre pour une semaine fixée $k$, avec un historique $d$, puis prédire la semaine $k+1$. Calculez différentes erreurs pour cette période.  \n",
    "- calculer les erreurs moyennes sur toutes les périodes disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Modelisation Random Forest\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Numero colonne du debut la periode d'apprentissage ==> K+1 à prévoir\n",
    "k = 60\n",
    "\n",
    "# Nombre de periodes passees : historique utilisé\n",
    "d = 4\n",
    "\n",
    "# Creation du modele\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100, # Nombre d'échantillons bootstrap et d'arbres\n",
    "    max_features=0.2, #  round(max_features * n_features) features are considered at each split (The default of 1.0 is equivalent to bagged trees)\n",
    "    max_depth=10,      # profondeur max de l'arbre\n",
    "    random_state=2,    # on règle une graine pour avoir tous les mêmes résultats\n",
    "    oob_score=True # Whether to use out-of-bag samples to estimate the generalization score. \n",
    ")\n",
    "\n",
    "y_train = df_day.loc[df_day_index[k]]\n",
    "x_train = df_day.loc[df_day_index[k-d:k]].T\n",
    "\n",
    "y_test = df_day.loc[df_day_index[k+1]]\n",
    "x_test = df_day.loc[df_day_index[k-d+1:k+1]].T\n",
    "\n",
    "nobs = y_test.shape[0]\n",
    "\n",
    "# On ajuste le modèle\n",
    "rf.fit(x_train, y_train)\n",
    "# On prédit la période suivante \n",
    "pred = rf.predict(x_test)\n",
    "\n",
    "print(pred.shape[0])\n",
    "\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "print(\"RMSE: %.4f\" % rmse)\n",
    "map1 = mean_absolute_percentage_error(pred, y_test)\n",
    "print(\"MAPE: %.4f\" % map1)\n",
    "cor = pearsonr(y_test, pred)\n",
    "print(\"Correlation observation/prevue: %.4f\" % cor[0])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, nobs, nobs)\n",
    "plt.plot(x, y_test, label=\"observation\", lw=2)\n",
    "plt.plot(x, pred, label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on a fait cela pour une période donnée, on systématise sur l'ensemble des périodes disponibles et on calcule les erreurs moyennes correspondantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Modelisation RF\n",
    "# Systematique\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Creation du modele\n",
    "rf = RandomForestRegressor(n_estimators=50, max_features=\"sqrt\", \n",
    "                           max_depth=3)\n",
    "\n",
    "RMSE_forest_day = []\n",
    "MAPE_forest_day = []\n",
    "for t_ in pred_day_time:\n",
    "    y_train = df_day.loc[df_day_index[t_]].to_numpy()\n",
    "    x_train = df_day.loc[df_day_index[t_-d:t_]].to_numpy().T\n",
    "\n",
    "    y_test = df_day.loc[df_day_index[t_+1]].to_numpy()\n",
    "    x_test = df_day.loc[df_day_index[t_-d+1:t_+1]].to_numpy().T\n",
    "    \n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    pred = rf.predict(x_test)\n",
    "    \n",
    "    RMSE_forest_day.append(mean_squared_error(y_test, pred, squared=False)) \n",
    "    MAPE_forest_day.append(mean_absolute_percentage_error(pred, y_test))\n",
    "    \n",
    "RMSE_forest_day = np.array(RMSE_forest_day)\n",
    "MAPE_forest_day = np.array(MAPE_forest_day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "\n",
    "ax1.plot(pred_day_time, RMSE_linear_day, label=\"RMSE (linear day)\", linewidth=1)\n",
    "ax1.plot(pred_day_time, RMSE_forest_day, label=\"RMSE (forest day)\", linewidth=1)\n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(pred_day_time,MAPE_linear_day, label=\"MAPE (linear day)\", linewidth=1)\n",
    "ax2.plot(pred_day_time,MAPE_forest_day, label=\"MAPE (forest day)\", linewidth=1)\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RMSE_linear_day.mean())\n",
    "print(RMSE_forest_day.mean())\n",
    "\n",
    "print(MAPE_linear_day.mean())\n",
    "print(MAPE_forest_day.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "RMSE_forest_week = []\n",
    "MAPE_forest_week = []\n",
    "\n",
    "for w_ in week_range: \n",
    "    y_train = df_week.loc[w_].to_numpy()\n",
    "    x_train = df_week.loc[w_-d:w_-1].to_numpy().T\n",
    "\n",
    "    y_test = df_week.loc[w_+1].to_numpy()\n",
    "    x_test = df_week.loc[w_-d+1:w_].to_numpy().T\n",
    "\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    pred = rf.predict(x_test)\n",
    "    \n",
    "    pred = np.array(pred)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    pred_by_day = pred.reshape((-1,144), order='C')\n",
    "    y_test_by_day = y_test.reshape((-1,144), order='C')\n",
    "    \n",
    "    for y_t,y_p in zip(y_test_by_day, pred_by_day) :\n",
    "        RMSE_forest_week.append(mean_squared_error(y_t, y_p, squared=False)) \n",
    "        MAPE_forest_week.append(mean_absolute_percentage_error(y_p, y_t))\n",
    "    \n",
    "RMSE_forest_week = np.array(RMSE_forest_week)\n",
    "MAPE_forest_week = np.array(MAPE_forest_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "first = 100 # has to be at least week_pred_range[0]\n",
    "last = 200 # at last week_pred_range[-1]\n",
    "\n",
    "first_w = np.where(week_pred_range == first)[0][0]\n",
    "last_w = np.where(week_pred_range == last)[0][0]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "ax1.plot(np.arange(first, last),RMSE_lazy_week[first:last], label=\"RMSE (week)\", linewidth=1)\n",
    "ax1.plot(week_pred_range[first_w:last_w], RMSE_linear_week[first_w:last_w], label=\"RMSE (linear week)\", linewidth=1)\n",
    "ax1.plot(week_pred_range[first_w:last_w], RMSE_forest_week[first_w:last_w], label=\"RMSE (forest week)\", linewidth=1)\n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(np.arange(first, last),MAPE_lazy_week[first:last], label=\"MAPE (week)\", linewidth=1)\n",
    "ax2.plot(week_pred_range[first_w:last_w],MAPE_linear_week[first_w:last_w], label=\"MAPE (linear week)\", linewidth=1)\n",
    "ax2.plot(week_pred_range[first_w:last_w],MAPE_forest_week[first_w:last_w], label=\"MAPE (forest week)\", linewidth=1)\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(RMSE_lazy_week.mean())\n",
    "print(RMSE_linear_week.mean())\n",
    "print(RMSE_forest_week.mean())\n",
    "\n",
    "print(MAPE_lazy_week.mean())\n",
    "print(MAPE_linear_week.mean())\n",
    "print(MAPE_forest_week.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Dans cette partie, à l'aide de la fonction ` GradientBoostingRegressor` du module ` sklearn.ensemble`,  vous allez utiliser le gradient boosting pour apprendre la relation entre une courbe de charge à une période $k$ fixée, et l'historique des $d$ courbes précédentes.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "### Exercice 11\n",
    "\n",
    "- Commencez par utiliser les paramètres par défaut de l'algorithme. \n",
    "- Entraînez le modèle pour une période $k$ fixée et faites la prédiction de la même façon que ci-dessus. En particulier, vous présenterez les mêmes graphiques et les mêmes calculs d'erreurs. \n",
    "- Choisissez les meilleurs paramètres de l'algorithme en utilisant la fonction `GridSearchCV`, pour essayer de diminuer les erreurs. \n",
    "- Enfin, évaluez la qualité de la méthode en utilisant toutes les valeurs de $k$ possibles (selon la longueur des données dont on dispose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GradientBoostingRegressor\n",
    "gb = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Réponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Modelisation avec Gradient Boosting\n",
    "\n",
    "# Choisir k numero de periode\n",
    "# Apprendre le lien Pk et son passe\n",
    "# Prevoir Pk+1\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Numero colonne du debut la periode d'apprentissage ==> K+1 à prévoir\n",
    "k = 60\n",
    "\n",
    "# Nombre de periodes passees : historique utilisé\n",
    "d = 4\n",
    "\n",
    "# Creation du modele\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "y_train = df_day.loc[df_day_index[k]]\n",
    "x_train = df_day.loc[df_day_index[k-d:k]].T\n",
    "\n",
    "y_test = df_day.loc[df_day_index[k+1]]\n",
    "x_test = df_day.loc[df_day_index[k-d+1:k+1]].T\n",
    "\n",
    "nobs = y_test.shape[0]\n",
    "\n",
    "# On ajuste le modèle\n",
    "gb.fit(x_train, y_train)\n",
    "# On prédit la période suivante \n",
    "pred = gb.predict(x_test)\n",
    "\n",
    "print(pred.shape[0])\n",
    "\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "print(\"RMSE: %.4f\" % rmse)\n",
    "map1 = mean_absolute_percentage_error(pred,y_test)\n",
    "print(\"MAPE: %.4f\" % map1)\n",
    "cor = pearsonr(y_test, pred)\n",
    "print(\"Correlation observation/prevue: %.4f\" % cor[0])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "x = np.linspace(1, nobs, nobs)\n",
    "plt.plot(x, y_test, label=\"observation\", lw=2)\n",
    "plt.plot(x, pred, label=\"prévision\", lw=2)\n",
    "plt.title('Courbes de charge', fontsize=18)\n",
    "plt.legend(fontsize=14, loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200],\n",
    "    'subsample' : [0.25,0.5,0.75,1],\n",
    "    'max_depth' : [2, 3, 4]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(gb, param_grid, cv=10)\n",
    "\n",
    "# On ajuste le modèle\n",
    "gbm.fit(x_train, y_train) # fit sur tout les jeux de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print('Les meilleurs paramètres sur la grille sont ', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "gbm.best_params_['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Creation du modele avec les paramètres optimaux\n",
    "gb = GradientBoostingRegressor(\n",
    "    learning_rate=gbm.best_params_['learning_rate'], \n",
    "    max_depth=gbm.best_params_['max_depth'],\n",
    "    n_estimators=gbm.best_params_['n_estimators'],\n",
    "    subsample=gbm.best_params_['subsample']\n",
    ")\n",
    "\n",
    "RMSE_gb_day = []\n",
    "MAPE_gb_day = []\n",
    "for t_ in pred_day_time:\n",
    "    y_train = df_day.loc[df_day_index[t_]]\n",
    "    x_train = df_day.loc[df_day_index[t_-d:t_]].T\n",
    "\n",
    "    y_test = df_day.loc[df_day_index[t_+1]]\n",
    "    x_test = df_day.loc[df_day_index[t_-d+1:t_+1]].T\n",
    "    \n",
    "    gb.fit(x_train, y_train) # fit sur tout les jeux de paramètres\n",
    "    \n",
    "    pred = gb.predict(x_test) # predit avec le meilleur jeu de params\n",
    "    \n",
    "    RMSE_gb_day.append(mean_squared_error(y_test, pred, squared=False)) \n",
    "    MAPE_gb_day.append(mean_absolute_percentage_error(pred, y_test))\n",
    "    \n",
    "RMSE_gb_day = np.array(RMSE_gb_day)\n",
    "MAPE_gb_day = np.array(MAPE_gb_day)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, layout=\"tight\")\n",
    "\n",
    "ax1.plot(pred_day_time, RMSE_linear_day, label=\"RMSE (linear day)\", linewidth=1)\n",
    "ax1.plot(pred_day_time, RMSE_forest_day, label=\"RMSE (forest day)\", linewidth=1)\n",
    "ax1.plot(pred_day_time, RMSE_gb_day, label=\"RMSE (gb day)\", linewidth=1)\n",
    "ax1.set_title(\"RMSE\")\n",
    "ax2.plot(pred_day_time,MAPE_linear_day, label=\"MAPE (linear day)\", linewidth=1)\n",
    "ax2.plot(pred_day_time,MAPE_forest_day, label=\"MAPE (forest day)\", linewidth=1)\n",
    "ax2.plot(pred_day_time, MAPE_gb_day, label=\"MAPE (gb day)\", linewidth=1)\n",
    "ax2.set_title(\"MAPE\")\n",
    "for ax in (ax1, ax2): ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(RMSE_linear_day.mean())\n",
    "print(RMSE_forest_day.mean())\n",
    "print(RMSE_gb_day.mean())\n",
    "\n",
    "print(MAPE_linear_day.mean())\n",
    "print(MAPE_forest_day.mean())\n",
    "print(MAPE_gb_day.mean())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
