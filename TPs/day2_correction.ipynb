{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff439a24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Prédiction de consommation électrique  avec `scikit-learn` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c7627-c31c-43b0-9888-8d3e29c886c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dans ce TP, nous allons étudier la consommation électrique en France métropole entre janvier 2016 et mai 2023, à partir des données provenant du réseau de transport d’électricité français (RTE), disponibles sur le site https://analysesetdonnees.rte-france.com/.\n",
    "\n",
    "Le fichier `data/data.csv` (ou `data/data.pkl`) a été obtenu en agrégeant les données contenues dans les fichiers suivants : \n",
    "- `rte.csv` : consommation d'électricité relevée toutes les demi-heures\n",
    "- `calendar.csv` : informations sur le temps\n",
    "- `meteo.csv` : informations liées à la météo, notamment l'emplacement des stations et les différents relevés (température, nébulosité, humidité, vitesse du vent, précipitation), pris toutes les 3 heures. \n",
    "\n",
    "Pour les détails sur la génération de ce fichier, voir le notebook `day2_preparation_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9f17a-c471-4870-826f-07555d22ddd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import des données\n",
    "\n",
    "Les données agrégées se trouvent dans le fichier `data/data.pkl`.\n",
    "\n",
    "- Importer les données sous forme d'un `DataFrame` pandas que l'on nomme `data`\n",
    "- Visualiser les premières et dernières lignes des données\n",
    "- Afficher la taille du `DataFrame`\n",
    "- Afficher les noms des premières 17 colonnes et ensuite des colonnes restantes\n",
    "- Faire de même pour le type de données présentes dans ces colonnes\n",
    "- Vérifier que le `DataFrame`ne contient pas de données manquantes\n",
    "- Convertir les variables `Mois`, `Jour`, `JourFerieType` en variables dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cbe5b5-6839-4a08-8ca9-5b35dc084c01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6913f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "path = 'data/'\n",
    "\n",
    "data = pd.read_pickle(path + \"data.pkl\")\n",
    "\n",
    "# A partir du .csv, il ne faut pas oublier de mettre la colonne DateTime au bon format\n",
    "#data = pd.read_csv(path + \"data.csv\")\n",
    "#data['DateTime'] = pd.to_datetime(data['DateTime']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4cd78e-8a88-4e22-b29c-56a3ecca5026",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d164eda-cec1-4bb5-aa59-929ddce754b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e14cfb-4b1c-436d-9e9a-846d2dfbbb9d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a46f2-591f-4798-904d-04b07e6e7e8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(data.columns[:17])\n",
    "print(data.columns[17:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670cbc9b-159a-4a8b-bc27-3ba86de59077",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(data[data.columns[:17]].dtypes)\n",
    "print(data[data.columns[17:]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa8885-e783-4b57-a434-b375e2e464f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data[data.columns[:17]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0752e0-218d-4148-a3cb-bac7c7d77638",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1c6cf-88b2-4057-abc9-640e74590da1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "moisCol = pd.get_dummies(data[['Mois']])\n",
    "jourCol = pd.get_dummies(data[['Jour']])\n",
    "jourFerieTypeCol = pd.get_dummies(data[['JourFerieType']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a1bb5-c0a6-4295-9fa1-f4670b1d77bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "data_with_dummies = pd.concat([data.drop(columns=['Mois', 'Jour', 'JourFerieType']), moisCol, jourCol, jourFerieTypeCol], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52c796a-075c-4cdb-bb78-a93fe4983c79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Analyse des données\n",
    "\n",
    "Observons le tableau `data` des données agregées.\n",
    "\n",
    "## Saisonnalité\n",
    "\n",
    "Afficher le graphe des consommations éléctriques en fonction du temps. Observez-vous une saisonnalité ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbae291-6b96-4c72-9819-8b0349edc926",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e5b1a-8b29-4ee6-8f90-bd299812463c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9606837-28a1-4f2c-b08c-ab92d799b912",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "## Descriptive Analysis\n",
    "\n",
    "# Plot the consumption time series\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data[\"DateTime\"], data[\"Consommation\"])\n",
    "plt.xlabel(\"DateTime\")\n",
    "plt.ylabel(\"Consommation\")\n",
    "plt.title(\"Consumption Time Series\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f131f-56b5-4d1b-a3af-2d005d2ae67f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "\n",
    "On remarque une saisonnalité, avec des plus fortes consommations en hiver et plus faibles en été, et une baisse des consommations, par rapport à la moyenne saisonnière, lors du printemps 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bd31a-a3ac-499f-844a-3af74492ddd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Profils de consommation\n",
    "\n",
    "Utiliser les fonctions `groupby` et `agg` de pandas pour regrouper les données en faisant la moyenne des consommations par mois, par jour, ou par demi-heure, de sorte à obtenir des profils de consommation annuel, hebdomadaire et journalier.\n",
    "\n",
    "Afficher ces différents profils à l'aide de la fonction `lineplot` de la librairie `seaborn` et les commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b663d3-234e-4708-818c-327e9b660bec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142eee03-1797-45f1-8cc2-fef7b307ea9e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "#### Profil de consommation annuel\n",
    "\n",
    "La moyenne des consommations à l'échelle des années montre des plus fortes consommations pendant les mois d'hiver et plus faibles pendant l'été."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a7285a-a038-4d93-82aa-376edc286d0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the annual average consumption \n",
    "monthly_avg = data.groupby([\"DemiHeure\", \"Mois\", \"MJour\"]).agg(Consommation=(\"Consommation\", \"mean\"), DateTime =(\"DateTime\" ,\"first\")).reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.lineplot(x=\"DateTime\", y=\"Consommation\", data=monthly_avg, hue=\"Mois\", legend=False) \n",
    "plt.xlabel(\"\") \n",
    "plt.ylabel(\"\")\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "plt.title(\"Average Consumption\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1c805-977b-48b8-93bd-59547f66fde0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "#### Profil de consommation hebdomadaire\n",
    "\n",
    "La moyenne des consommations sur les semaines montre un consommation similaire les jours ouvrés et une baisse des consommation les jours fériés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1be39a-43b0-4cbe-bac7-5230edf90388",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the Weekly average consumption\n",
    "weekly_avg = data.groupby([\"DemiHeure\", \"Jour\"]).agg(Consommation=(\"Consommation\", \"mean\"), DateTime =(\"DateTime\" ,\"first\")).reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax =  sns.lineplot(x=\"DateTime\", y=\"Consommation\", data=weekly_avg)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%a'))\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Weekly Average Consumption\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d9013-0f5c-4195-a2a3-e85a9349c9a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Profil de consommation journalier\n",
    "\n",
    "Les consommations journalières ont un creux entre 4h et 5h, montent jusqu'à un premier pic autour de midi, un deuxième entre 19h et 20H et un petit pic vers 22h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024f64c-02f6-4913-9cd5-b783be40807e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the Daily average consumption\n",
    "daily_avg = data.groupby([\"DemiHeure\"]).agg(Consommation=(\"Consommation\", \"mean\"), DateTime =(\"DateTime\" ,\"first\")).reset_index()\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.lineplot(x=\"DateTime\", y=\"Consommation\", data=daily_avg)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%l%p'))\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Daily Average Consumption\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba5e27-2ec7-41bc-a016-793f70087096",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Comportements particuliers\n",
    "\n",
    "Il est possible de mettre en évidence des petites anomalies dues au jours fériés ou au printemps 2020. \n",
    "\n",
    "- Afficher la consommation du mois de mai 2017, en mettant en évidence les jours féries\n",
    "- Afficher le profil de consommation journalier par jour de la semaine\n",
    "- Comparer la consommation moyenne de l'année 2020 à celle du reste des données et affi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f37747b-b941-4ebc-8536-8e4c637c9514",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a57b4-f60d-4623-bd16-0a1387237384",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the consumption for May 2017\n",
    "may_2017_data = data[(data['Annee'] == 2017) & (data['Mois'] == 'mai')]\n",
    "may_2017_ferie = may_2017_data[may_2017_data['JourFerie'] == 1]\n",
    "may_2017_ferie['MJour'].unique()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(may_2017_data['DateTime'], may_2017_data['Consommation'], color='blue')\n",
    "for i in may_2017_ferie['MJour'].unique():\n",
    "    plt.plot(may_2017_ferie[may_2017_ferie['MJour'] == i]['DateTime'], may_2017_ferie[may_2017_ferie['MJour'] == i]['Consommation'], color='black')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Consumption in May 2017')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b40204-c32f-4dff-baf1-efd2a1a1e3f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Observe the consumption depending on the type of day\n",
    "viz = data.groupby([\"DemiHeure\", \"Jour\"]).agg(Consommation=(\"Consommation\", \"mean\"), DateTime =(\"DateTime\" ,\"first\")).reset_index()\n",
    "viz['DateTime'] = viz['DateTime'].apply(lambda x: x.replace(day=1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.lineplot(x='DateTime', y='Consommation', hue='Jour', data=viz)\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%l%p'))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Consumption Depending on the Type of Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27699e4-d89f-4cc5-a3ad-7b154aa0f785",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Observe the consumption during the COVID lockdown\n",
    "data_grouped_2020 = data.groupby(['is.2020', \"MJour\",\"Mois\"]).agg(Consommation=(\"Consommation\", \"mean\"), DateTime =(\"DateTime\" ,\"first\")).reset_index()\n",
    "\n",
    "data_grouped_2020['DateTime'] = data_grouped_2020['DateTime'].apply(lambda x: x.replace(year=2000))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.lineplot(x='DateTime', y='Consommation', hue='is.2020', data=data_grouped_2020, palette=['blue', 'black'], legend=False)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Consumption During COVID Lockdown')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e68f0e2-f668-42bc-a8c2-798a6a3ba4b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Modèles : entraînement, prédiction et erreur "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3a2c3-041b-487b-9740-32833b112ea8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Séparation du jeu de données en train et test\n",
    "\n",
    "Séparer le jeu de données en deux pour obtenir le jeu d'entraînement et le jeu de test tels que \n",
    "\n",
    "- `X_train` et `Y_train` contiennent 50% du jeu de données pour l'apprentissage du modèle  \n",
    "- `X_test` et `Y_test` contiennent les 50% restants pour le test.\n",
    "\n",
    "On pourra utiliser la  fonction `train_test_split` du module `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6214d13-c7f8-4db3-9070-80229331e848",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634b5bc-5e7d-4735-aafc-25a94c04d061",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_with_dummies.drop(columns=['DateTime', 'Consommation']), data_with_dummies['Consommation'], test_size=0.5, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c053ee-3d07-49b2-a577-0ac5ddae9e07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a10e0-57e2-492e-982c-954c7e7439a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Naive predictor\n",
    "\n",
    "Construire un prédicteur naïf qui renvoie la moyenne des consommations (une constante) et calculer l'erreur MAPE et l'erreur RMSE de ce prédicteur sur le jeu de test et sur celui de train.\n",
    "\n",
    "Ce prédicteur trivial représente le point de départ pour comparer les autres modèles.\n",
    "\n",
    "- Stocker les erreurs MAPE et RMSE sur le jeu de train et le jeu de test du modèle naïf dans un DataFrame `df_errors`.\n",
    "\n",
    "Pour rappel, si $\\hat Y_t$ est la valeur prédite par le modèle et $Y_t$ la consommation réalisée :\n",
    "\n",
    "MAPE = **mean absolute percentage error** : c'est une erreur de prédiction *relative*:\n",
    "$${\\displaystyle {\\mbox{MAPE}}={\\frac {1}{n}}\\sum _{t=1}^{n}\\left|{\\frac {Y_{t}-\\hat Y_{t}}{Y_{t}}}\\right|}\n",
    "$$\n",
    "En pratique, on préfère diviser par $|Y_{t}+\\varepsilon|$ pour éviter des division par zéro.\n",
    "\n",
    "RMSE = **root mean squared error** : c'est une erreur de prédiction *absolue*, sensible aux outliers:\n",
    "$${\\displaystyle {\\mbox{RMSE}}=\\sqrt{\\frac 1 n \\sum _{t=1}^{n}\\left(Y_{t}-\\hat Y_{t}\\right)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6165dac-ba39-4ef0-9e8d-a2d4d3d74dbd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "On pourra utiliser les fonctions `mean_absolute_percentage_error` et `root_mean_squared_error` du module `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d186b-4e46-449f-8566-9c0f7a0cf341",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21642bb9-d6d4-434d-83e2-00f536029f29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import root_mean_squared_error as rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3bd90-861e-49e5-b5f2-ac316f793078",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Naive predictor\n",
    "predict_naive_test = np.repeat(Y_train.values.mean(),len(Y_test), axis = 0)\n",
    "predict_naive_train = np.repeat(Y_train.values.mean(),len(Y_train), axis = 0)\n",
    "\n",
    "mape_test = mape(Y_test, predict_naive_test)*100\n",
    "mape_train = mape(Y_train, predict_naive_train)*100\n",
    "\n",
    "rmse_test = rmse(Y_test, predict_naive_test)\n",
    "rmse_train = rmse(Y_train, predict_naive_train)\n",
    "\n",
    "print('On train set\\n')\n",
    "print(f'The MAPE in naive prediction with mean is {mape_train:.2f}%.')\n",
    "print(f'The RMSE in naive prediction with mean is {rmse_train:.2f}.')\n",
    "print('\\nOn test set\\n')\n",
    "print(f'The MAPE in naive prediction with mean is {mape_test:.2f}%.')\n",
    "print(f'The RMSE in naive prediction with mean is {rmse_test:.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae4ed0d-8036-42ac-bb1a-823e9ebe7cd3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# stocker les résultats\n",
    "d = {'Model': 'naive (mean)', \n",
    "     'MAPE test': mape_test, \n",
    "     'RMSE test': rmse_test, \n",
    "     'MAPE train': mape_train, \n",
    "     'RMSE train': rmse_train\n",
    "     }\n",
    "df_errors = pd.DataFrame(data=[d])\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2837339-956b-49da-a26b-fb54a702251e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6931a-7eae-4f1c-9a95-977c5c3fe329",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Tous les modèles de régression de la librairie scikit-learn ont une méthode `fit` qui permet d'entraîner le modèle et une méthode `predict` qui calcule la valeur prédite.\n",
    "\n",
    "Nous allons comparer plusieurs méthodes et pour cela il sera utile de définir une fonction `fit_and_predict_error` qui, étant donné un modèle `model`, et un jeu de données `x_train`,`y_train`, `x_test`, `y_test`, entraîne le modèle en appelant la méthode `fit` du modèle sur le jeu d'entraînement, calcule la prédiction en appelant la méthode `predict` du modèle à la fois sur le jeu de test et sur le jeu de train, et calcule les erreurs MAPE et RMSE sur les 2 jeux.\n",
    "\n",
    "Cette fonction renvoie un dictionnaire contenant les prédictions calculées, `train` et `test`, et les erreurs MAPE et RMSE pour les jeux de train et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef02cdb-daa3-4417-b503-f3d2f729b353",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0b6b8-0de1-4658-9f28-776723e98186",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import time as tm\n",
    "\n",
    "def fit_and_predict_error(model, x_train, y_train, x_test, y_test):\n",
    "    start_time = tm.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    predict_train = model.predict(x_train)\n",
    "    predict_test = model.predict(x_test)\n",
    "    end_time = tm.time()\n",
    "\n",
    "    mape_test = mape(y_test, predict_test)*100\n",
    "    rmse_test = rmse(y_test, predict_test)\n",
    "    \n",
    "    print('\\nOn test set\\n')\n",
    "    print(f'The MAPE is {mape_test:.2f}%.')\n",
    "    print(f'The RMSE is {rmse_test:.2f}.')\n",
    "    \n",
    "    return {'train' : predict_train, 'test' : predict_test, \n",
    "            'mape_train' : mape(y_train, predict_train)*100,\n",
    "            'mape_test' : mape_test,\n",
    "            'rmse_train' : rmse(y_train, predict_train), \n",
    "            'rmse_test' : rmse_test, \n",
    "            'time' : end_time-start_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8845c284-3f07-4c1c-883b-6504424dd6b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Pour stocker l'information sur les erreurs dans le tableau des erreurs `df_errors`, nous définissons également une fonction qui permet de le faire rapidement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629538f9-ab59-4781-81dd-9e117a4419e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_error(model_out, model_name, df):\n",
    "    return df._append({'Model' : model_name, \n",
    "                  'MAPE test' : model_out['mape_test'], \n",
    "                  'RMSE test' : model_out['rmse_test'], \n",
    "                  'MAPE train' : model_out['mape_train'], \n",
    "                  'RMSE train' : model_out['rmse_train'], \n",
    "                  'CPU time' : model_out['time']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3894f7-b9a9-4f2c-af01-4b78e1eaa8b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Regression linéaire\n",
    "\n",
    "Nous allons en première approche utiliser des modèles linéaires pour apprendre et prévoir les données de consommation.  \n",
    "\n",
    "- A l'aide de la librairie `sklearn.linear_model`, mettre en place plusieurs modèles de regression linéaire pour prédire la variable `Consommation` en fonction des caractéristiques suivantes : \n",
    "    1. `Temperature`\n",
    "    2. Données méteo\n",
    "    3. Données méteo et `PositionDansAnnee`, `JourFerie`, `DemiHeure`\n",
    "    4. Les caractéristiques ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation', 'PositionDansAnnee', 'DemiHeure', 'JourFerie',  'Vacances', 'MJour', 'Annee', 'is.2020']\n",
    "    5. Toutes les caractéristiques\n",
    "\n",
    "- Lequel de ces modèles donne les meilleurs résultats ? \n",
    "\n",
    "- Afficher, pour les modèles naïf, 1, 4 et 5, la consommation réelle et la consommation prédite sur les données complètes, sur un même graphe (il y a donc 4 graphes, un par modèle). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3746ab34-4579-4a64-95cf-fca8d3427d35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd136b-5dc2-402d-8f4f-b4ed81b16d2b",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610f929-3924-42a9-9772-d1bdc4c297e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "##### Model\n",
    "linear_pipe = make_pipeline(StandardScaler(), LinearRegression(fit_intercept=True))\n",
    "\n",
    "# Model 1 : Linear regression on temperature\n",
    "linear_temp = fit_and_predict_error(linear_pipe, X_train[['Temperature']], Y_train, X_test[['Temperature']], Y_test)\n",
    "complete_linear_temp = linear_pipe.predict(data[['Temperature']])\n",
    "df_errors = add_error(linear_temp, 'Linear on Temperature', df_errors)\n",
    "\n",
    "# Model 2 : Linear regression on meteo features\n",
    "meteo_features = ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation']\n",
    "linear_meteo = fit_and_predict_error(linear_pipe, X_train[meteo_features], Y_train, X_test[meteo_features], Y_test)\n",
    "complete_linear_meteo = linear_pipe.predict(data[meteo_features])\n",
    "df_errors = add_error(linear_meteo, 'Linear on Meteo', df_errors)\n",
    "\n",
    "# Model 3 : Linear regression on meteo features and calendar\n",
    "meteo_cal_features = ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation','PositionDansAnnee', 'JourFerie', 'DemiHeure']\n",
    "linear_meteo_cal = fit_and_predict_error(linear_pipe, X_train[meteo_cal_features], Y_train, X_test[meteo_cal_features], Y_test)\n",
    "complete_linear_meteo_cal = linear_pipe.predict(data[meteo_cal_features])\n",
    "df_errors = add_error(linear_meteo_cal, 'Linear on Meteo and Cal', df_errors)\n",
    "\n",
    "# Model 4 : Linear regression on small\n",
    "features = ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation', 'PositionDansAnnee', 'DemiHeure', 'JourFerie',  'Vacances', 'MJour', 'Annee', 'is.2020']\n",
    "linear_small = fit_and_predict_error(linear_pipe, X_train[features], Y_train, X_test[features], Y_test)\n",
    "complete_linear_small = linear_pipe.predict(data[features])\n",
    "df_errors = add_error(linear_small, 'Linear S', df_errors)\n",
    "\n",
    "# Model 5 : Linear regression on large\n",
    "linear_large = fit_and_predict_error(linear_pipe, X_train, Y_train, X_test, Y_test)\n",
    "complete_linear_large = linear_pipe.predict(data_with_dummies.drop(columns = ['DateTime', 'Consommation']))\n",
    "df_errors = add_error(linear_large, 'Linear L', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb231124-1c7e-4c95-ba78-1597f096b0d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83017d-4207-4314-b4aa-66117892ed99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# On peut varier le mois du 01 au 04\n",
    "time = data[data['DateTime'] > pd.Timestamp(\"2023-03-01 00:00\", tz='UTC')]['DateTime']\n",
    "index = data['Consommation'].size-time.size\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(12,8), sharey=True)\n",
    "for ax in axs.flat:\n",
    "    ax.plot(time, data[index:]['Consommation'], label='Consommation', color='blue') \n",
    "axs.flat[0].plot(time, np.repeat(Y_train.mean(),len(time), axis = 0), label='Prevision naive', color='black')\n",
    "axs.flat[1].plot(time, complete_linear_temp[index:], label='Prevision temperature', color='red')\n",
    "axs.flat[2].plot(time, complete_linear_small[index:], label='Prevision small', color='green')\n",
    "axs.flat[3].plot(time, complete_linear_large[index:], label='Prevision large', color='orange')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\n",
    "    ax.legend() \n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.suptitle(\"Linear regression\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbdf8a1-f7d8-443d-9204-f3532a48364a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nous allons dorenavant travailler uniquement sur deux ensembles de caractéristiques :\n",
    "- Les caractéristiques réduites  :  ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation', 'PositionDansAnnee', 'DemiHeure', 'JourFerie', 'Vacances', 'MJour', 'Annee', 'is.2020']\n",
    "- Les caractéristiques complètes\n",
    "\n",
    "Créer deux jeux de données d'entrainement (et de test) `X_train_S` et `X_train_L` (respectivement `X_test_S` et `X_test_L`) correspondants à ces deux ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612b95c-0a9e-4dc6-957a-b54448d87264",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5aec3-0194-49dd-bd60-3e0cb357ae62",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "X_train_S = X_train[features]\n",
    "X_train_L = X_train\n",
    "\n",
    "X_test_S = X_test[features]\n",
    "X_test_L = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78837329-6e17-4720-bb7d-4ceb59677d35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lasso and Ridge regression\n",
    "\n",
    "Essayons d'améliorer les performances en ajoutant une pénalité $\\ell_1$ et une pénalité $\\ell_2$ à la regression linéaire. \n",
    "\n",
    "A l'aide des modules `LassoCV` et `RidgeCV` mettre en place deux estimateurs sur les données réduites et sur les données complètes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd16fcf-b7a8-4183-8fd9-a0b4966e243c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a26ec2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "\n",
    "# LASSO\n",
    "#=========\n",
    "\n",
    "# Model Small : Lasso regression on reduced data\n",
    "lasso_pipe_S = make_pipeline(StandardScaler(), LassoCV())\n",
    "lasso_small = fit_and_predict_error(lasso_pipe_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(lasso_small, 'Lasso S', df_errors)\n",
    "\n",
    "# Model Large : Lasso regression on complete data\n",
    "lasso_pipe_L = make_pipeline(StandardScaler(), LassoCV())\n",
    "lasso_large = fit_and_predict_error(lasso_pipe_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(lasso_large, 'Lasso L', df_errors)\n",
    "\n",
    "# RIDGE\n",
    "#=========\n",
    "\n",
    "# Model Small : Ridge regression on reduced data\n",
    "ridge_pipe_S = make_pipeline(StandardScaler(), RidgeCV())\n",
    "ridge_small = fit_and_predict_error(ridge_pipe_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(ridge_small, 'Ridge S', df_errors)\n",
    "\n",
    "# Model Small : Ridge regression complete data\n",
    "ridge_pipe_L = make_pipeline(StandardScaler(), RidgeCV())\n",
    "ridge_large = fit_and_predict_error(ridge_pipe_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(ridge_large, 'Ridge L', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888d2a1-e5a8-4545-a34a-3e8cd9f364bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07656d7-8ba0-4163-a2f6-2777d96798ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors = df_errors.drop(index=[1,2,3,5,6,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c723cec-5aaf-45fe-9f0a-fed055a1b876",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30390bf-26ea-48a4-9e84-fa1cd6636233",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Arbres de décision -- CART\n",
    "\n",
    "Les *Classification and Regression Trees* (CART) permettent de prédire la consommation en suivant des simples règles de décision qui dépendent des caractéristiques observées.\n",
    "\n",
    "Le choix du nombres et du type de caractéristiques utilisées pour construire un arbre, ainsi que sa profondeur influent énormément sur le résultat, les paramètres à indiquer dans sa construction sont à choisir attentivement. \n",
    "\n",
    "A noter que dans un contexte d'arbres de décision la normalisation des caractéristiques n'est pas nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d5ac1-6472-4ec9-870f-78e0d854d9bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Default\n",
    "\n",
    "Utiliser la classe `DecisionTreeRegressor` du module `sklearn.tree` pour construire un estimateur basé sur un arbre de décision.\n",
    "\n",
    "- Utiliser initialement les paramètres par défaut.\n",
    "\n",
    "- Entraîner le modèle sur les données réduites et sur les données complètes.\n",
    "\n",
    "- Afficher les erreurs. Que remarque-t-on sur les erreurs calculées sur le train set ? Comment le justifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5015821-1393-45b7-93c2-457bda7a21d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6346d9-ac0b-4943-a752-c6fdfe58740b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f611d2-e02b-42a0-a29d-02f9ee44ddd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cart_S = DecisionTreeRegressor()\n",
    "\n",
    "cart_small = fit_and_predict_error(cart_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(cart_small, 'Default Cart S', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f4193-35cc-42f2-8589-ac5a22312921",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cart_L = DecisionTreeRegressor()\n",
    "\n",
    "cart_large = fit_and_predict_error(cart_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(cart_large, 'Default Cart L', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bc9f3-e30d-4ada-8bb6-001f2a42f7e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4310e-b026-43c7-a6ae-6c6753495f15",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Dans l'appel à la documentation `?cart` on trouve la valeur par défaut\n",
    "\n",
    ">max_depth : int, default=None\n",
    "    The maximum depth of the tree. If None, then nodes are expanded until\n",
    "    all leaves are pure or until all leaves contain less than\n",
    "    min_samples_split samples.\n",
    "\n",
    "qui signifie que l'arbre est développé jusqu'à quand toutes les feuilles sont pures. Donc sur le train la prédiction est exacte, car l'arbre permet de reconstruire exactement les consommation à partir des données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3f763-7ba2-4441-b90c-61a2431b67df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Réduction de profondeur\n",
    "\n",
    "Retrouver dans la documentation les valeurs par défaut des paramètres d'un arbre de régression suivants :\n",
    "\n",
    "- max_depth\n",
    "- min_samples_leaf\n",
    "- max_features\n",
    "  \n",
    "Quelle est la profondeur de l'arbre construit par défaut ? \n",
    "\n",
    "Construire un arbre de profondeur 10 et comparer les erreurs avec les modèles précédents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb7d0f-c78a-4c7b-9634-ccba399b43db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df29d29-2bd3-4b8d-ad8f-4b9ada69c90c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print('Depth', cart_S.get_depth())  \n",
    "\n",
    "feature_importance = cart_S.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "X_train_S.columns[sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9603c59-b49e-4fad-9f9f-93224470de69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cart = DecisionTreeRegressor(max_depth = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabbfecf-ed73-4bc9-b317-2e8724b2a479",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cart_10_small = fit_and_predict_error(cart, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(cart_10_small, 'Cart depth 10 S', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027db4d0-627c-4c84-b622-d9176e23e6ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cart_10_large = fit_and_predict_error(cart, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(cart_10_large, 'Cart depth 10 L', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c51b67-e222-4ba1-8e96-43ca58d2cf7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417788b1-30ae-42a6-84a2-7b89e6fe3966",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Pourquoi l'arbre par défaut n'a pas un nombre de feuilles = len(X_train)? Pas parce qu'il y a des lignes pareilles.\n",
    "np.sum(X_train_S.duplicated())\n",
    "print('Number of leaves', cart_S.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8864010-7d34-4dae-a4d4-7019f39866d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Visualisation\n",
    "\n",
    "- Construire un arbre de profondeur 4 et l'entraîner sur les données complètes\n",
    "- A l'aide de la fonction `plot_tree` du module `tree` de sklearn, visualiser l'arbre de décision.\n",
    "\n",
    "- Quelles sont les caractéristiques sur lesquelles sont fait les splits de cet arbre ? \n",
    "- Combien de noeuds a cet arbre ? Combien d'observations y a-t-il dans chaque noeud ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2b998-281c-4684-8b89-4d52fa204f1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90fe64-6dc1-4018-8325-ccae4ef51139",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cart.max_depth = 4\n",
    "cart.fit(X_train_L, Y_train)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(cart, fontsize=10, feature_names=X_train_L.columns.values)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd677fe-0767-493e-b3f9-11e87ec70d9c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(cart.tree_.n_node_samples) # nb d'observations dans chaque noeud\n",
    "print(cart.tree_.node_count) # nb de noeuds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8d2e6-a924-4181-b8ba-66af04ed3664",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf025c8-b1c4-416e-a1f9-d97e81a76c51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Le bagging (ou agrégation Bootstrap) est un type d'apprentissage d'ensemble dans lequel plusieurs modèles de base sont entrainés indépendamment et en parallèle sur différents sous-ensembles des données d'entraînement. Dans le bagging, les étapes d'entraînement et de prédiction sont précédées par une étape de bootstrap.\n",
    "\n",
    "1. **Échantillonnage bootstrap** : Dans l'échantillonnage bootstrap, $K$ sous-ensembles aléatoires des données originales sont échantillonnés avec remplacement. Cette étape garantit que les modèles de base sont formés sur divers sous-ensembles des données, car certains échantillons peuvent apparaître plusieurs fois dans le nouveau sous-ensemble, tandis que d'autres peuvent être omis. Cela réduit les risques de surajustement et améliore la précision du modèle.\n",
    "\n",
    "2. **Entraînement sur les modèles de base** : Après la première étape d'échantillonnage bootstrap, le modèle de base (arbres de décision, SVM...) est entraîné indépendamment sur chaque sous-ensemble de données bootstrap différent. Ces modèles de base sont généralement dits « faibles » car ils peuvent ne pas être très précis à eux seuls. \n",
    "\n",
    "3. **Agrégation** : Une fois que tous les modèles de base ont été entraînés, ils sont utilisé pour faire chacun une prédiction sur les données de test. Dans les modèles de classification, la prédiction finale est effectuée en agrégeant les prédictions des modèles de base en utilisant le vote majoritaire. Dans les modèles de régression, la prédiction finale est obtenue en faisant la moyenne des prédictions des modèles de base.\n",
    "\n",
    "**Évaluation Out-of-Bag (OOB)** : Dans l'étape d'échantillonage, certaines observations sont exclues de l'échantillon boostrap. Ces observations *out-of-bag* peuvent être utilisées pour évaluer les performances du modèle.\n",
    "\n",
    "![Classificateur par agrégation bootstrap](img/Bagging-classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfedea9-4cf4-43ff-a86f-ff1b1c7b5bdf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Les arbres de décision vus au point précédent sont extrêmement dépendant du training set. Les modèles de bagging, grâce à l'étape d'échantillonnage aléatoire, permettent de réduire cette sensibilité aux données d'entraînement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3c1ad-af63-42e4-8c92-ac3f3663547d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Bagging à la main\n",
    "\n",
    "Ecrire un bagging à la main de taille `K=100` *sur les données réduites* en suivant les étapes suivantes :\n",
    "\n",
    "1. Créer K échantillons boostrap de même taille que l'échantillon d'entraînement :\n",
    "    - Utiliser la fonction `np.random.choice` avec paramètre `replace=True` pour générer un tableau d'indices `indexes` de même taille que l'échantillon original\n",
    "    - Un échantillon booststrap est donné par `X_train_S[indexes]`\n",
    "2. Entraîner un arbre de décision simple (peu profond, avec un nombre d'observations minimal par feuille, ...) sur chaque échantillon bootstrap\n",
    "3. Calculer la valeur prédite par bagging :\n",
    "      - Calculer la prédiction de chaque arbre\n",
    "      - Renvoyer la moyenne des valeurs prédites par les K arbres\n",
    "4. Calculer et afficher les erreurs MAPE et RMSE *out-of-bag*. \n",
    "\n",
    "Une fois le modèle sur les données réduites maîtrisé, il est possible de passer sur les données complètes, tout en tenant compte des temps de calculs attendus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbc74c-df96-41d0-bc90-450e1976ceac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57dd05-190f-4dde-bc45-513aec04bb36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print('Temps attendu sur données réduites : ', 0.5*100/60, 'm')\n",
    "print('Temps attendu sur données complètes : ', 7.5*100/60, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f49d9-9ed1-4501-b529-157d3a30903c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# 100 Regression Trees on Bootstrap Samples\n",
    "K = 100\n",
    "n_train = len(X_train_S) # ou X_train_S.shape[0]\n",
    "n_test = len(X_test_S) \n",
    "pred_train = np.zeros((n_train, K))\n",
    "pred_test = np.zeros((n_test, K))\n",
    "indexes = np.zeros((n_train, K))\n",
    "pred_oob = []\n",
    "\n",
    "cart.max_depth = 10\n",
    "\n",
    "dict_train = {}\n",
    "dict_oob = {}\n",
    "\n",
    "for i in range(n_train):\n",
    "    dict_train[i] = []\n",
    "    dict_oob[i] = []\n",
    "\n",
    "for k in range(K):\n",
    "    indexes = np.random.choice(n_train, n_train, replace=True)\n",
    "    cart.fit(X_train_S.iloc[indexes], Y_train.iloc[indexes])\n",
    "    pred = cart.predict(X_train_S)\n",
    "    \n",
    "    for i in range(n_train):\n",
    "        if i in indexes:\n",
    "            dict_train[i].append(pred[i])\n",
    "        else:\n",
    "            dict_oob[i].append(pred[i])\n",
    "    \n",
    "    pred_test[:, k] = cart.predict(X_test_S)\n",
    "\n",
    "pred_test_mean = pred_test.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c7727-ff9c-44f7-b555-1586c148ff60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "pred_train_mean = np.array([np.mean(dict_train[i]) for i in range(n_train)]) # valeur prédite sur les données du train\n",
    "pred_oob_mean = np.array([np.mean(dict_oob[i]) for i in range(n_train)]) # valeur prédite sur les données oob\n",
    "\n",
    "print(mape(pred_oob_mean, Y_train)*100)\n",
    "print(rmse(pred_oob_mean, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2e53a-fff7-42e2-b153-0cf3da75ba44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors = df_errors._append({'Model' : 'Manual Bagging depth  10 S', \n",
    "                  'MAPE test' : mape(pred_test_mean, Y_test)*100, \n",
    "                  'RMSE test' : rmse(pred_test_mean, Y_test), \n",
    "                  'MAPE train' : mape(pred_train_mean, Y_train)*100, \n",
    "                  'RMSE train' : rmse(pred_train_mean, Y_train), }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29b618-3ae9-4452-94b3-8206c4bbd3ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433552b-99cc-43ab-972c-09e66d0fba01",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors = df_errors._append({'Model' : 'Manual Bagging depth  10 S', \n",
    "                  'MAPE test' : mape(pred_test_mean, Y_test)*100, \n",
    "                  'RMSE test' : rmse(pred_test_mean, Y_test), \n",
    "                  'MAPE train' : mape(pred_train_mean, Y_train)*100, \n",
    "                  'RMSE train' : rmse(pred_train_mean, Y_train), }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9386d3-9ced-409d-a041-1550f819de45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc12333-935d-45c0-9986-4bcbb7845e64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Bagging de sklearn\n",
    "\n",
    "- Comparer avec un bagging construit en utilisant la fonction `BaggingRegressor` du module `sklearn.ensemble`.\n",
    "- Afficher le score *out-of-bag* de ce prédicteur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868eb7e-928b-4745-b612-d7f9b7b03464",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be5d0c-1e75-4d97-b1d3-7b5869c214d2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b80da-a5e8-431e-a22f-62ce14e49cd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#?BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7056db-0a06-4e89-9a80-be52ec5cf097",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cart = DecisionTreeRegressor(max_depth=10)\n",
    "bagging_S = BaggingRegressor(estimator=cart, oob_score=True, n_estimators=100)\n",
    "\n",
    "bagging_small = fit_and_predict_error(bagging_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(bagging_small, 'Bagging Cart depth 10 S', df_errors)\n",
    "\n",
    "bagging_L = BaggingRegressor(estimator=cart, oob_score=True, n_estimators=100)\n",
    "bagging_large = fit_and_predict_error(bagging_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(cart_large, 'Bagging Cart depth 10 L', df_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501336f-39d0-44fb-959f-bad5c059e070",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3418895d-8cf8-400c-ac4e-9f25f48798e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(bagging_S.oob_score_)\n",
    "print(bagging_L.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ac300-9e2e-4098-bce9-db69814ca55e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Random forest\n",
    "\n",
    "Le forêts aléatoires sont une extension du bagging pour les arbres de décision qui permet de réduire davantage la variance du modèle, en ajoutant un caractère aléatoire lors de la création des arbres.\n",
    "\n",
    "Pendant la construction d'un arbre, au lieu de rechercher la caractéristique la plus importante lors de la division d'un nœud, on recherche la meilleure caractéristique **parmi un sous-ensemble aléatoire de caractéristiques**. Il y a donc deux niveaux *random* dans ce modèle (d'où le nom \"random forest\"): le random du bootstrap et la sélection random des caractéristiques. Le premier réduit la dépendance au training set, le deuxième réduit la corrélation entre les arbres de la forêt. Il en résulte une grande diversité qui se traduit généralement par un meilleur modèle.\n",
    "\n",
    "### Exercice\n",
    "\n",
    "- A l'aide de la classe `RandomForestRegressor` du module `sklearn.ensemble`, entraîner une foret aléatoire avec paramètres par défaut sur les données réduites et comparer les erreurs avec les autres modèles. Afficher également le score *out-of-bag* de ce prédicteur.  \n",
    "- Visualiser dans un graphe l'évolution des erreurs en fonction du nombre d'arbres de la forêt.\n",
    "- Les résultats théoriques montrent que le bon nombre de caractéristiques à tenir en compte lors d'un split est soit de l'ordre de la racine carré du nombre total des caractéristiques, soit de son logarithme. Entraîner une foret aléatoire avec un nombre d'arbres choisi sur la base de la visualisation du point précédent, et un nombre de caractéristiques de l'ordre de la racine carré du nombre total de caractéristiques. Afficher également le score *out-of-bag* de ce prédicteur.  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639b88a-2069-4a10-8b4b-e38a62e17e4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b525a9-9dc5-4f6b-a7b6-6da4a3cf6838",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(oob_score=True)\n",
    "\n",
    "rf_small = fit_and_predict_error(rf, X_train_S, Y_train, X_test_S, Y_test)   \n",
    "df_errors = add_error(rf_small, 'Default Random Forest S', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b880c4-a81c-4262-a53a-69e8508efc99",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49d35d-cb33-4451-9691-293252ccedfa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "K = rf.n_estimators\n",
    "prev_test = np.zeros((len(X_test_S), K))\n",
    "errEvol = np.zeros(K)\n",
    "for k in range(K):\n",
    "    prev_test[:, k] = rf.estimators_[k].predict(X_test_S.values)\n",
    "    pred_mean_k = prev_test[:, : (k+1)].mean(axis = 1)\n",
    "    errEvol[k] = mape(Y_test, pred_mean_k)\n",
    "plt.plot(errEvol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa23476-4613-4442-bc20-7f3a21959865",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "rf_S = RandomForestRegressor(max_features= \"sqrt\", n_estimators=60, oob_score=True)\n",
    "\n",
    "rf_small = fit_and_predict_error(rf_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(rf_small, 'Random Forest 60 sqrt S', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a56450-a91a-4469-9423-5349847cf542",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5befb1-51c3-4aea-a69e-2c63d57753b2",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "rf_L = RandomForestRegressor(max_features= \"sqrt\", n_estimators=60, oob_score=True)\n",
    "\n",
    "rf_large = fit_and_predict_error(rf_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(rf_large, 'Random Forest 60 sqrt L', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c115c-e34f-41bf-a972-b9ef5e3331f6",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Extra trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d06b2-2f23-4d00-a1c6-7a3cf818dab0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Proche des forêts aléatoires, les Extra Trees, dit aussi Extremely Randomized Trees, ajoutent une couche supplémentaire d'aléatoire au forêts, en choisissant le split d'une caractéristique au hasard, au lieu qu'en sélectionnant le meilleur split. Cela réduit par ailleurs de façon considérable le temps de calcul.\n",
    "\n",
    "### Exercice\n",
    "\n",
    "- Combiner la classe `ExtraTreeRegressor` et `BaggingRegressor` pour obtenir une forêt d'arbres extrêmement aléatoires.  \n",
    "- Entraîner, prédire et afficher le score *out-of-bag* d'abord sur les données réduites, et ensuite sur les données complètes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b78fa2-c1f9-4099-848c-5f5f94d7bbac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab640365-f4d6-48e3-96ce-49f1c233c613",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor\n",
    "\n",
    "# n_estimators=10 par défaut, on l'augmente pour avoir un estimateur satisfaisant\n",
    "extra_tree_S = ExtraTreeRegressor()\n",
    "bagging_xtree_S = BaggingRegressor(extra_tree_S, oob_score=True, n_estimators=100)\n",
    "\n",
    "extra_small = fit_and_predict_error(bagging_xtree_S, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(extra_small, 'Extra Tree S', df_errors)\n",
    "\n",
    "df_errors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c777e8-32fe-4667-ac17-dd8724e0ab46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "bagging_xtree_S.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d797a08-c398-4343-b1b9-cb3010c7ab68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "extra_tree_L = ExtraTreeRegressor()\n",
    "bagging_xtree_L = BaggingRegressor(extra_tree_L, oob_score=True, n_estimators=100)\n",
    "\n",
    "extra_large = fit_and_predict_error(bagging_xtree_L, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(extra_large, 'Extra Tree L', df_errors)\n",
    "\n",
    "df_errors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d3bd1-4d29-4526-b110-ca8de5cf9998",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "bagging_xtree_L.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4243a-2198-426f-a007-ea15e6bbb5a9",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Boosting\n",
    "\n",
    "Nous avons vu que les méthodes de Bagging permettent de construire un prédicteur robuste à partir de plusieurs prédicteurs faibles. Les prédicteurs faibles peuvent être construits en parallèle, c'est-à-dire que la construction de chacun d'entre eux peut être faite indépendamment des autres.\n",
    "\n",
    "Une autre technique d'ensemble, différente du Bagging, consiste à générer les prédicteurs de façon séquentielle, en améliorant à chaque itération le nouveau modèle par rapport au précédent. C'est la technique du **Boosting**.\n",
    "\n",
    "Tout d'abord, un modèle est construit à partir des données d'apprentissage. Ensuite, un deuxième modèle est construit pour tenter de corriger les erreurs présentes dans le premier modèle. Cette procédure se poursuit et des modèles sont ajoutés jusqu'à ce que l'ensemble des données d'apprentissage soit prédit correctement ou que le nombre maximum de modèles soit atteint. \n",
    "\n",
    "Dans toutes les techniques de Boosting, des poids sont associés aux données d'apprentissage, et à chaque itération ces poids sont réajustés, de façon à augmenter le poids des données mal prédites  et réduire celui des données correctement prédites. Ceci permet au modèle suivant de se \"concentrer\" sur les mauvaise prédictions et de s'améliorer.\n",
    "\n",
    "![Boosting classifier](img/Boosting-classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b987e-3861-4bdd-a795-1cbf8c6e609e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Il existe plusieurs algorithmes de Boosting, parmi les plus connus nous pouvons citer : \n",
    "- **Gradient Boosting** :\n",
    "    - Chaque nouveau modèle est entraîné pour minimiser la fonction de perte (erreur quadratique moyenne ou cross-entropie) du modèle précédent à l'aide d'une descente de gradient.\n",
    "    - À chaque itération, l'algorithme calcule le gradient de la fonction de perte par rapport aux prédictions de l'ensemble actuel, puis entraîne un nouveau modèle faible pour minimiser ce gradient.\n",
    "    - Les prédictions du nouveau modèle sont ensuite ajoutées à l'ensemble, et le processus est répété jusqu'à ce qu'un critère d'arrêt soit rempli.\n",
    "- **AdaBoost** -- Adaptative Boosting\n",
    "- **XGBoost** -- eXtreme Gradient Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be90f8a-68bf-4baa-bd2d-079abf85d304",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Utiliser le module `GradientBoostingRegressor` pour prédire la consommation via une regression par Gradient Boosting avec un learning rate égal à 0.7, un nombre d'estimateurs égal à 1000 et une profondeur de l'arbre égale à 10. \n",
    "\n",
    "Si vous en avez le temps, faites de la validation croisée sur le learning rate et le nombre d'estimateurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195b7128-e082-4093-bfae-eaafb4923736",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef346e-c5cd-4756-881e-65b8014615f2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingRegressor(learning_rate=0.7, n_estimators=100,max_depth=10)\n",
    "\n",
    "gb_small = fit_and_predict_error(gb, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(gb_small, 'Gradient Boosting S n=100', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f342e-fe7e-4d58-b913-69d9df7a0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate=0.7, n_estimators=100,max_depth=10)\n",
    "\n",
    "gb_large = fit_and_predict_error(gb, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(gb_large, 'Gradient Boosting L n=100', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df46cc5e-4f97-4774-af53-2986179da64d",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': np.arange(0.4, 0.8, 0.1),\n",
    "    'n_estimators' : [500, 1000, 1500]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = gb, param_grid = param_grid)\n",
    "\n",
    "gb_small = fit_and_predict_error(grid_search, X_train_S, Y_train, X_test_S, Y_test)\n",
    "df_errors = add_error(gb_small, 'Gradient Boosting CV S', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bbd7970e-8099-46ce-a83e-cadd7cd6147f",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40459a5-4c63-4863-9a7b-5026c7e5fc32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Feature importance/importance des variables\n",
    "\n",
    "L'importance des variables indique dans quelle mesure chaque caractéristique contribue à la prédiction du modèle. Une première idée de l'importance des variables, par exemple, peut être donnée par la correlation entre chaque variable et la variable à prédire. Selon le modèle, il existe d'autres mesures qui peuvent aider à affiner la compréhension de quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cff7b-f098-41ed-ba59-c7768af9925d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Regressions linéaires\n",
    "\n",
    "Combien de caractéristiques sont retenues dans les modèles Lasso ? \n",
    "\n",
    "Commenter au vu des erreurs obtenues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827410b0-51fa-4465-9fdf-8b6454c5e9b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1b4d3-8f04-479a-ac9f-7086883939bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "total_features_lasso_small = len(lasso_pipe_S.named_steps['lassocv'].coef_)\n",
    "features_lasso_small =  total_features_lasso_small - np.sum(np.abs(lasso_pipe_S.named_steps['lassocv'].coef_) == 0) \n",
    "\n",
    "print(\"Total number of features of Lasso Small : \", total_features_lasso_small)\n",
    "print(\"Retained features of Lasso Small : \", features_lasso_small)\n",
    "\n",
    "total_features_lasso_large = len(lasso_pipe_L.named_steps['lassocv'].coef_)\n",
    "features_lasso_large =  total_features_lasso_large - np.sum(np.abs(lasso_pipe_L.named_steps['lassocv'].coef_) == 0) \n",
    "\n",
    "print(\"Total number of features of Lasso Large : \", total_features_lasso_large)\n",
    "print(\"Retained features of Lasso Large : \", features_lasso_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76ad95-0983-46b3-b7f1-ee3e585973f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "Le modèle de Lasso entraîné sur les données complètes affiche la même erreur que le modèle linéaire entraîné sur les mêmes données, alors qu'il utilise 44 caractéristiques en moins pour calculer la prédiction. Le modèle de Lasso est donc à préférer par rapport à une regression linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfc4fb2-9cd9-4f09-b60b-08a2c9f2450c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Modèles d'ensembles \n",
    "Pour les arbres de décisions, les forêts aléatoires ou le gradient boosting, l'importance d'une variable peut être calculée comme la réduction totale du critère apportée par cette variable. Cet indice est connu aussi sous le nom de indice de Gini.\n",
    "\n",
    "Afficher dans un histogramme à barres horizontales (`barh`) l'indice de Gini des 10 variables le plus importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c218b-197c-493f-9699-b1a918389769",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d49f6a-c9f9-4a0a-8da6-a153159f6995",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# pour les bagging on peut récuperer les fi de chaque sous-modele\n",
    "#bagging_xtree_L.estimators_[0].feature_importances_\n",
    "\n",
    "models = [cart_S,rf_S,gb]\n",
    "\n",
    "fig, axs = plt.subplots(len(models), figsize=(12,8), sharex=True)\n",
    "for model,ax in zip(models,axs.flat):\n",
    "    feature_importance = model.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    n_features = 10\n",
    "    #n_features = sorted_idx.shape[0]\n",
    "    pos = np.arange(n_features) + 0.5\n",
    "    ax.barh(pos, feature_importance[sorted_idx][-n_features:], align=\"center\")\n",
    "    ax.set_yticks(pos, X_train_S.columns.values[sorted_idx][-n_features:])\n",
    "    ax.set_title(f'{type(model).__name__ }')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964862b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "#df_errors.to_pickle(path + \"day2_errors.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
