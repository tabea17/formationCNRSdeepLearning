{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0fb83e-2bbc-4a2a-9462-0b35fdae56a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# TP: Régression logistique et `scikit-learn` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e053ea4-f29f-4e6c-9972-8754cfdf8c2c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Dans ce premier TP, nous mettons en oeuvre un modèle de régression logistique pour la prédiction de labels binaires $y \\in \\{0,1\\}$. On rappelle que la régression logistique repose sur une modélisation probabiliste, et donc plutôt que de prédire simplement 0 ou 1, on calcule pour chaque observation $x$ une probabilité dans $[0,1]$ qui correspond à un estimateur $\\mathbf{P}(y=1|x)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1dfc4-bd4f-48c0-8865-733e8a1d4988",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Les données utilisées dans ce TP proviennent d'un jeu de données classique qui s'appelle \"Census Income\" dataset (également connu sous le nom de \"Adult Income\" et disponible sur le site [https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)).\n",
    "\n",
    "Ce dataset a été extrait par Barry Becker du recensement américain de 1994 et est souvent utilisé pour des tâches de classification binaire, où l'objectif est de **prédire si un individu gagne plus ou moins de $50\\,000$ dollars par an**, en se basant sur les caractéristiques démographiques et professionnelles disponibles. Les **caractéristiques sont qualitatives et quantitatives** et incluent l'âge, le niveau d'éducation, le statut matrimonial, la profession, le pays d'origine, le sexe, le capital investi, le nombre d'heures de travail par semaine, etc.\n",
    "\n",
    "Le fichier `data/adult_clean.csv` a été obtenu en nettoyant les fichiers publics (voir le notebook `day1_preparation_data.ipynb`): on a retiré les données manquantes et les doublons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3608f5b-8a81-4d35-a6c0-23ec7be9f468",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Le jeu de données\n",
    "\n",
    "On utilise le module `pandas` qui est une bibliothèque open-source populaire en Python, largement utilisée pour la manipulation et l'analyse des données. Ce module fournit des structures de données flexibles et performantes: \n",
    "- les **DataFrames** qui sont similaires aux tables de base de données ou aux feuilles de calcul Excel\n",
    "- les **Series** qui sont des tableaux unidimensionnels avec étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef5b9e-2c41-43b9-a166-3dcf7a1a032e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d27f1f-aa1b-4a93-a307-3212e149f3cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Chargement \n",
    "\n",
    "- Importer les données du fichier `data/adult_clean.csv` sous forme d'un `DataFrame` pandas que l'on nomme `dataset`. \n",
    "- Visualiser les premières lignes de `dataset`, noter le nombre de caractéristiques (et leurs noms) et le nom de la variable à prédire.\n",
    "- Quel est le nombre total de données (de lignes) du `dataset`, et la proportion de données `<=50K` et `>50K`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aef5b77-8c5b-497d-b91f-0074d5e39a76",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14668e36-66e8-4119-8815-4be9463c0444",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on visualise les premières lignes du fichier pour voir la structure\n",
    "# ici le format est classique: la \",\" est le séparateur et la première ligne contient le nom des colonnes\n",
    "filename = \"data/adult_clean.csv\"\n",
    "with open(filename, 'r') as f:\n",
    "    for line, k  in zip(f, range(5)): \n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3760a5-e0f8-4ac7-a5b6-608abd4b4850",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on crée l'objet dataset via l'appel de la fonction `read_csv` du module pandas\n",
    "dataset = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9706d91-1572-443c-8df5-63fa3adc7b36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on visualise les 5 premières lignes du `dataset`\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d380990c-7c4e-41d0-be49-37c273d70ea9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on utiliser la méthode `value_counts` pour obtenir des informations sur les données à prédire \n",
    "dataset[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5bb44-a917-4ca9-9880-468df7a9fb21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Remarque** : Pour lister toutes les méthodes/attributs utilisables pour un objet on peut utiliser la fonction `dir` par exemple \n",
    "```python\n",
    "print(dir(dataset))\n",
    "```\n",
    "Pour ne lister que les méthodes/attributs *publiques* on peut filtrer le résultat par exemple \n",
    "```python\n",
    "print([m for m in dir(dataset) if m.startswith('_') == False])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1801d996-43b6-4d0b-9760-8e2cf3cf3ce4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print([m for m in dir(dataset) if m.startswith('_') == False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c7e74-7af2-4d8c-b63b-8482610c985d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Exploration, visualisation \n",
    "\n",
    "- Familiarisez-vous avec les données (à l'aide de `shape`, `dtypes`, `describe`, `value_counts`).\n",
    "- Visualiser quelques caractéristiques en séparant les 2 groupes `<=50K` et `>50K`.\n",
    "- Séparer les données en 3 dataframes qu'on nomme :\n",
    "\n",
    "    - `quantitative`: dataframe avec toutes les covariables quantitatives\n",
    "    - `qualitative`: dataframe avec toutes les covariables qualitatives\n",
    "    - `category` : pour les labels observés `class`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2014831-2b04-442f-a1fc-63c754a060a1",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf6b1ae-f218-4037-87cc-d376c1384a5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd10d8-4d92-4e48-ae97-5cb92fd8c34c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c481cd2-a48d-4034-b275-89f4c19ab9ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dataset.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d7ee9-5d16-471c-ac00-b357e50af4a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dataset[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed997f-783a-4217-ae7a-3a2ab95da63d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dataset[\"race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c79436c-2662-494e-8089-37e44d668e1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18bbca-a082-4105-bc1d-2c94900ab3f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=dataset, x=\"age\", hue=\"class\", \n",
    "             multiple=\"stack\", alpha=0.5, discrete=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21ef909-289b-4a4e-9891-7ea114594d70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=dataset, x=\"sex\", hue=\"class\", \n",
    "                  multiple=\"stack\", alpha=0.5, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2dca40-3e4e-4750-93d4-626300e368b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=dataset, x=\"education\", hue=\"class\", \n",
    "                  multiple=\"stack\", alpha=0.5, discrete=True)\n",
    "ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7a832-9ee1-48b4-b4e1-4ff9d892b6f4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(data=dataset, x=\"age\", y=\"hours-per-week\",\n",
    "                     hue=\"class\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc8f59-d561-4329-8a0c-dee215681a18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "quant_columns = [ \"age\", \"capital-gain\", \"capital-loss\", \"hours-per-week\" ]\n",
    "quali_columns = [ \"workclass\", \"education\", \"marital-status\", \"occupation\", \n",
    "                  \"relationship\", \"race\", \"sex\", \"native-country\" ]\n",
    "quantitative = dataset[quant_columns]\n",
    "qualitative = dataset[quali_columns]\n",
    "category = dataset[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a96ab6-6e45-4f94-b8a1-6c27c9cc8176",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Remarque** :\n",
    "On pourrait automatiser en utilisant par exemple \n",
    "\n",
    "```python\n",
    "quantitative = dataset.columns[dataset.dtypes == 'int64']\n",
    "qualitative = dataset.columns[dataset.dtypes == 'object'][:-2]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe5ce5-83b0-4684-8ec4-adfe5647cee8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Pré-traitement des données\n",
    "\n",
    "On ne travaille que très rarement sur des donnnées brutes. \n",
    "\n",
    "Pour des  **variables quantitatives**, il est important de les  **standardiser** (centrer et réduire) afin de les ramener à  des échelles comparables. Cela diminue également les problèmes numériques. \n",
    "\n",
    "Pour une **variable qualitative** ou **catégorielle**, il n'y a en général pas  d'ordre naturel de ses modalités. Donc il ne faut pas bêtement remplacer des catégories *A*, *B*, *C*,... par 1, 2, 3,... Le problème est que dans un modèle de régression, on va calculer par exemple des moyennes sur ces valeurs, mais en général *B* n'est pas la moyenne de *A* et *C* (alors que c'est le cas pour la valeur 2 par rapport à 1 et 3). Il nous faut alors un encodage qui est invariant à l'ordre des modalités. On utilise  le **one-hot encoding** qui consiste à transformer une variable qualitative en plusieurs variables binaires dites **dummies**. Une variable avec K modalités est transformée en K-1 variables binaires. Chacune de ces variables binaires indique pour une catégorie spécifiée si la variable observée est égale à cette catégorie ou pas. Il suffit de K-1 variables binaires pour encoder K catégories, car l'information sur la K-ième catégorie peut être déduite des K-1 autres variables binaires. Donc, si on utilisait K variables binaires, on introduirait des corrélations entre les colonnes, ce qu'il faut éviter dans un cadre de régression.\n",
    "\n",
    "En vue de la régression logistique on effectue le pré-traitement suivant: définir les variables \n",
    "- `labels` en remplaçant les classes `<=50K` et `>50K` par les valeurs numériques 0 et 1\n",
    "- `quantitative_norm` obtenu en renormalisant le dataset `quantitative`\n",
    "- `qualitative_enc` obtenu par l'appel de `get_dummies` du module `pandas` sur le dataset `qualitative` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa6eef0-97a4-4b6c-b2da-e709949ac309",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c7acf-d383-4690-a677-488e18902555",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "labels = category.replace({ '<=50K': 0, '>50K': 1 }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e21d4-aa7a-4581-87f8-ea9df41ac188",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "quantitative_norm = (quantitative - quantitative.mean()) / quantitative.std()\n",
    "quantitative_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641f8f3-d9cc-4385-8f18-b0968ebe2072",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "qualitative_enc = pd.get_dummies(qualitative)\n",
    "qualitative_enc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb664318-9173-4bd7-8fae-ae28c4a3163a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Remarque 1**: \n",
    "La valeur 98 correspond à la somme des valeurs possibles par covariable qualitative. On peut le vérifier aisément:\n",
    "```python\n",
    "counter = 0\n",
    "for col in qualitative:\n",
    "    print(col, dataset[col].unique().shape[0])\n",
    "    counter += dataset[col].unique().shape[0]\n",
    "print(counter)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9355d7d4-fba1-4d3b-8d0b-6762eccee0ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Remarque 2**:\n",
    "On pourrait utiliser les fonctions `StandardScaler` et `OneHotEncoder` du module `scikit-learn` mais l'usage est d'utiliser ces fonctions à travers un pipeline pour automatiser le processus. On verra l'utilisation un peu plus loin. \n",
    "\n",
    "Si vous executez les lignes suivantes, vous remarquerez que `quantitative_norm2` est un tableau `numpy` (il a perdu sa structure de données de `DataFrame`) et `qualitative_enc2` est une matrice creuse (sparse matrix) de `scipy`. \n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "quantitative_preprocessor = StandardScaler()\n",
    "qualitative_preprocessor = OneHotEncoder()\n",
    "\n",
    "quantitative_norm2 = quantitative_preprocessor.fit_transform(quantitative)\n",
    "qualitative_enc2 = qualitative_preprocessor.fit_transform(qualitative)\n",
    "```\n",
    "\n",
    "Si on reconstruit des `DataFrame` à partir de ces tableaux numériques on peut vérifier que ces fonctions donnent des sorties similaires à notre traitement manuel:\n",
    "```python\n",
    "np.sum((quantitative_norm - pd.DataFrame(quantitative_norm2, columns=quantitative.columns))**2)\n",
    "qualitative_enc.equals(\n",
    "    pd.DataFrame(qualitative_enc2.todense().astype(bool), columns=qualitative_enc.columns)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6b3f0-797f-420c-970a-13f3000c90ff",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Attention**:\n",
    "On normalise et on encode sur l'ensemble des données! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96f23bb-8349-4b32-8346-82b5c6e3cef9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Echantillons: apprentissage et test \n",
    "\n",
    "On rappelle que la modélisation se fait en trois temps :\n",
    "- on sépare les données : TRAIN / TEST\n",
    "- on apprend le modèle sur TRAIN\n",
    "- on évalue la performance du modèle appris sur TEST\n",
    "\n",
    "On coupe les données de façon aléatoire en deux groupes. \n",
    "Le plus souvent, on les sépare Cen 80% pour l'apprentissage et 20% pour le test. D'autres pourcentages courants sont 67-33 ou 50-50.\n",
    "On   utilise la  fonction `train_test_split` du package `sklearn.model_selection` pour séparer aléatoirement les données. \n",
    "\n",
    "Même si le split est aléatoire, on souhaite que les deux échantillons soient tous les deux représentatifs du problème. En particulier, on voudrait qu'ils contiennent le même pourcentage de labels 0 et 1, ce qui est notamment important quand  les labels ne sont pas équilibrés (pas 50-50).\n",
    "\n",
    "Ici, la proportion de 1, individus qui sont dans la catégorie `>50K` est d'environ 0.25 (le vérifier!).\n",
    "\n",
    "Si le taux n'est pas très élevé, une coupe totalement aléatoire des données risque de produire des sous-échantillons où l'un des deux ne contient que peu de labels qui valent 1. Cela peut être problématique pour l'apprentissage du modèle comme pour l'évaluation de la méthode.\n",
    "\n",
    "En pratique, dans des problèmes de classification, on force alors la même répartition des labels dans les deux échantillons TRAIN et TEST, via l'option `stratify`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ce0cd-5728-475e-83f0-38b8a47d0de7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Création des échantillons \n",
    "\n",
    "Utiliser la fonction `train_test_split` du module `scikit-learn` pour créer à partir de nos données `quantitative_norm`, `qualitative_enc` et `labels` les 4 variables suivantes: \n",
    "- `x_train` et `y_train` qui contiennent 80% du jeu de données pour l'apprentissage du modèle de régression logistique \n",
    "- `x_test` et `y_test` qui contiennent les 20% restants pour le test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9e2dd-fc2d-4214-a408-ef71afcda061",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92be0c7-cc79-429e-9eb8-3f245240c18d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split TRAIN / TEST\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    pd.concat([quantitative_norm, qualitative_enc], axis=1),\n",
    "    labels,\n",
    "    stratify=labels,\n",
    "    test_size = 0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b168c-6bb0-4d04-9edc-110955bcfa56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8def85-b403-4a39-8993-ded777297474",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "**Remarque**:\n",
    "Dans cette première approche nous utilisons la fonction `train_test_split` du module `scikit-learn`. En pratique il est préférable d'utiliser une approche par validation croisée qui permet d'évaluer la performance de généralisation du modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364ecb2-df56-467f-aa85-a59da6fbea65",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Régression logistique\n",
    "\n",
    "Le but de ce TP est de fitter un modèle de régression logistique à ces données afin de prédire le label (`<=50K` ou `>50K`) pour des  nouveaux individus à partir de leurs caractéristiques. Nous commençons par le modèle simple qui prend en compte toutes les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2a58c-6df9-4f9f-8ae4-7c0cf69bfa9f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Création du modèle et estimation\n",
    "\n",
    "- Utiliser la fonction `LogisticRegression` de `sklearn.linear_model` pour effectuer une régression logistique simple (i.e. sans pénalisation). Fitter le modèle sur les données `train`. Visualiser les coefficients estimés (intercept et variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6da26-b3b5-4d00-8ad9-77e5d702ae36",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e64c59-3b5c-487f-a9f7-0919edf7ebab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Définition du modèle de régression logistique : sans pénalisation \n",
    "model = LogisticRegression(penalty=None, max_iter=1000)\n",
    "# sans l'option max_iter, on peut avoir un nb max d'itérations insuffisant pour atteindre la convergence\n",
    "# On estime les paramètres de ce modèle sur les données \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Résultats de la régression logistique\n",
    "# On visualise l'intercept b et les 32 coefficients w_i estimés pour les 32 variables \n",
    "print(\"intercept:\", model.intercept_)\n",
    "print(\"coefficients:\", model.coef_.shape, \"\\n\", model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc8ad6-f41a-47f8-bab1-b4d0dfbd73b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c50f7-a3bf-4e67-8c34-726433b30f6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Estimation\n",
    "\n",
    "- Sur le jeu `test`, calculer les probabilités que `>50K` pour chaque individu (`predict_proba()`) et les prédictions (`predict()`) que l'on obtient par seuillage des probabilités au seuil de $t = 1/2$.\n",
    "- Faire varier le seuil $t \\in [0,1]$, comparer le nombre moyen de positifs prédits par rapport à celui connu dans `y_test`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdccb3-97e7-4107-813e-ec9e077c25eb",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d670f3c-8a37-4a1d-8d09-6146d90aef1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "La méthode `predict_proba` renvoie 2 colonnes: la première est la probabilité d'être `<50K` (label 0, négatif) et la seconde la probabilité d'être `>=50K` (label 1, positif). A partir de ces probas on peut \"décider\" en fixant un seuil $t \\in [0,1]$ d'être ou non dans une des 2 catégories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494fcb11-ed70-474a-ad4a-363ee22a716b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "seuil_t = 0.5   # à modifier pour voir l'influence de ce paramètre \n",
    "pred_prob = model.predict_proba(x_test)\n",
    "pred_t = pred_prob[:, 1] > seuil_t  # ce vecteur de booléen est la prédiction obtenue avec le seuil t \n",
    "print(f\"La proportion de positifs >=50K prédits avec le seuil t={seuil_t} est:\", pred_t.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37ec97-7732-41e0-aca8-77fa02ccf7b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "La méthode `predict` renvoie directement la prédiction obtenue avec le seuil $t = 0.5$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41296c42-bc46-4204-aaff-313c74f386d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "print(f\"La proportion de positifs >=50K prédits par le modèle est:\", pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ba3da1-bb0f-491e-9ec3-fef327d20de5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"La proportion de positifs >=50K dans y_test est:\", np.mean(y_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d725b-a51c-414d-b217-2afbc962f5ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Mesures de qualité du classifieur \n",
    "\n",
    "Le module `metrics` de `scikit-learn` contient plusieurs fonctions qui permettent d'évaluer la qualité des prédictions d'un modèle. Ces métriques sont détaillées dans les sections sur les métriques de classification, les métriques de classement multi-label, les métriques de régression et les métriques de clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2835f5-2761-4b73-bbbf-0bf4a36a9eaa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(dir(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e02d6e1-9b21-4bc0-a265-7859b4d48272",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Accuracy score  \n",
    "\n",
    "Le taux de précision (_accuracy score_) est la mesure de performance qui représente la proportion d'échantillons correctement classés par le modèle parmi l'ensemble total des échantillons. Ce taux est un pourcentage, où une valeur de 100% signifie que toutes les prédictions du modèle sont correctes.\n",
    "\n",
    "- Implémenter à la main (en `numpy`) le calcul de ce score pour les données de test.\n",
    "- Obtenir ce score via l'appel de `accuracy_score` du module `sklearn.metrics` et via la méthode `score` de l'objet `model`.\n",
    "- Comparer ce score à un estimateur trivial qui consiste à toujours renvoyer la classe la plus fréquente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f484506-74a1-4882-a425-2703e356398e",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65d6f8-90ba-4cc6-ae2d-24d774f0ecf0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# accuracy calculé à la main\n",
    "y_predicted = model.predict(x_test)\n",
    "accuracy = np.mean(y_predicted == y_test)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718dd43-6866-4858-80df-bcfc4b0162bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# accuracy avec sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebde6b-d051-4ed6-b3c6-2982149a1d7a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# accuracy avec score\n",
    "print(f\"Accuracy: {model.score(x_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e7ed4-6c31-4356-a33b-ca777894628c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "Comme la proportion de personnes dans la classe `<=50K` est d'environ 75%, un  classifieur trivial consiste à décider de prédire toujours `<=50K` quelque soit les valeurs des variables. L'accuracy de ce classifieur est alors de 75% :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cd31f-fc62-4ef7-8e4e-6c3c4bc12a52",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "dummy_accuracy = np.mean(np.zeros_like(y_test) == y_test)\n",
    "print(f\"Accuracy of the dummy classifier: {dummy_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa56b4-78a9-4d3d-8c5b-23ea82295051",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit(x_train, y_train)\n",
    "print(f\"Accuracy of the dummy classifier: {dummy_classifier.score(x_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd711301-d917-4918-8bea-5675caf81e5b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "Il est alors important de noter qu'un classifieur trivial peut déjà avoir une accuracy assez élevée ! \n",
    "Et du coup, dans notre cas, une accuracy de 84% est   moins impressionnante qu'à première vue.\n",
    "Il faut alors toujours comparer l'accuracy d'un classifieur à celle d'une méthode baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64330509-5962-4b0a-8964-b09a03a9cb44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Matrice de confusion, recall, precision\n",
    "\n",
    "La matrice de confusion permet de visualiser les performances du modèle en termes de prédictions correctes (vrais positifs et vrais négatifs) et d'erreurs de prédiction (faux positifs et faux négatifs). La représentation classique se fait sous forme d'une matrice où les nombres sur la diagonale sont liés aux prédictions correctes, tandis que les nombres hors de la diagonale sont liés aux prédictions incorrectes. Plus précisément: \n",
    "\n",
    "- le coin inférieur droit représente les **vrais positifs** (TP): les personnes de la classe `>50K` prédites comme telles par le modèle \n",
    "- le coin supérieur gauche représente les **vrais négatifs** (TN): les personnes de la classe `<=50K` prédites comme telles par le modèle \n",
    "- le coin supérieur droit représente les **faux positifs** (FP): les personnes de la classe `<=50K` prédites comme étant `>50K`\n",
    "- le coin inférieur gauche représente les **faux négatifs** (FN): les personnes de la classe `>50K` prédites comme étant `<=50K`\n",
    "\n",
    "**Attention**:\n",
    "Dans la page wikipedia et dans les slides la matrice est \"inversée\": les vrais positifs sont en haut à gauche... \n",
    "\n",
    "A partir de ces données on peut construire 2 métriques: \n",
    "- le **recall** est défini par TP/(TP+FN): il mesure la capacité du classifieur à identifier tous les exemples positifs réels, c'est-à-dire sa sensibilité ou son taux de détection. Dans notre cadre, le recall est le taux d'individus identifiés comme `>50K` par le classifeur parmi tous les individus avec `>50K` dans `y_test`.\n",
    "- la **precision** est définie par TP/(TP+FP): elle mesure la capacité du classifieur à ne prédire positif que lorsque la prédiction est vraiment correcte, c'est-à-dire sa spécificité.  P. ex.  le classifieur qui prédit systématiquement `>50K` pour tous les individus a un  recall  de 100%, mais sa precision est de 0%. Donc, on veut que les deux scores, le recall et la precision, d'un classifieur soient élevés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e844f839-eb19-4152-b3d0-50fdb6b48a63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "- Tracer la matrice de confusion en utilisant `ConfusionMatrixDisplay` et donner les scores `recall` et `precision`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2b617-4b4d-440a-a383-a935fb1dfcb1",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ],
    "user_expressions": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33835fd2-1430-466c-9545-3da4b73a80ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model, x_test, y_test)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb212793-641c-459d-9eb0-e0a5fd596ee2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "recall = recall_score(y_test, y_predicted)\n",
    "\n",
    "print(f\"Precision score: {precision:.3f}\")\n",
    "print(f\"Recall score: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bfa766-8b94-41bb-8a92-ec3529bda985",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Courbe ROC, AUC\n",
    "\n",
    "Les valeurs prédites `y_predicted` ci-dessus ont été obtenues en seuillant les probabilités de `>50K` calculées par le modèle de régression logistique avec le seuil par defaut $t=1/2$.  Or, en variant le seuil $t$ il est possible que le classifieur associé ait des meilleurs scores.\n",
    "\n",
    "La courbe ROC est une courbe paramétrique, paramétrée par $t \\in [0,1]$. Elle représente les points (FP, TP) pour tout seuil $t\\in[0,1]$. \n",
    "\n",
    "Avec le seuil $t=0$, le classifieur prédit `<=50K` systématiquement, donc il n'y a pas de positifs et on a TP = 0 et FP = 0. En revanche, avec un seuil de $t=1$, le classifieur prédit toujours `>50K` et donc on a TP = 1 et FP = 1. Toutes les courbes ROC commencent donc au point $(0,0)$ et se terminent au point $(1, 1)$.\n",
    "\n",
    "Si la courbe est élevée, le modèle a une très bonne performance quelque soit le seuil. Cela est mesuré par l'aire sous la courbe (AUC). L'AUC permet de comparer deux modèles, ou un modèle sur des jeux de données différentes, comme les données train et test.\n",
    "\n",
    "- Utiliser la fonction `RocCurveDisplay` pour tracer la courbe ROC de notre modèle pour les données train et les données test. Sur quelles données observe-t-on une meilleure performance ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a40f8-7b92-4552-9f5c-25eafc7405f7",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523d499-e1b0-4a49-bc82-2f01f2b01888",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(model, x_test, y_test, name=\"Test\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(model, x_train, y_train, name=\"Train\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(dummy_classifier, x_test, y_test, linestyle=\"--\", color='grey', ax=ax)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"Receiver Operating Characteristic curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badcd5fe-6213-4b93-a6e2-c64a2b1eea5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Courbe precision/recall, AP\n",
    "\n",
    "Un autre outil de comparaison est la courbe precision/recall qui représente les points des coordonnées (recall, precision) pour tout seuil $t\\in[0,1]$. L'interprétation est la même : plus la courbe est élevée (ou plus l'aire sous la courbe est grande), mieux c'est.\n",
    "\n",
    "Noter que contrairement à la courbe ROC, la courbe precision/recall n'est pas toujours monotone.\n",
    "\n",
    "Tracer la courbe precision/recall de notre modèle sur les données test en utilisant la fonction `PrecisionRecallDisplay`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e9d4c-3e71-4aad-92a9-e9f091b1b80c",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17932076-49a8-4c82-b33c-862512035386",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "PrecisionRecallDisplay.from_estimator(model, x_test, y_test, ax=ax)\n",
    "#PrecisionRecallDisplay.from_estimator(dummy_classifier, x_test, y_test, linestyle=\"--\", ax=ax)\n",
    "# il n'est pas recommandé de tracer la courbe du dummy_classifier car l'interprétation est douteuse...\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title(\"Precision-recall curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455942b-9641-44fe-93a1-1a6feb3023bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Régression logistique avec pénalisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ec628-f40a-4496-ada3-c6d56f9ab959",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Régression ridge\n",
    "\n",
    "Nous allons utiliser une pénalité en norme 2 (dite $\\ell_2$ ou Ridge) sur les coefficients de la régression. Cette pénalité Ridge a tendance à \"rétrecir\" les valeurs des coefficients (on parle de shrinkage) et régularise la solution. \n",
    "\n",
    "- Mettre en oeuvre la régression logistique avec pénalité $\\ell_2$ sur les données d'apprentissage. On utilisera toujours la fonction `LogisticRegression`avec  l'option `penalty='l2'`. On utilisera une pénalité assez forte, p. ex. `C=0.01`. \n",
    "- Comparer les valeurs des coefficients avec le cas sans pénalité (visualisez l'effet de shrinkage). \n",
    "- Évaluer les performances du classifieur sur les données de test.\n",
    "- Pour les deux classifieurs (avec et sans pénalisation $\\ell_2$), comparer les courbes de score sur les données `test` ainsi que les performances en termes de courbes (ROC ou precision-recall) et d'AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e2ce2-413d-4095-b8c4-d58cff350947",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62355eac-12da-4971-af9c-a7033c2aa708",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "C_ridge = 0.01\n",
    "model_ridge = LogisticRegression(penalty='l2', C=C_ridge, max_iter=1000, solver='liblinear')\n",
    "model_ridge.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa62141-e0e3-459a-91c5-d5855eca4d49",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def extract_coeff(model, name=None):\n",
    "    return pd.DataFrame({ \n",
    "        \"feature\": model.feature_names_in_, \n",
    "        \"value\": np.abs(model.coef_.flatten()), \n",
    "        \"method\": name, \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9c459-5643-4f81-b8a0-5771eb381c83",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "extract_coeff(model, \"no penality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b633b01-170c-4c2e-8976-9788b75ed798",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Nombre de coefficients non nuls avec pénalité Ridge (C={C_ridge}):\", np.sum(extract_coeff(model_ridge)[\"value\"] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc29a6-5343-422f-8471-6e5e4b7c234f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df1 = extract_coeff(model, \"no penality\").sort_values(\"value\", ascending=False)[:20]\n",
    "df2 = extract_coeff(model_ridge, f\"ridge C={C_ridge}\")\n",
    "df2 = df2[df2[\"feature\"].isin(df1[\"feature\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8d33e-2d2b-41bf-b829-034d3e3031d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=pd.concat([df1, df2]), x=\"feature\", y=\"value\", hue=\"method\")\n",
    "ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e5f07-7e90-49b9-b57e-5e50f2bfc52d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_predicted_ridge = model_ridge.predict(x_test)\n",
    "\n",
    "precision_ridge = precision_score(y_test, y_predicted_ridge)\n",
    "recall_ridge = recall_score(y_test, y_predicted_ridge)\n",
    "\n",
    "print(f\"Precision score: {precision_ridge:.3f}\")\n",
    "print(f\"Recall score: {recall_ridge:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4afbd0-dd1f-4fb5-8bf3-f06bf43cc736",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(model, x_test, y_test, name=\"no penality\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(model_ridge, x_test, y_test, name=f\"ridge C={C_ridge}\", ax=ax)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"Receiver Operating Characteristic curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ddd85-8b67-4349-a9ed-0f0b6e844cc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "PrecisionRecallDisplay.from_estimator(model, x_test, y_test, name=\"no penality\",ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(model_ridge, x_test, y_test, name=f\"ridge C={C_ridge}\",ax=ax)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title(\"Precision-recall curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f01430d-5a6d-45af-b729-3c5dc4d4787c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Régression lasso\n",
    "\n",
    "Dans cette partie, on va mettre en oeuvre une pénalité $\\ell_1$ dans la régression logistique. Cela peut permettre de faire de la sélection de variables : les variables peu informatives pour la prédiction ne seront plus du tout utilisées (coefficient $w_i$ estimé à 0). On peut ainsi construire un estimateur plus parcimonieux. \n",
    "\n",
    "- Mettre en oeuvre la régression logistique avec pénalité $\\ell_1$ sur les données d'apprentissage (avec l'option le `solver='liblinear'`).\n",
    "- Comparer les valeurs des coefficients avec le cas sans pénalité et avec pénalité $\\ell_2$ (visualiser l'effet d'annulation des coefficients). Tester différentes valeurs de $C$.\n",
    "- Pour l'ensemble des classifieurs (avec et sans pénalisation $\\ell_1$ et $\\ell_2$), comparer les performances en termes de courbes (ROC et precision-recall) et d'AUC. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16f398b-f549-459b-919d-38eb1ca7eb34",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715b620-ecc2-48db-870e-55b622529c23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "C_lasso = 0.01\n",
    "model_lasso = LogisticRegression(penalty='l1', C=C_lasso, max_iter=1000, solver='liblinear')\n",
    "model_lasso.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ffd59-5e77-4ccb-a0d8-514bdfdf45fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(f\"Nombre de coefficients non nuls avec pénalité Lasso (C={C_lasso}):\", np.sum(extract_coeff(model_lasso)[\"value\"] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3f31a-7954-4db6-8536-743a0362b930",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "df3 = extract_coeff(model_lasso, f\"lasso C={C_lasso}\")\n",
    "df3 = df3[df3[\"feature\"].isin(df1[\"feature\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43cb74-4e90-492e-a8ad-6e8adcec3541",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=pd.concat([df1, df2, df3]), x=\"feature\", y=\"value\", hue=\"method\")\n",
    "ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b44e6-6daf-47b8-bac0-a4739b0cccce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_predicted_lasso = model_lasso.predict(x_test)\n",
    "\n",
    "precision_lasso = precision_score(y_test, y_predicted_lasso)\n",
    "recall_lasso = recall_score(y_test, y_predicted_lasso)\n",
    "\n",
    "print(f\"Precision score: {precision_lasso:.3f}\")\n",
    "print(f\"Recall score: {recall_lasso:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b63da-adc5-4fd9-b0ef-e86d09bb3976",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(model, x_test, y_test, name=\"no penality\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(model_ridge, x_test, y_test, name=f\"ridge C={C_ridge}\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(model_lasso, x_test, y_test, name=f\"lasso C={C_lasso}\", ax=ax)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"Receiver Operating Characteristic curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2afb52-1455-4ca7-b0ce-50da10f244ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "PrecisionRecallDisplay.from_estimator(model, x_test, y_test, name=\"no penality\", ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(model_ridge, x_test, y_test, name=f\"ridge C={C_ridge}\", ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(model_lasso, x_test, y_test, name=f\"lasso C={C_lasso}\", ax=ax)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title(\"Precision-recall curve\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee27d3-508f-4868-ae28-01de652b8b06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Chemins de régularisation pour le Lasso\n",
    "\n",
    "Le but est de visualiser l'effet de la **constante de pénalisation** sur l'évolution des coefficients $w_i$, à travers les **chemins de régularisation**. Lorsque la pénalité est très forte (i.e $C$ très petite), aucune  variable n'est sélectionnée (tous les coefficients $w_i$ sont estimés à 0). Dans ce cas, la fonction de régression logistique est constante (on a seulement l'intercept) et le lien entre $y$ et $X$ est très mal appris. Puis au fur et à mesure que $C$ augmente, on inclue de plus en plus de variables dans notre modèle de régression logistique. Lorsque $C$ est très grande, on ne pénalise plus et on retrouve les résultats de la régression logistique simple. \n",
    "\n",
    "- Fixer une grille de valeurs de $C$, estimer le modèle lasso pour chaque constante $C$ et afficher les coefficients en fonction de $C$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466b452-90d8-4e46-ab4d-bbec69280b7d",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb2571-6115-4164-8fca-54712112ad74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_grid = 13\n",
    "n_coef = model.coef_.shape[1]\n",
    "C_grid = np.logspace(-4, 1, n_grid)\n",
    "coefs = np.empty((n_grid, n_coef))\n",
    "for k, C in enumerate(C_grid): \n",
    "    model_ = LogisticRegression(penalty='l1', C=C, max_iter=1000, solver='liblinear')\n",
    "    model_.fit(x_train, y_train)\n",
    "    coefs[k] = model_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be880003-6474-46c0-a4f1-3aed235f74e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6), layout=\"tight\")\n",
    "ax.semilogx(C_grid, coefs)\n",
    "ax.set_ylim(-3, 3)\n",
    "ax.set_xlabel(\"Constante de pénalisation\")\n",
    "ax.set_ylabel(\"Valeur du coefficient\")\n",
    "fig.suptitle(fr\"Evolution des {n_coef} coefficients avec pénalisation $\\ell_1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3755e-c135-4be8-b42b-436a9f6d9400",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Validation croisée\n",
    "\n",
    "Le processus de validation croisée consiste à diviser l'ensemble de données disponible en deux parties : un ensemble d'entraînement (training set) et un ensemble de validation (validation set). Le modèle est alors entraîné sur l'ensemble d'entraînement et évalué sur l'ensemble de validation. Cette procédure est répétée plusieurs fois en changeant les partitions d'entraînement et de validation, de sorte que chaque exemple de données soit utilisé à la fois pour l'entraînement et pour la validation.\n",
    "\n",
    "La validation croisée est utilisée pour évaluer les performances d'un modèle, estimer sa capacité à généraliser et guider les choix d'hyperparamètres afin d'obtenir un bon modèle. Elle aide à éviter le surapprentissage et à évaluer la robustesse du modèle face à de nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712141a0-58d6-4765-b847-93e5914f4925",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce10acd2-ba45-4c3e-9ae8-b0136869e88e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Stabilité des prédictions\n",
    "\n",
    "- Utiliser la fonction `cross_validate` du module `sklearn.model_selection` pour obtenir un intervale de confiance de l'accuracy score. On fera cette étude sur le modèle de régression logistique simple `model` et celui avec pénalité $\\ell_1$ `model_lasso`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404357f-7c6c-4c5b-a4ce-4a22e71319b8",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a1b13-0eb1-4e85-b304-e1b976b97622",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.concat([quantitative_norm, qualitative_enc], axis=1)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model, data, labels, cv=8)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e39957e-9b4a-4ab1-b32a-d03025e4d617",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf14b0a-c6f0-4a13-9196-fa8de14a1279",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "data = pd.concat([quantitative_norm, qualitative_enc], axis=1)\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_results = cross_validate(model_lasso, data, labels, cv=8)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf40cc4-2dae-487b-b43f-65f571b0cc5e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953754d-4d18-4561-b3be-111edb7bf945",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Choix de la constante de pénalisation\n",
    "\n",
    "On peut aussi la validation croisée pour choisir un hyperparamètre. Dans cette partie, nous allons mettre en oeuvre le choix de la constante de pénalisation par **validation croisée**. \n",
    "Nous le ferons dans le cadre d'une pénalité $\\ell_1$, mais on pourrait faire exactement la même chose avec un autre type de pénalité. \n",
    "\n",
    "Par défaut, la fonction `LogisticRegression` ne sait pas choisir la constante de pénalisation automatiquement et par défaut cette constante est fixée à 1. Ce choix n'a pas de justification et n'a donc aucune raison d'être utilisé. \n",
    "\n",
    "- Utiliser la fonction `LogisticRegressionCV` pour choisir la constante $C$ qui maximise le score AUC (aire sous la courbe ROC) dans une grille de valeur de $C$ fixée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d8c53-c116-4531-a174-fde75619f3b9",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e574b-15ff-4d67-aa38-2924b2d0bda7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "C_grid = np.logspace(-4, 1, 14)\n",
    "cv = 8\n",
    "\n",
    "# Modèle de régression logistique avec pénalité l1 \n",
    "# validation croisée pour le choix automatique de la constante de pénalité C\n",
    "model_lasso_cv = LogisticRegressionCV(penalty='l1', tol=1e-3, Cs=C_grid, cv=8,\n",
    "                                      solver='liblinear', scoring='roc_auc') \n",
    "model_lasso_cv.fit(x_train, y_train)\n",
    "\n",
    "# résultats intermédiaires de calculs de ROC-AUC sur chacun des cv-folds\n",
    "crit = model_lasso_cv.scores_[1]\n",
    "print(crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c05609-3d4e-4f07-8b0b-333b38b22c90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"La valeur de C 'optimale' avec pénalité lasso est: \", model_lasso_cv.C_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e8abc0-6cc5-4d6f-a362-0f725e27a692",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_predicted_lasso_cv = model_lasso_cv.predict(x_test)\n",
    "\n",
    "precision_lasso_cv = precision_score(y_test, y_predicted_lasso_cv)\n",
    "recall_lasso_cv = recall_score(y_test, y_predicted_lasso_cv)\n",
    "\n",
    "print(f\"Precision score: {precision_lasso_cv:.3f}\")\n",
    "print(f\"Recall score: {recall_lasso_cv:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f131029-8890-4077-be5f-dd2bb57c9be4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## `scikit-learn` et automatisation: `pipeline`\n",
    "\n",
    "En `scikit-learn`, un _pipeline_ est une séquence ordonnée d'étapes de prétraitement des données et de modélisation regroupées en une seule entité. Il permet de définir et d'automatiser un flux de travail cohérent pour le traitement des données et l'entraînement d'un modèle.\n",
    "\n",
    "Il se compose en général de plusieurs étapes:\n",
    "- transformations des données :  normalisation des variables, l'imputation des valeurs manquantes, la réduction de dimension, etc. Elles permettent de préparer les données avant de les fournir au modèle.\n",
    "- le modèle d'apprentissage automatique.\n",
    "- la validation croisée : pour évaluer les performances du modèle.\n",
    "\n",
    "L'avantage d'utiliser un pipeline est qu'il permet de regrouper toutes ces étapes en une seule entité. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d63ca5d-eb11-4a62-8fbc-d9306ad0ceb8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Création d'un pipeline pour notre régression logistique \n",
    "\n",
    "- Définir à partir des classes `OneHotEncoder`, `StandardScaler` de `sklearn.preprocessing` et `ColumnTransformer` de `sklearn.compose` un préprocesseur qui réalise les mêmes transformations que celles faites dans la section 1.1.5 (Pré-traitement des données). Attention, la transformation `OneHotEncoder` doit s'appliquer uniquement aux données qualitatives et la transformation `StandardScaler` doit s'appliquer uniquement aux données quantitatives. \n",
    "- Créer un pipeline avec la fonction `make_pipeline` de `sklearn.pipeline` pour définir un modèle de régression logistique avec prétraitement des données automatique (fait par le préprocesseur)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f71dfb-f6b2-4039-af0b-3ed295403869",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fff3a9e-1604-40f3-a6d5-964d448e3b53",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "quantitative_preprocessor = StandardScaler()\n",
    "qualitative_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('standard_scaler', quantitative_preprocessor, quantitative.columns),\n",
    "    ('one-hot-encoder', qualitative_preprocessor, qualitative.columns)\n",
    "])\n",
    "\n",
    "model_pipe = make_pipeline(preprocessor, LogisticRegression(penalty=None, max_iter=1000))\n",
    "model_pipe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1150e-82f9-4c17-9d48-1c3c0713fcec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Utilisation du pipeline \n",
    "\n",
    "- Faire une estimation du modèle. Attention, quelles données doivent être utilisées ?\n",
    "- Faire des prédictions et calculer les différents scores sur le jeu de test.\n",
    "- Faire une étape de validation croisée. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f034c0-e6e1-4a80-951a-46fb12c9ce56",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9331a1b-8adf-4ff6-808f-f3b630678be3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# on retravaille à partir des données avant prétraitement \n",
    "data = pd.concat([quantitative, qualitative], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels,  stratify=labels,\n",
    "                                                    test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ef23b-c539-4f99-90d5-b65128b2d5ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model_pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5d26a-3ccc-408c-8480-5fea75a147be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model_pipe.named_steps['logisticregression'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa39042-00cc-4b31-86a0-4871f15b8241",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model_pipe.named_steps['logisticregression'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14da1d6-4b18-45e3-9306-f4da0acde4c4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "y_predicted = model_pipe.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "recall = recall_score(y_test, y_predicted)\n",
    "\n",
    "print(f\"Accuracy score: {accuracy:.3f}\")\n",
    "print(f\"Precision score: {precision:.3f}\")\n",
    "print(f\"Recall score: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4341ab31-ca10-484d-9a90-b35a9941bccc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "model_pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535824b3-0bab-469e-b3b8-a868b7dafe55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(model_pipe, data, labels, cv=5)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc9829-d756-456e-9357-bcd47e278cac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "scores = cv_results[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy is: \"\n",
    "      f\"{scores.mean():.3f} ± {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87974da9-76d8-445b-9aab-9191b02ead51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Avec une autre méthode de classification: Gradient Boosting\n",
    "\n",
    "L'avantage d'utiliser un module riche comme `scikit-learn` est qu'on peut facilement changer une brique pour tester d'autres modèles. Ici on propose de remplacer la brique `LogisticRegression` par une méthode basée sur les arbres de décisions. Les arbres de décisions et les méthodes de \"boosting\" seront expliquées dans le second cours mais voyons les résultats que l'on peut obtenir. \n",
    "\n",
    "- Utiliser le préprocesseur `OneHotEncoder` avec l'option `sparse_output` à `False` et la classe `HistGradientBoostingClassifier` du module `sklearn.ensemble` pour composer un pipeline que l'on nomme `model_gradboost`.\n",
    "\n",
    "- Comparer les courbes ROC et Precision/Recall obtenues avec cet estimateur et la régression logistique. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80798f1-9465-49ec-af96-e07af6ec78a3",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f441b-245a-49e8-af48-e7ed572b1dd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "quantitative_preprocessor = StandardScaler()\n",
    "qualitative_preprocessor = OneHotEncoder(handle_unknown=\"ignore\", \n",
    "                                         sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('standard_scaler', quantitative_preprocessor, quantitative.columns),\n",
    "    ('ordinal-encoder', qualitative_preprocessor, qualitative.columns)],\n",
    ")\n",
    "\n",
    "model_gradboost = make_pipeline(preprocessor, HistGradientBoostingClassifier())\n",
    "model_gradboost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6b6ab-4a95-40dc-81bd-2113775e572a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**Remarque:** dans la [documentation officielle](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_categorical.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-categorical-py) il est conseillé d'utiliser un autre préprocesseur pour les données qualitatives. Il s'agit de l'encodage `OrdinalEncoder`. Par cohérence avec la régression logistique on garde le `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5217985-8abb-4ae5-8a9a-54b30b2b4726",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "RocCurveDisplay.from_estimator(model_pipe, x_test, y_test, \n",
    "                               name=\"Logistic Regression\", ax=ax)\n",
    "RocCurveDisplay.from_estimator(model_gradboost, x_test, y_test, \n",
    "                               name=\"Gradient Boosting\", ax=ax)\n",
    "ax.set_xlabel(\"False positive rate\")\n",
    "ax.set_ylabel(\"True positive rate\")\n",
    "ax.set_title(\"Receiver Operating Characteristic curve on Test set\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ec657-57ed-4027-a053-d207e509d240",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "PrecisionRecallDisplay.from_estimator(model_pipe, x_test, y_test, \n",
    "                                      name=\"Logistic Regression\", ax=ax)\n",
    "PrecisionRecallDisplay.from_estimator(model_gradboost, x_test, y_test, \n",
    "                                      name=\"Gradient Boosting\", ax=ax)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title(\"Precision-recall curve on Test set\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
