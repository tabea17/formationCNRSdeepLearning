{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff439a24",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Prédiction de consommation électrique  avec `scikit-learn` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c7627-c31c-43b0-9888-8d3e29c886c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Dans ce TP, nous allons étudier la consommation électrique en France métropole entre janvier 2016 et mai 2023, à partir des données provenant du réseau de transport d’électricité français (RTE), disponibles sur le site https://analysesetdonnees.rte-france.com/.\n",
    "\n",
    "Le fichier `data/data.csv` (ou `data/data.pkl`) a été obtenu en agrégeant les données contenues dans les fichiers suivants : \n",
    "- `rte.csv` : consommation d'électricité relevée toutes les demi-heures\n",
    "- `calendar.csv` : informations sur le temps\n",
    "- `meteo.csv` : informations liées à la météo, notamment l'emplacement des stations et les différents relevés (température, nébulosité, humidité, vitesse du vent, précipitation), pris toutes les 3 heures. \n",
    "\n",
    "Pour les détails sur la génération de ce fichier, voir le notebook `day2_preparation_data.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c9f17a-c471-4870-826f-07555d22ddd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import des données\n",
    "\n",
    "Les données agrégées se trouvent dans le fichier `data/data.pkl`.\n",
    "\n",
    "- Importer les données sous forme d'un `DataFrame` pandas que l'on nomme `data`\n",
    "- Visualiser les premières et dernières lignes des données\n",
    "- Afficher la taille du `DataFrame`\n",
    "- Afficher les noms des premières 17 colonnes et ensuite des colonnes restantes\n",
    "- Faire de même pour le type de données présentes dans ces colonnes\n",
    "- Vérifier que le `DataFrame`ne contient pas de données manquantes\n",
    "- Convertir les variables `Mois`, `Jour`, `JourFerieType` en variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4011f98-958c-43a4-b8db-1bbf25ef6033",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e52c796a-075c-4cdb-bb78-a93fe4983c79",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Analyse des données\n",
    "\n",
    "Observons le tableau `data` des données agregées.\n",
    "\n",
    "## Saisonnalité\n",
    "\n",
    "Afficher le graphe des consommations éléctriques en fonction du temps. Observez-vous une saisonnalité ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775daca1-d6fd-4911-8739-b3e377e0463b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c84bd31a-a3ac-499f-844a-3af74492ddd5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Profils de consommation\n",
    "\n",
    "Utiliser les fonctions `groupby` et `agg` de pandas pour regrouper les données en faisant la moyenne des consommations par mois, par jour, ou par demi-heure, de sorte à obtenir des profils de consommation annuel, hebdomadaire et journalier.\n",
    "\n",
    "Afficher ces différents profils à l'aide de la fonction `lineplot` de la librairie `seaborn` et les commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d83559-f60f-4c8e-b6e1-76860cebe3ca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ba5e27-2ec7-41bc-a016-793f70087096",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Comportements particuliers\n",
    "\n",
    "Il est possible de mettre en évidence des petites anomalies dues au jours fériés ou au printemps 2020. \n",
    "\n",
    "- Afficher la consommation du mois de mai 2017, en mettant en évidence les jours féries\n",
    "- Afficher le profil de consommation journalier par jour de la semaine\n",
    "- Comparer la consommation moyenne de l'année 2020 à celle du reste des données et affi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747613a-dfb8-4a36-9a5b-62ae8757c21f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e68f0e2-f668-42bc-a8c2-798a6a3ba4b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Modèles : entraînement, prédiction et erreur "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3a2c3-041b-487b-9740-32833b112ea8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Séparation du jeu de données en train et test\n",
    "\n",
    "Séparer le jeu de données en deux pour obtenir le jeu d'entraînement et le jeu de test tels que \n",
    "\n",
    "- `X_train` et `Y_train` contiennent 50% du jeu de données pour l'apprentissage du modèle  \n",
    "- `X_test` et `Y_test` contiennent les 50% restants pour le test.\n",
    "\n",
    "On pourra utiliser la  fonction `train_test_split` du module `sklearn.model_selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbdb1bb-ca5f-4093-b2e8-52a421db6dad",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "787a10e0-57e2-492e-982c-954c7e7439a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Naive predictor\n",
    "\n",
    "Construire un prédicteur naïf qui renvoie la moyenne des consommations (une constante) et calculer l'erreur MAPE et l'erreur RMSE de ce prédicteur sur le jeu de test et sur celui de train.\n",
    "\n",
    "Ce prédicteur trivial représente le point de départ pour comparer les autres modèles.\n",
    "\n",
    "- Stocker les erreurs MAPE et RMSE sur le jeu de train et le jeu de test du modèle naïf dans un DataFrame `df_errors`.\n",
    "\n",
    "Pour rappel, si $\\hat Y_t$ est la valeur prédite par le modèle et $Y_t$ la consommation réalisée :\n",
    "\n",
    "MAPE = **mean absolute percentage error** : c'est une erreur de prédiction *relative*:\n",
    "$${\\displaystyle {\\mbox{MAPE}}={\\frac {1}{n}}\\sum _{t=1}^{n}\\left|{\\frac {Y_{t}-\\hat Y_{t}}{Y_{t}}}\\right|}\n",
    "$$\n",
    "En pratique, on préfère diviser par $|Y_{t}+\\varepsilon|$ pour éviter des division par zéro.\n",
    "\n",
    "RMSE = **root mean squared error** : c'est une erreur de prédiction *absolue*, sensible aux outliers:\n",
    "$${\\displaystyle {\\mbox{RMSE}}=\\sqrt{\\frac 1 n \\sum _{t=1}^{n}\\left(Y_{t}-\\hat Y_{t}\\right)^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6165dac-ba39-4ef0-9e8d-a2d4d3d74dbd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "On pourra utiliser les fonctions `mean_absolute_percentage_error` et `root_mean_squared_error` du module `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb71cb-c669-409f-8985-ebd73c7e7f90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2837339-956b-49da-a26b-fb54a702251e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Fonctions utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6931a-7eae-4f1c-9a95-977c5c3fe329",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Tous les modèles de régression de la librairie scikit-learn ont une méthode `fit` qui permet d'entraîner le modèle et une méthode `predict` qui calcule la valeur prédite.\n",
    "\n",
    "Nous allons comparer plusieurs méthodes et pour cela il sera utile de définir une fonction `fit_and_predict_error` qui, étant donné un modèle `model`, et un jeu de données `x_train`,`y_train`, `x_test`, `y_test`, entraîne le modèle en appelant la méthode `fit` du modèle sur le jeu d'entraînement, calcule la prédiction en appelant la méthode `predict` du modèle à la fois sur le jeu de test et sur le jeu de train, et calcule les erreurs MAPE et RMSE sur les 2 jeux.\n",
    "\n",
    "Cette fonction renvoie un dictionnaire contenant les prédictions calculées, `train` et `test`, et les erreurs MAPE et RMSE pour les jeux de train et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6968f8-6429-406f-828a-af021759ab86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8845c284-3f07-4c1c-883b-6504424dd6b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Pour stocker l'information sur les erreurs dans le tableau des erreurs `df_errors`, nous définissons également une fonction qui permet de le faire rapidement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629538f9-ab59-4781-81dd-9e117a4419e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_error(model_out, model_name, df):\n",
    "    return df._append({'Model' : model_name, \n",
    "                  'MAPE test' : model_out['mape_test'], \n",
    "                  'RMSE test' : model_out['rmse_test'], \n",
    "                  'MAPE train' : model_out['mape_train'], \n",
    "                  'RMSE train' : model_out['rmse_train'], \n",
    "                  'CPU time' : model_out['time']}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3894f7-b9a9-4f2c-af01-4b78e1eaa8b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Regression linéaire\n",
    "\n",
    "Nous allons en première approche utiliser des modèles linéaires pour apprendre et prévoir les données de consommation.  \n",
    "\n",
    "- A l'aide de la librairie `sklearn.linear_model`, mettre en place plusieurs modèles de regression linéaire pour prédire la variable `Consommation` en fonction des caractéristiques suivantes : \n",
    "    1. `Temperature`\n",
    "    2. Données méteo\n",
    "    3. Données méteo et `PositionDansAnnee`, `JourFerie`, `DemiHeure`\n",
    "    4. Les caractéristiques ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation', 'PositionDansAnnee', 'DemiHeure', 'JourFerie',  'Vacances', 'MJour', 'Annee', 'is.2020']\n",
    "    5. Toutes les caractéristiques\n",
    "\n",
    "- Lequel de ces modèles donne les meilleurs résultats ? \n",
    "\n",
    "- Afficher, pour les modèles naïf, 1, 4 et 5, la consommation réelle et la consommation prédite sur les données complètes, sur un même graphe (il y a donc 4 graphes, un par modèle). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9aed08-ed07-4499-90a4-f5a3579d28d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfbdf8a1-f7d8-443d-9204-f3532a48364a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Nous allons dorenavant travailler uniquement sur deux ensembles de caractéristiques :\n",
    "- Les caractéristiques réduites  :  ['Temperature', 'Nebulosity', 'Humidity', 'WindSpeed', 'Precipitation', 'PositionDansAnnee', 'DemiHeure', 'JourFerie', 'Vacances', 'MJour', 'Annee', 'is.2020']\n",
    "- Les caractéristiques complètes\n",
    "\n",
    "Créer deux jeux de données d'entrainement (et de test) `X_train_S` et `X_train_L` (respectivement `X_test_S` et `X_test_L`) correspondants à ces deux ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f658244-51ca-4754-80c2-4a7b4d798abf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78837329-6e17-4720-bb7d-4ceb59677d35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Lasso and Ridge regression\n",
    "\n",
    "Essayons d'améliorer les performances en ajoutant une pénalité $\\ell_1$ et une pénalité $\\ell_2$ à la regression linéaire. \n",
    "\n",
    "A l'aide des modules `LassoCV` et `RidgeCV` mettre en place deux estimateurs sur les données réduites et sur les données complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714321b-5510-4003-83ce-746d68630096",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a30390bf-26ea-48a4-9e84-fa1cd6636233",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Arbres de décision -- CART\n",
    "\n",
    "Les *Classification and Regression Trees* (CART) permettent de prédire la consommation en suivant des simples règles de décision qui dépendent des caractéristiques observées.\n",
    "\n",
    "Le choix du nombres et du type de caractéristiques utilisées pour construire un arbre, ainsi que sa profondeur influent énormément sur le résultat, les paramètres à indiquer dans sa construction sont à choisir attentivement. \n",
    "\n",
    "A noter que dans un contexte d'arbres de décision la normalisation des caractéristiques n'est pas nécessaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d5ac1-6472-4ec9-870f-78e0d854d9bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Default\n",
    "\n",
    "Utiliser la classe `DecisionTreeRegressor` du module `sklearn.tree` pour construire un estimateur basé sur un arbre de décision.\n",
    "\n",
    "- Utiliser initialement les paramètres par défaut.\n",
    "\n",
    "- Entraîner le modèle sur les données réduites et sur les données complètes.\n",
    "\n",
    "- Afficher les erreurs. Que remarque-t-on sur les erreurs calculées sur le train set ? Comment le justifier ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e5675-2c85-44e9-84b9-8aeb7deafad3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf3f763-7ba2-4441-b90c-61a2431b67df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Réduction de profondeur\n",
    "\n",
    "Retrouver dans la documentation les valeurs par défaut des paramètres d'un arbre de régression suivants :\n",
    "\n",
    "- max_depth\n",
    "- min_samples_leaf\n",
    "- max_features\n",
    "  \n",
    "Quelle est la profondeur de l'arbre construit par défaut ? \n",
    "\n",
    "Construire un arbre de profondeur 10 et comparer les erreurs avec les modèles précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9648fdd-ef1a-4e6e-8b27-e7f1968ba87c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8864010-7d34-4dae-a4d4-7019f39866d8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Visualisation\n",
    "\n",
    "- Construire un arbre de profondeur 4 et l'entraîner sur les données complètes\n",
    "- A l'aide de la fonction `plot_tree` du module `tree` de sklearn, visualiser l'arbre de décision.\n",
    "\n",
    "- Quelles sont les caractéristiques sur lesquelles sont fait les splits de cet arbre ? \n",
    "- Combien de noeuds a cet arbre ? Combien d'observations y a-t-il dans chaque noeud ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4530f2f-2f8c-4a7f-ada3-2ed140caf50c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eef8d2e6-a924-4181-b8ba-66af04ed3664",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf025c8-b1c4-416e-a1f9-d97e81a76c51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Le bagging (ou agrégation Bootstrap) est un type d'apprentissage d'ensemble dans lequel plusieurs modèles de base sont entrainés indépendamment et en parallèle sur différents sous-ensembles des données d'entraînement. Dans le bagging, les étapes d'entraînement et de prédiction sont précédées par une étape de bootstrap.\n",
    "\n",
    "1. **Échantillonnage bootstrap** : Dans l'échantillonnage bootstrap, $K$ sous-ensembles aléatoires des données originales sont échantillonnés avec remplacement. Cette étape garantit que les modèles de base sont formés sur divers sous-ensembles des données, car certains échantillons peuvent apparaître plusieurs fois dans le nouveau sous-ensemble, tandis que d'autres peuvent être omis. Cela réduit les risques de surajustement et améliore la précision du modèle.\n",
    "\n",
    "2. **Entraînement sur les modèles de base** : Après la première étape d'échantillonnage bootstrap, le modèle de base (arbres de décision, SVM...) est entraîné indépendamment sur chaque sous-ensemble de données bootstrap différent. Ces modèles de base sont généralement dits « faibles » car ils peuvent ne pas être très précis à eux seuls. \n",
    "\n",
    "3. **Agrégation** : Une fois que tous les modèles de base ont été entraînés, ils sont utilisé pour faire chacun une prédiction sur les données de test. Dans les modèles de classification, la prédiction finale est effectuée en agrégeant les prédictions des modèles de base en utilisant le vote majoritaire. Dans les modèles de régression, la prédiction finale est obtenue en faisant la moyenne des prédictions des modèles de base.\n",
    "\n",
    "**Évaluation Out-of-Bag (OOB)** : Dans l'étape d'échantillonage, certaines observations sont exclues de l'échantillon boostrap. Ces observations *out-of-bag* peuvent être utilisées pour évaluer les performances du modèle.\n",
    "\n",
    "![Classificateur par agrégation bootstrap](img/Bagging-classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfedea9-4cf4-43ff-a86f-ff1b1c7b5bdf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Les arbres de décision vus au point précédent sont extrêmement dépendant du training set. Les modèles de bagging, grâce à l'étape d'échantillonnage aléatoire, permettent de réduire cette sensibilité aux données d'entraînement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3c1ad-af63-42e4-8c92-ac3f3663547d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Bagging à la main\n",
    "\n",
    "Ecrire un bagging à la main de taille `K=100` *sur les données réduites* en suivant les étapes suivantes :\n",
    "\n",
    "1. Créer K échantillons boostrap de même taille que l'échantillon d'entraînement :\n",
    "    - Utiliser la fonction `np.random.choice` avec paramètre `replace=True` pour générer un tableau d'indices `indexes` de même taille que l'échantillon original\n",
    "    - Un échantillon booststrap est donné par `X_train_S[indexes]`\n",
    "2. Entraîner un arbre de décision simple (peu profond, avec un nombre d'observations minimal par feuille, ...) sur chaque échantillon bootstrap\n",
    "3. Calculer la valeur prédite par bagging :\n",
    "      - Calculer la prédiction de chaque arbre\n",
    "      - Renvoyer la moyenne des valeurs prédites par les K arbres\n",
    "4. Calculer et afficher les erreurs MAPE et RMSE *out-of-bag*. \n",
    "\n",
    "Une fois le modèle sur les données réduites maîtrisé, il est possible de passer sur les données complètes, tout en tenant compte des temps de calculs attendus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d23d7-3ace-4df0-a96e-af73fec79e23",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc12333-935d-45c0-9986-4bcbb7845e64",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Bagging de sklearn\n",
    "\n",
    "- Comparer avec un bagging construit en utilisant la fonction `BaggingRegressor` du module `sklearn.ensemble`.\n",
    "- Afficher le score *out-of-bag* de ce prédicteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe83e0-fe0a-4edd-80c3-e6ce05edf321",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc9ac300-9e2e-4098-bce9-db69814ca55e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Random forest\n",
    "\n",
    "Le forêts aléatoires sont une extension du bagging pour les arbres de décision qui permet de réduire davantage la variance du modèle, en ajoutant un caractère aléatoire lors de la création des arbres.\n",
    "\n",
    "Pendant la construction d'un arbre, au lieu de rechercher la caractéristique la plus importante lors de la division d'un nœud, on recherche la meilleure caractéristique **parmi un sous-ensemble aléatoire de caractéristiques**. Il y a donc deux niveaux *random* dans ce modèle (d'où le nom \"random forest\"): le random du bootstrap et la sélection random des caractéristiques. Le premier réduit la dépendance au training set, le deuxième réduit la corrélation entre les arbres de la forêt. Il en résulte une grande diversité qui se traduit généralement par un meilleur modèle.\n",
    "\n",
    "### Exercice\n",
    "\n",
    "- A l'aide de la classe `RandomForestRegressor` du module `sklearn.ensemble`, entraîner une foret aléatoire avec paramètres par défaut sur les données réduites et comparer les erreurs avec les autres modèles. Afficher également le score *out-of-bag* de ce prédicteur.  \n",
    "- Visualiser dans un graphe l'évolution des erreurs en fonction du nombre d'arbres de la forêt.\n",
    "- Les résultats théoriques montrent que le bon nombre de caractéristiques à tenir en compte lors d'un split est soit de l'ordre de la racine carré du nombre total des caractéristiques, soit de son logarithme. Entraîner une foret aléatoire avec un nombre d'arbres choisi sur la base de la visualisation du point précédent, et un nombre de caractéristiques de l'ordre de la racine carré du nombre total de caractéristiques. Afficher également le score *out-of-bag* de ce prédicteur.  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f30ee6-00e1-4032-ab17-ea0216c8d9df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "059c115c-e34f-41bf-a972-b9ef5e3331f6",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Extra trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d06b2-2f23-4d00-a1c6-7a3cf818dab0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Proche des forêts aléatoires, les Extra Trees, dit aussi Extremely Randomized Trees, ajoutent une couche supplémentaire d'aléatoire au forêts, en choisissant le split d'une caractéristique au hasard, au lieu qu'en sélectionnant le meilleur split. Cela réduit par ailleurs de façon considérable le temps de calcul.\n",
    "\n",
    "### Exercice\n",
    "\n",
    "- Combiner la classe `ExtraTreeRegressor` et `BaggingRegressor` pour obtenir une forêt d'arbres extrêmement aléatoires.  \n",
    "- Entraîner, prédire et afficher le score *out-of-bag* d'abord sur les données réduites, et ensuite sur les données complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b85765a-57dd-46d5-bc03-24b90519d73f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6f4243a-2198-426f-a007-ea15e6bbb5a9",
   "metadata": {
    "editable": true,
    "raw_mimetype": "",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Boosting\n",
    "\n",
    "Nous avons vu que les méthodes de Bagging permettent de construire un prédicteur robuste à partir de plusieurs prédicteurs faibles. Les prédicteurs faibles peuvent être construits en parallèle, c'est-à-dire que la construction de chacun d'entre eux peut être faite indépendamment des autres.\n",
    "\n",
    "Une autre technique d'ensemble, différente du Bagging, consiste à générer les prédicteurs de façon séquentielle, en améliorant à chaque itération le nouveau modèle par rapport au précédent. C'est la technique du **Boosting**.\n",
    "\n",
    "Tout d'abord, un modèle est construit à partir des données d'apprentissage. Ensuite, un deuxième modèle est construit pour tenter de corriger les erreurs présentes dans le premier modèle. Cette procédure se poursuit et des modèles sont ajoutés jusqu'à ce que l'ensemble des données d'apprentissage soit prédit correctement ou que le nombre maximum de modèles soit atteint. \n",
    "\n",
    "Dans toutes les techniques de Boosting, des poids sont associés aux données d'apprentissage, et à chaque itération ces poids sont réajustés, de façon à augmenter le poids des données mal prédites  et réduire celui des données correctement prédites. Ceci permet au modèle suivant de se \"concentrer\" sur les mauvaise prédictions et de s'améliorer.\n",
    "\n",
    "![Boosting classifier](img/Boosting-classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b987e-3861-4bdd-a795-1cbf8c6e609e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Il existe plusieurs algorithmes de Boosting, parmi les plus connus nous pouvons citer : \n",
    "- **Gradient Boosting** :\n",
    "    - Chaque nouveau modèle est entraîné pour minimiser la fonction de perte (erreur quadratique moyenne ou cross-entropie) du modèle précédent à l'aide d'une descente de gradient.\n",
    "    - À chaque itération, l'algorithme calcule le gradient de la fonction de perte par rapport aux prédictions de l'ensemble actuel, puis entraîne un nouveau modèle faible pour minimiser ce gradient.\n",
    "    - Les prédictions du nouveau modèle sont ensuite ajoutées à l'ensemble, et le processus est répété jusqu'à ce qu'un critère d'arrêt soit rempli.\n",
    "- **AdaBoost** -- Adaptative Boosting\n",
    "- **XGBoost** -- eXtreme Gradient Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be90f8a-68bf-4baa-bd2d-079abf85d304",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice\n",
    "\n",
    "Utiliser le module `GradientBoostingRegressor` pour prédire la consommation via une regression par Gradient Boosting avec un learning rate égal à 0.7, un nombre d'estimateurs égal à 1000 et une profondeur de l'arbre égale à 10. \n",
    "\n",
    "Si vous en avez le temps, faites de la validation croisée sur le learning rate et le nombre d'estimateurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df3aa31-40fe-423c-9eae-b4035ede05a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f342e-fe7e-4d58-b913-69d9df7a0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(learning_rate=0.7, n_estimators=100,max_depth=10)\n",
    "\n",
    "gb_large = fit_and_predict_error(gb, X_train_L, Y_train, X_test_L, Y_test)\n",
    "df_errors = add_error(gb_large, 'Gradient Boosting L n=100', df_errors)\n",
    "\n",
    "df_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40459a5-4c63-4863-9a7b-5026c7e5fc32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Feature importance/importance des variables\n",
    "\n",
    "L'importance des variables indique dans quelle mesure chaque caractéristique contribue à la prédiction du modèle. Une première idée de l'importance des variables, par exemple, peut être donnée par la correlation entre chaque variable et la variable à prédire. Selon le modèle, il existe d'autres mesures qui peuvent aider à affiner la compréhension de quelles variables contribuent le plus à la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cff7b-f098-41ed-ba59-c7768af9925d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Regressions linéaires\n",
    "\n",
    "Combien de caractéristiques sont retenues dans les modèles Lasso ? \n",
    "\n",
    "Commenter au vu des erreurs obtenues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71361bc5-e651-4824-85a7-2f4b9c4d81bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adfc4fb2-9cd9-4f09-b60b-08a2c9f2450c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Exercice : Modèles d'ensembles \n",
    "Pour les arbres de décisions, les forêts aléatoires ou le gradient boosting, l'importance d'une variable peut être calculée comme la réduction totale du critère apportée par cette variable. Cet indice est connu aussi sous le nom de indice de Gini.\n",
    "\n",
    "Afficher dans un histogramme à barres horizontales (`barh`) l'indice de Gini des 10 variables le plus importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ce29a-f6bb-4ef2-996b-aade027c0239",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "aremplir"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
